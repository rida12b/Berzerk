This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/workflows/ci.yml
.github/workflows/deploy.yml
.gitignore
agents.py
backtester.py
berzerk_dashboard_old.py
berzerk_dashboard.py
berzerk_lab.py
deployment/berzerk-monitor.service
deployment/README.md
diagnostic_db.py
env.example
orchestrator.py
pyproject.toml
pytest.ini
README.md
real_time_rss_monitor.py
requirements.txt
reset_and_analyze.py
start_realtime_monitor.py
suivi_projet.md
test_feeds.py
tests/__init__.py
tests/integration/__init__.py
tests/unit/__init__.py
tests/unit/test_agents.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/workflows/ci.yml">
name: BERZERK - Test, Lint & Format

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  validate-code:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11"]

    steps:
    - name: 1. Checkout du code
      uses: actions/checkout@v4

    - name: 2. Mise en place de Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: 3. Installation des d√©pendances
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-mock black ruff

    - name: 4. Cr√©ation du fichier .env pour la CI
      # IMPORTANT: Ces variables doivent √™tre configur√©es dans le repo GitHub
      # Settings > Secrets and variables > Actions > Variables (PAS Secrets)
      run: |
        echo "GOOGLE_API_KEY=${{ vars.GOOGLE_API_KEY }}" >> .env
        echo "TAVILY_API_KEY=${{ vars.TAVILY_API_KEY }}" >> .env
        echo "CI_ENV=true" >> .env # Variable pour indiquer qu'on est en CI

    - name: 5. V√©rification du formatage avec Black
      run: black --check .

    - name: 6. Linting avec Ruff
      run: ruff check .

    - name: 7. Ex√©cution des tests avec Pytest
      run: pytest
</file>

<file path=".github/workflows/deploy.yml">
name: BERZERK - Deploy to Production

on:
  push:
    branches: [ main ]

jobs:
  deploy:
    # Ce job ne s'ex√©cutera que si le workflow de CI a r√©ussi
    needs: validate-code
    runs-on: ubuntu-latest
    
    # S'assure que le d√©clencheur est bien un push, et non une pull request
    if: github.event_name == 'push'

    steps:
    - name: 1. Checkout du code
      uses: actions/checkout@v4

    - name: 2. D√©ploiement sur le serveur de production via SSH
      uses: appleboy/ssh-action@v1.0.3
      with:
        host: ${{ secrets.PROD_HOST }}
        username: ${{ secrets.PROD_USERNAME }}
        key: ${{ secrets.PROD_SSH_KEY }}
        port: 22
        script: |
          # Commandes √† ex√©cuter sur le serveur distant
          # Naviguer vers le r√©pertoire de l'application
          cd /home/berzerk/app 

          # Mettre √† jour le code depuis la branche main
          echo ">>> Mise √† jour du code depuis Git..."
          git pull origin main

          # Activer l'environnement virtuel
          echo ">>> Activation de l'environnement virtuel..."
          source venv/bin/activate
          
          # Mettre √† jour les d√©pendances Python
          echo ">>> Installation des d√©pendances..."
          pip install -r requirements.txt
          
          # Red√©marrer le service de monitoring pour appliquer les changements
          echo ">>> Red√©marrage du service de monitoring..."
          sudo systemctl restart berzerk-monitor
          
          # Optionnel : Red√©marrer le service du dashboard s'il tourne aussi sur le serveur
          # sudo systemctl restart berzerk-dashboard

          echo ">>> D√©ploiement termin√© avec succ√®s !"
</file>

<file path="deployment/berzerk-monitor.service">
[Unit]
Description=BERZERK Real-Time RSS Monitor Service
After=network.target

[Service]
# Utilisateur qui ex√©cutera le service
User=berzerk 
# Groupe qui ex√©cutera le service
Group=berzerk 

# R√©pertoire de travail de l'application
WorkingDirectory=/home/berzerk/app 

# Commande pour d√©marrer le service
# Utilise le python de l'environnement virtuel
ExecStart=/home/berzerk/app/venv/bin/python real_time_rss_monitor.py

# Politique de red√©marrage : toujours red√©marrer en cas de crash
Restart=always 
# D√©lai avant de red√©marrer
RestartSec=10 

# Configuration des logs
StandardOutput=journal
StandardError=journal
SyslogIdentifier=berzerk-monitor

[Install]
WantedBy=multi-user.target
</file>

<file path="deployment/README.md">
# üöÄ Guide de D√©ploiement BERZERK

## Configuration du Serveur de Production

### 1. Pr√©paration du serveur

#### G√©n√©rer une paire de cl√©s SSH
```bash
ssh-keygen -t ed25519 -C "berzerk-deploy-key"
```

#### Cloner le projet sur le serveur
```bash
git clone https://github.com/votre-nom/berzerk.git /home/berzerk/app
```

#### Cr√©er l'environnement virtuel
```bash
cd /home/berzerk/app
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

#### Cr√©er le fichier .env sur le serveur
```bash
nano /home/berzerk/app/.env
# Ajoutez vos cl√©s :
# GOOGLE_API_KEY=votre_cl√©_google
# TAVILY_API_KEY=votre_cl√©_tavily
```

### 2. Configuration du service systemd

#### Copier le fichier de service
```bash
sudo cp deployment/berzerk-monitor.service /etc/systemd/system/
```

#### Activer et d√©marrer le service
```bash
sudo systemctl daemon-reload
sudo systemctl enable berzerk-monitor.service
sudo systemctl start berzerk-monitor.service
```

#### V√©rifier le statut
```bash
sudo systemctl status berzerk-monitor
journalctl -u berzerk-monitor -f
```

### 3. Configuration GitHub

#### Variables (Settings > Secrets and variables > Actions > Variables)
- `GOOGLE_API_KEY`: Votre cl√© API Google Gemini
- `TAVILY_API_KEY`: Votre cl√© API Tavily

#### Secrets (Settings > Secrets and variables > Actions > Secrets)
- `PROD_HOST`: Adresse IP ou domaine du serveur
- `PROD_USERNAME`: Nom d'utilisateur SSH (ex: ubuntu, berzerk)
- `PROD_SSH_KEY`: Cl√© SSH priv√©e pour l'authentification

### 4. Workflow de D√©ploiement

Le syst√®me CI/CD fonctionne ainsi :

1. **Push vers main** ‚Üí D√©clenche le workflow CI
2. **Tests & Linting** ‚Üí Validation automatique de la qualit√©
3. **D√©ploiement** ‚Üí Si CI r√©ussie, d√©ploiement automatique
4. **Red√©marrage services** ‚Üí Application des changements
</file>

<file path="env.example">
# Cl√© API pour Google Gemini
GOOGLE_API_KEY="votre_cl√©_ici"

# Cl√© API pour Tavily Search
TAVILY_API_KEY="votre_cl√©_ici"
</file>

<file path="pyproject.toml">
[tool.black]
line-length = 88
target-version = ['py311']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | venv
  | _build
  | buck-out
  | build
  | dist
)/
'''

[tool.ruff]
# M√™me longueur de ligne que Black
line-length = 88
target-version = "py311"

# Fichiers √† exclure
exclude = [
    ".bzr",
    ".direnv",
    ".eggs",
    ".git",
    ".hg",
    ".mypy_cache",
    ".nox",
    ".pants.d",
    ".pytype",
    ".ruff_cache",
    ".svn",
    ".tox",
    ".venv",
    "__pypackages__",
    "_build",
    "buck-out",
    "build",
    "dist",
    "node_modules",
    "venv",
]

[tool.ruff.lint]
# R√®gles √† activer
select = [
    "E",  # pycodestyle errors
    "W",  # pycodestyle warnings
    "F",  # pyflakes
    "I",  # isort
    "B",  # flake8-bugbear
    "C4", # flake8-comprehensions
    "UP", # pyupgrade
]

# R√®gles √† ignorer
ignore = [
    "E501", # line too long, g√©r√© par Black
    "B008", # do not perform function calls in argument defaults
    "C901", # too complex
]

[tool.ruff.lint.mccabe]
max-complexity = 10
</file>

<file path="pytest.ini">
[pytest]
minversion = 6.0
addopts = -ra -q
testpaths =
    tests
</file>

<file path="README.md">
# ‚ö° BERZERK

An AI-powered financial news analysis engine for generating "tac-au-tac" investment decisions.

BERZERK est un syst√®me automatis√© qui surveille en temps r√©el les actualit√©s financi√®res, d√©ploie une √©quipe d'agents IA sp√©cialis√©s pour analyser leur impact potentiel, et g√©n√®re des d√©cisions d'investissement claires et exploitables. Le projet est construit sur une philosophie de "Pure Pr√©diction", visant √† agir sur le potentiel futur d'une information avant que le march√© ne l'ait pleinement int√©gr√©e.

![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![Framework](https://img.shields.io/badge/Framework-Streamlit-ff69b4.svg)

## üéØ Core Features

**Real-Time News Monitoring**: Surveillance quasi-instantan√©e (cycles de 30s) du flux RSS de Bloomberg avec des optimisations HTTP avanc√©es (ETags, Last-Modified) pour une efficacit√© maximale.

**AI Agent Team**: Une √©quipe d'agents IA, orchestr√©e par LangGraph, collabore pour analyser les news sous diff√©rents angles :
- **Ticker Hunter**: Identifie les entreprises cot√©es les plus impact√©es par une news.
- **Pure Prediction Analyst**: √âvalue l'impact futur d'une nouvelle sur une action sp√©cifique, en ignorant d√©lib√©r√©ment la r√©action pass√©e du march√©.
- **Sector & Geopolitical Analysts**: Fournissent un contexte plus large lorsque n√©cessaire.
- **Final Investor**: Synth√©tise toutes les analyses pour prendre la d√©cision finale.

**Automated Analysis Pipeline**: Un graphe d'√©tats (LangGraph) g√®re l'ensemble du processus, de la r√©cup√©ration de la news √† la d√©cision finale, de mani√®re robuste et tra√ßable.

**"Clart√© Radicale" Decision Feed**: Une interface utilisateur Streamlit √©pur√©e qui pr√©sente les d√©cisions d'investissement de mani√®re simple, hi√©rarchis√©e et orient√©e vers l'action.

**Performance Backtesting**: Un module int√©gr√© pour simuler la performance historique des recommandations d'achat et valider la strat√©gie du syst√®me.

**Centralized Database**: Utilise SQLite pour stocker les articles, les analyses et les d√©cisions, assurant la persistance et √©vitant le retraitement.

## üèóÔ∏è Architecture

Le syst√®me est con√ßu avec une s√©paration claire entre le backend de surveillance/analyse et le frontend de visualisation.

```mermaid
graph TD
    subgraph "Backend (Service 24/7)"
        A[RSS Feed - Bloomberg] -- News --> B(real_time_rss_monitor.py);
        B -- D√©tecte nouvelle --> C{orchestrator.py};
        C -- Lance pipeline LangGraph --> D[AI Agent Team];
        D -- Analyse & D√©cide --> E[D√©cision Finale];
        E -- Sauvegarde --> F[(berzerk.db)];
    end

    subgraph "Frontend (Visualisation)"
        F -- Lit les d√©cisions --> G[berzerk_decision_feed.py];
        G -- Affiche --> H{Utilisateur};
    end
    
    subgraph "Outils de Validation"
        F -- Lit les d√©cisions d'achat --> I(backtester.py);
        I -- Simule les trades --> J[Rapport de Performance];
    end
```

## üõ†Ô∏è Tech Stack

- **Backend**: Python 3.9+
- **AI & Orchestration**: LangChain, LangGraph, Google Gemini
- **Frontend**: Streamlit
- **Database**: SQLite
- **Data & Web**: yfinance (donn√©es financi√®res), Tavily (recherche web), requests, BeautifulSoup4, feedparser

## üöÄ Setup and Installation

Suivez ces √©tapes pour mettre en place BERZERK sur votre machine locale.

### 1. Clone the Repository

```bash
git clone https://github.com/votre-nom-utilisateur/berzerk.git
cd berzerk
```

### 2. Create a Virtual Environment

Il est fortement recommand√© d'utiliser un environnement virtuel pour isoler les d√©pendances du projet.

```bash
python3 -m venv venv
source venv/bin/activate
# Sur Windows: venv\Scripts\activate
```

### 3. Install Dependencies

Toutes les d√©pendances requises sont list√©es dans requirements.txt.

```bash
pip install -r requirements.txt
```

### 4. Set Up Environment Variables

Le syst√®me a besoin de cl√©s API pour fonctionner. Copiez le fichier d'exemple et remplissez-le avec vos cl√©s.

```bash
cp env.example .env
```

Ouvrez le fichier `.env` avec un √©diteur de texte et ajoutez vos cl√©s API :

```dotenv
# Cl√© API pour Google Gemini
GOOGLE_API_KEY="votre_cl√©_ici"

# Cl√© API pour Tavily Search
TAVILY_API_KEY="votre_cl√©_ici"
```

### 5. Initialize the Database

La base de donn√©es `berzerk.db` sera cr√©√©e automatiquement au premier lancement du moniteur. Aucune action manuelle n'est requise.

## üìñ How to Use

BERZERK peut √™tre utilis√© de plusieurs mani√®res, en fonction de vos besoins.

### 1. Lancement Principal (Recommand√©)

Le script `start_realtime_monitor.py` est le moyen le plus simple de d√©marrer le syst√®me. Il lance le moniteur en arri√®re-plan et, optionnellement, le tableau de bord.

Pour lancer la surveillance seule :
```bash
python start_realtime_monitor.py
```

Pour lancer la surveillance ET le tableau de bord en parall√®le :
```bash
python start_realtime_monitor.py --with-dashboard
```

Vous pouvez ensuite acc√©der au tableau de bord sur http://localhost:8501.

Appuyez sur `Ctrl+C` dans le terminal pour arr√™ter tous les processus.

### 2. Lancer le Tableau de Bord Manuellement

Si vous voulez seulement visualiser les d√©cisions d√©j√† pr√©sentes dans la base de donn√©es.

```bash
streamlit run berzerk_decision_feed.py
```

### 3. V√©rifier la Performance

Pour lancer une simulation des performances pass√©es des d√©cisions d'achat.

```bash
python backtester.py
```

### 4. Analyser une URL Unique (Mode Test)

Pour tester le pipeline sur un article sp√©cifique sans lancer la surveillance continue.

```bash
python orchestrator.py "https://url-de-votre-article.com"
```

### 5. R√©initialiser les Analyses

Pour nettoyer toutes les analyses existantes et relancer le processus sur les articles les plus r√©cents (utile apr√®s une mise √† jour des agents).

```bash
python reset_and_analyze.py
```

## üß† The BERZERK Philosophy: "Tac au Tac" Pure Prediction

BERZERK a √©volu√© pour adopter une philosophie radicale : **la pr√©diction pure**. Contrairement √† une approche prudente qui v√©rifierait si le march√© a d√©j√† r√©agi √† une nouvelle, BERZERK agit comme un visionnaire.

- **Il Ignore D√©lib√©r√©ment les Donn√©es de March√© Pass√©es** : Le syst√®me ne regarde pas le prix de la veille ou le volume r√©cent. Il √©vite ainsi d'√™tre "pollu√©" par la volatilit√© et les r√©actions irrationnelles √† court terme.

- **Il se Fonde sur le Potentiel de l'Information** : La d√©cision est bas√©e sur l'impact fondamental que la news est susceptible d'avoir sur le business d'une entreprise.

- **Il Vise √† Agir AVANT la Foule** : L'objectif est de capturer la valeur cr√©√©e par l'information elle-m√™me, pas de suivre une tendance d√©j√† en cours.

Cette approche fait de BERZERK non pas un simple co-pilote d'analyse, mais une v√©ritable **machine de guerre pr√©dictive**, con√ßue pour √™tre offensive et d√©cisive.

## üìÇ Project Modules Explained

- **`orchestrator.py`**: Le c≈ìur du syst√®me. Contient le pipeline LangGraph qui orchestre la collaboration des agents IA.
- **`agents.py`**: D√©finit les profils et les capacit√©s de chaque agent IA sp√©cialis√© (Ticker Hunter, Pure Prediction Analyst, etc.).
- **`real_time_rss_monitor.py`**: Le service de surveillance 24/7 qui scanne les flux RSS, d√©tecte les nouvelles et d√©clenche le pipeline d'analyse.
- **`berzerk_decision_feed.py`**: L'interface utilisateur Streamlit con√ßue selon le principe de "Clart√© Radicale".
- **`backtester.py`**: Outil de validation qui simule la rentabilit√© des d√©cisions d'achat pass√©es.
- **`start_realtime_monitor.py`**: Script de lancement simplifi√© pour une prise en main facile.
- **`reset_and_analyze.py`**: Script de maintenance pour r√©initialiser et relancer les analyses.
- **`berzerk.db`**: La base de donn√©es SQLite o√π toutes les donn√©es (articles, d√©cisions) sont stock√©es.

## üìÑ License

This project is licensed under the MIT License. See the LICENSE file for details.
</file>

<file path="tests/__init__.py">
# Fichier marker pour le package de tests BERZERK
</file>

<file path="tests/integration/__init__.py">
# Tests d'int√©gration pour le projet BERZERK
</file>

<file path="tests/unit/__init__.py">
# Tests unitaires pour le projet BERZERK
</file>

<file path="tests/unit/test_agents.py">
from agents import get_agent_description, get_available_agents


def test_route_to_agents_fallback_logic():
    """
    Teste la logique de fallback du routeur quand le LLM √©choue.
    Ce test est plus simple et ne d√©pend pas du LLM.
    """
    # 1. Test avec un ticker en majuscules (devrait d√©clencher analyste_actions)
    entities = ["AAPL", "technologie", "innovation"]

    # Test direct de la logique de fallback (extraite de la fonction)
    fallback_agents = []

    # Recherche de tickers (g√©n√©ralement en majuscules, 2-5 caract√®res)
    tickers = [
        entity for entity in entities if entity.isupper() and 2 <= len(entity) <= 5
    ]
    if tickers:
        fallback_agents.append({"agent_type": "analyste_actions", "focus": tickers[0]})

    # Recherche de secteurs (mots-cl√©s courants)
    secteurs = [
        "tech",
        "technologie",
        "√©nergie",
        "finance",
        "sant√©",
        "pharma",
        "automobile",
    ]
    for entity in entities:
        if any(secteur in entity.lower() for secteur in secteurs):
            fallback_agents.append(
                {"agent_type": "analyste_sectoriel", "focus": entity}
            )
            break

    # 2. V√©rifications
    assert len(fallback_agents) == 2
    assert fallback_agents[0]["agent_type"] == "analyste_actions"
    assert fallback_agents[0]["focus"] == "AAPL"
    assert fallback_agents[1]["agent_type"] == "analyste_sectoriel"
    assert fallback_agents[1]["focus"] == "technologie"


def test_get_available_agents():
    """
    Teste que la fonction get_available_agents retourne les bons types d'agents.
    """
    agents = get_available_agents()

    # V√©rification que les agents de base sont pr√©sents
    expected_agents = [
        "analyste_actions",
        "analyste_sectoriel",
        "strategiste_geopolitique",
        "ticker_hunter",
    ]

    for agent in expected_agents:
        assert agent in agents


def test_get_agent_description():
    """
    Teste que get_agent_description retourne une description pour les agents connus.
    """
    # Test avec un agent connu
    description = get_agent_description("analyste_actions")
    assert description != "Agent non reconnu"
    assert len(description) > 10  # Une description doit avoir du contenu

    # Test avec un agent inconnu
    description_unknown = get_agent_description("agent_inexistant")
    assert description_unknown == "Agent non reconnu"
</file>

<file path=".gitignore">
# YoYo AI version control directory
.yoyo/

# Base de donn√©es SQLite
*.db
berzerk.db

# Variables d'environnement
.env
.env.local

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
.venv/
pip-log.txt
pip-delete-this-directory.txt

# Virtual Environment
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Temporary files
*.tmp
*.temp" > .gitignore
</file>

<file path="backtester.py">
#!/usr/bin/env python3
"""
üéØ BERZERK BACKTESTER - Module de Validation de Performance
=====================================================

Ce module analyse les d√©cisions d'ACHAT stock√©es dans la base de donn√©es
et simule leur rentabilit√© pour valider la performance du syst√®me BERZERK.

Strat√©gie de test :
- P√©riode de d√©tention : 7 jours calendaires
- Prix d'achat : Ouverture du jour de bourse suivant la d√©cision
- Prix de vente : Ouverture du jour de bourse apr√®s 7 jours
- M√©triques calcul√©es : ROI, taux de r√©ussite, performance cumul√©e

Auteur : BERZERK System
Date : 2024-01-XX
"""

import json
import sqlite3
import sys
from datetime import datetime, timedelta

import yfinance as yf

# Configuration
HOLDING_PERIOD_DAYS = 7
DATABASE_PATH = "berzerk.db"


class BerzerkBacktester:
    """
    Classe principale pour le backtesting des d√©cisions BERZERK
    """

    def __init__(self, db_path: str = DATABASE_PATH):
        self.db_path = db_path
        self.results = []

    def get_buy_decisions(self) -> list[dict]:
        """
        R√©cup√®re toutes les d√©cisions d'ACHAT de la base de donn√©es
        """
        print("üîç Recherche des d√©cisions d'ACHAT dans la base de donn√©es...")

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # R√©cup√©rer tous les articles avec d√©cisions
        cursor.execute(
            """
            SELECT id, title, link, published_date, decision_json
            FROM articles
            WHERE decision_json IS NOT NULL
            AND status = "analyzed"
            ORDER BY published_date DESC
        """
        )

        rows = cursor.fetchall()
        conn.close()

        buy_decisions = []

        for row in rows:
            article_id, title, link, published_date, decision_json = row

            try:
                decision = json.loads(decision_json)

                # Nouveau format : chercher dans 'action'
                action = decision.get("action", "").upper()

                # V√©rifier si c'est une d√©cision d'ACHAT
                if action in ["ACHETER", "ACHAT", "BUY"]:
                    ticker = decision.get("ticker")

                    if ticker:  # Seulement si on a un ticker valide
                        buy_decisions.append(
                            {
                                "article_id": article_id,
                                "title": title,
                                "link": link,
                                "ticker": ticker,
                                "decision_date": datetime.fromisoformat(published_date),
                                "action": action,
                                "justification": decision.get(
                                    "justification", "Aucune justification"
                                ),
                                "allocation": decision.get(
                                    "allocation_pourcentage", 0.0
                                ),
                                "confiance": decision.get("confiance", "INCONNUE"),
                            }
                        )
                        print(
                            f"‚úÖ D√©cision d'ACHAT trouv√©e: {ticker} ({title[:30]}...)"
                        )
                    else:
                        print(f"‚ö†Ô∏è  D√©cision d'ACHAT sans ticker: {title[:30]}...")
                else:
                    print(f"üìä D√©cision {action}: {title[:30]}...")

            except json.JSONDecodeError as e:
                print(f"‚ùå Erreur JSON pour l'article {article_id}: {e}")
            except Exception as e:
                print(f"‚ùå Erreur lors du traitement de l'article {article_id}: {e}")

        print(f"\nüìà {len(buy_decisions)} d√©cision(s) d'ACHAT trouv√©e(s)")
        return buy_decisions

    def get_next_trading_day(self, date: datetime) -> datetime:
        """
        Trouve le prochain jour de bourse apr√®s une date donn√©e

        Args:
            date: Date de d√©part

        Returns:
            datetime: Prochain jour de bourse
        """
        # Commencer par le jour suivant
        next_day = date + timedelta(days=1)

        # √âviter les weekends (lundi = 0, dimanche = 6)
        while next_day.weekday() >= 5:  # 5 = samedi, 6 = dimanche
            next_day += timedelta(days=1)

        return next_day

    def simulate_trade(self, trade: dict) -> dict | None:
        """
        Simule un trade individuel avec la strat√©gie de d√©tention de 7 jours

        Args:
            trade: Dictionnaire contenant les infos du trade

        Returns:
            Dict: R√©sultat de la simulation ou None si erreur
        """
        ticker = trade["ticker"]
        decision_date = trade["decision_date"]

        print(
            f"üìä Simulation du trade {ticker} (d√©cision du {decision_date.strftime('%Y-%m-%d')})"
        )

        try:
            # Dates de trading avec ajustement pour les dates tr√®s r√©centes
            buy_date = self.get_next_trading_day(decision_date)
            sell_date = self.get_next_trading_day(
                buy_date + timedelta(days=HOLDING_PERIOD_DAYS)
            )

            # P√©riode de t√©l√©chargement des donn√©es avec marge √©tendue
            start_date = buy_date - timedelta(
                days=10
            )  # Plus de marge pour les dates r√©centes
            end_date = datetime.now() + timedelta(
                days=2
            )  # Utiliser date actuelle + marge

            print(
                f"   üìÖ P√©riode de donn√©es: {start_date.strftime('%Y-%m-%d')} ‚Üí {end_date.strftime('%Y-%m-%d')}"
            )

            # T√©l√©charger les donn√©es historiques
            stock = yf.Ticker(ticker)
            hist = stock.history(start=start_date, end=end_date)

            if hist.empty:
                print(f"‚ùå Pas de donn√©es historiques pour {ticker}")
                return None

            print(f"   üìä {len(hist)} jours de donn√©es r√©cup√©r√©s")

            # Trouver les prix d'achat et de vente
            buy_price = None
            sell_price = None
            actual_buy_date = None
            actual_sell_date = None

            # Prix d'achat : premier prix d'ouverture disponible >= buy_date
            for date, row in hist.iterrows():
                if date.date() >= buy_date.date():
                    buy_price = row["Open"]
                    actual_buy_date = date
                    print(
                        f"   üí∞ Prix d'achat trouv√©: {buy_price:.2f} USD le {date.strftime('%Y-%m-%d')}"
                    )
                    break

            # Si pas de prix d'achat exact, prendre le dernier prix disponible
            if buy_price is None:
                if not hist.empty:
                    last_row = hist.iloc[-1]
                    buy_price = last_row["Close"]  # Utiliser le prix de cl√¥ture
                    actual_buy_date = hist.index[-1]
                    print(
                        f"   üí∞ Prix d'achat (dernier disponible): {buy_price:.2f} USD le {actual_buy_date.strftime('%Y-%m-%d')}"
                    )
                else:
                    print(f"‚ùå Impossible de trouver un prix d'achat pour {ticker}")
                    return None

            # Prix de vente : chercher le prix apr√®s la p√©riode de d√©tention
            if datetime.now().date() < sell_date.date():
                # Si la date de vente est dans le futur, utiliser le prix actuel
                try:
                    current_info = stock.info
                    sell_price = current_info.get("regularMarketPrice", buy_price)
                    actual_sell_date = datetime.now()
                    print(
                        f"   üìà Prix de vente (actuel): {sell_price:.2f} USD le {actual_sell_date.strftime('%Y-%m-%d')}"
                    )
                except Exception:
                    # Si pas d'info actuelle, utiliser le dernier prix historique
                    sell_price = hist.iloc[-1]["Close"]
                    actual_sell_date = hist.index[-1]
                    print(
                        f"   üìà Prix de vente (dernier historique): {sell_price:.2f} USD le {actual_sell_date.strftime('%Y-%m-%d')}"
                    )
            else:
                # Prix de vente normal : chercher dans l'historique
                for date, row in hist.iterrows():
                    if date.date() >= sell_date.date():
                        sell_price = row["Open"]
                        actual_sell_date = date
                        print(
                            f"   üìà Prix de vente trouv√©: {sell_price:.2f} USD le {date.strftime('%Y-%m-%d')}"
                        )
                        break

                # Si pas trouv√©, utiliser le dernier prix disponible
                if sell_price is None:
                    sell_price = hist.iloc[-1]["Close"]
                    actual_sell_date = hist.index[-1]
                    print(
                        f"   üìà Prix de vente (dernier disponible): {sell_price:.2f} USD le {actual_sell_date.strftime('%Y-%m-%d')}"
                    )

            if buy_price is None or sell_price is None:
                print(f"‚ùå Impossible de trouver les prix pour {ticker}")
                return None

            # Calculer la performance
            roi_percent = ((sell_price - buy_price) / buy_price) * 100

            result = {
                "ticker": ticker,
                "title": (
                    trade["title"][:50] + "..."
                    if len(trade["title"]) > 50
                    else trade["title"]
                ),
                "decision_date": decision_date,
                "buy_date": actual_buy_date,
                "sell_date": actual_sell_date,
                "buy_price": round(buy_price, 2),
                "sell_price": round(sell_price, 2),
                "roi_percent": round(roi_percent, 2),
                "allocation": trade["allocation"],
                "is_profitable": roi_percent > 0,
                "is_partial_simulation": datetime.now().date()
                < sell_date.date(),  # Indicateur si simulation partielle
            }

            status = "‚úÖ PROFIT" if roi_percent > 0 else "‚ùå PERTE"
            partial_note = (
                " (‚ö†Ô∏è Simulation partielle)" if result["is_partial_simulation"] else ""
            )
            print(f"üíπ {ticker}: {roi_percent:+.2f}% {status}{partial_note}")

            return result

        except Exception as e:
            print(f"‚ùå Erreur simulation {ticker}: {e}")
            return None

    def run_backtest(self) -> dict:
        """
        Ex√©cute le backtest complet et g√©n√®re le rapport de performance

        Returns:
            Dict: R√©sultats complets du backtest
        """
        print("üöÄ D√âMARRAGE DU BACKTEST BERZERK")
        print("=" * 60)

        # √âtape 1 : Extraire les d√©cisions d'ACHAT
        buy_decisions = self.get_buy_decisions()

        if not buy_decisions:
            print("‚ùå Aucune d√©cision d'ACHAT trouv√©e dans la base de donn√©es")
            return {"error": "No buy decisions found"}

        # √âtape 2 : Simuler chaque trade
        print(f"\nüéØ Simulation de {len(buy_decisions)} trades...")
        print("-" * 60)

        successful_trades = []
        failed_trades = []

        for trade in buy_decisions:
            result = self.simulate_trade(trade)
            if result:
                successful_trades.append(result)
            else:
                failed_trades.append(trade)

        # √âtape 3 : Calculer les m√©triques
        if not successful_trades:
            print("‚ùå Aucun trade n'a pu √™tre simul√©")
            return {"error": "No successful simulations"}

        # M√©triques de performance
        total_trades = len(successful_trades)
        winning_trades = [t for t in successful_trades if t["is_profitable"]]
        losing_trades = [t for t in successful_trades if not t["is_profitable"]]

        win_rate = (len(winning_trades) / total_trades) * 100
        avg_roi = sum(t["roi_percent"] for t in successful_trades) / total_trades
        total_roi = sum(t["roi_percent"] for t in successful_trades)

        best_trade = max(successful_trades, key=lambda x: x["roi_percent"])
        worst_trade = min(successful_trades, key=lambda x: x["roi_percent"])

        # Stocker les r√©sultats
        self.results = successful_trades

        return {
            "total_trades": total_trades,
            "successful_simulations": len(successful_trades),
            "failed_simulations": len(failed_trades),
            "winning_trades": len(winning_trades),
            "losing_trades": len(losing_trades),
            "win_rate": round(win_rate, 2),
            "avg_roi": round(avg_roi, 2),
            "total_roi": round(total_roi, 2),
            "best_trade": best_trade,
            "worst_trade": worst_trade,
            "trades": successful_trades,
        }

    def display_results(self, results: dict):
        """
        Affiche le rapport de performance format√©

        Args:
            results: R√©sultats du backtest
        """
        if "error" in results:
            print(f"‚ùå Erreur : {results['error']}")
            return

        print("\n" + "=" * 60)
        print("üìà RAPPORT DE PERFORMANCE BERZERK")
        print("=" * 60)

        # Statistiques globales
        print("\nüìä STATISTIQUES GLOBALES")
        print("-" * 30)
        print(f"Total des trades simul√©s    : {results['total_trades']}")
        print(f"Simulations r√©ussies       : {results['successful_simulations']}")
        print(f"Simulations √©chou√©es       : {results['failed_simulations']}")
        print(f"Trades gagnants            : {results['winning_trades']}")
        print(f"Trades perdants            : {results['losing_trades']}")
        print(f"Taux de r√©ussite           : {results['win_rate']:.2f}%")
        print(f"ROI moyen par trade        : {results['avg_roi']:+.2f}%")
        print(f"ROI total cumul√©           : {results['total_roi']:+.2f}%")

        # Meilleurs et pires trades
        print("\nüèÜ MEILLEUR TRADE")
        print("-" * 20)
        best = results["best_trade"]
        print(f"Ticker  : {best['ticker']}")
        print(f"ROI     : {best['roi_percent']:+.2f}%")
        print(
            f"Achat   : {best['buy_price']:.2f} USD le {best['buy_date'].strftime('%Y-%m-%d')}"
        )
        print(
            f"Vente   : {best['sell_price']:.2f} USD le {best['sell_date'].strftime('%Y-%m-%d')}"
        )

        print("\nüìâ PIRE TRADE")
        print("-" * 15)
        worst = results["worst_trade"]
        print(f"Ticker  : {worst['ticker']}")
        print(f"ROI     : {worst['roi_percent']:+.2f}%")
        print(
            f"Achat   : {worst['buy_price']:.2f} USD le {worst['buy_date'].strftime('%Y-%m-%d')}"
        )
        print(
            f"Vente   : {worst['sell_price']:.2f} USD le {worst['sell_date'].strftime('%Y-%m-%d')}"
        )

        # D√©tail de tous les trades
        print("\nüìã D√âTAIL DE TOUS LES TRADES")
        print("-" * 40)
        for trade in results["trades"]:
            status = "‚úÖ" if trade["is_profitable"] else "‚ùå"
            print(
                f"{status} {trade['ticker']:<6} | {trade['roi_percent']:+6.2f}% | "
                f"{trade['buy_date'].strftime('%Y-%m-%d')} ‚Üí {trade['sell_date'].strftime('%Y-%m-%d')} | "
                f"{trade['title']}"
            )

        # Conclusions
        print("\nüéØ CONCLUSIONS")
        print("-" * 15)
        if results["win_rate"] > 60:
            print(
                "üî• Performance EXCELLENTE ! Le syst√®me montre une tr√®s bonne capacit√© pr√©dictive."
            )
        elif results["win_rate"] > 50:
            print("üëç Performance POSITIVE. Le syst√®me bat le hasard.")
        else:
            print("‚ö†Ô∏è  Performance √Ä AM√âLIORER. Revoir les strat√©gies d'analyse.")

        if results["avg_roi"] > 2:
            print("üí∞ ROI moyen tr√®s attractif pour une strat√©gie √† 7 jours.")
        elif results["avg_roi"] > 0:
            print("üìà ROI moyen positif, strat√©gie rentable.")
        else:
            print("üìâ ROI moyen n√©gatif, n√©cessite des ajustements.")


def main():
    """
    Fonction principale du backtester
    """
    print("üéØ BERZERK BACKTESTER - Validation de Performance")
    print("=" * 60)

    # V√©rifier les pr√©requis
    import importlib.util
    
    missing_modules = []
    for module in ["pandas", "yfinance"]:
        if importlib.util.find_spec(module) is None:
            missing_modules.append(module)
    
    if missing_modules:
        print(f"‚ùå Erreur : Modules manquants {missing_modules}")
        print("üí° Installez les d√©pendances : pip install yfinance pandas")
        sys.exit(1)

    # Lancer le backtester
    backtester = BerzerkBacktester()
    results = backtester.run_backtest()
    backtester.display_results(results)

    print(f"\nüîÑ Backtest termin√© ! P√©riode test√©e : {HOLDING_PERIOD_DAYS} jours")
    print("üìä Utilisez ces r√©sultats pour am√©liorer les strat√©gies BERZERK.")


if __name__ == "__main__":
    main()
</file>

<file path="berzerk_dashboard_old.py">
#!/usr/bin/env python3
"""
üéØ BERZERK COMMAND CENTER - Dashboard Professionnel
===================================================

Interface Streamlit avanc√©e pour visualiser et analyser les performances
du syst√®me BERZERK avec tableaux de bord interactifs et analytics.

Fonctionnalit√©s:
- üìà Live Feed: Analyses en temps r√©el avec cartes interactives
- üèÜ Performance & Backtest: M√©triques de performance et backtesting
- üìä Graphiques interactifs avec Plotly
- üé® Interface moderne avec couleurs et ic√¥nes
- ‚ö° Cache optimis√© pour performances

Usage: streamlit run berzerk_dashboard.py
"""

import json
import sqlite3
import time
from datetime import datetime, timedelta

import pandas as pd
import plotly.graph_objects as go
import streamlit as st
import yfinance as yf

# Configuration de la page simplifi√©e
st.set_page_config(
    page_title="BERZERK - Centre de Contr√¥le",
    page_icon="‚ö°",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# En-t√™te principal SIMPLE et CLAIR
st.markdown(
    """
<div class="main-header">
    <h1 style="color: white; font-size: 2.5rem; margin: 0; font-weight: 700;">
        ‚ö° BERZERK Command Center
    </h1>
    <p style="color: rgba(255,255,255,0.9); font-size: 1.2rem; margin: 0.5rem 0 0 0;">
        Intelligence Artificielle ‚Ä¢ Analyse d'Actualit√©s Financi√®res ‚Ä¢ D√©cisions d'Investissement
    </p>
</div>
""",
    unsafe_allow_html=True,
)

# Styles CSS ULTRA SIMPLES - Fond blanc, texte lisible
st.markdown(
    """
<style>
    /* Fond g√©n√©ral blanc */
    .main {
        background-color: #ffffff !important;
        color: #333333 !important;
    }

    /* Supprimer le fond sombre de Streamlit */
    .stApp {
        background-color: #ffffff !important;
    }

    /* En-t√™te avec couleurs douces */
    .main-header {
        background: linear-gradient(135deg, #4285f4, #34a853);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
        color: white !important;
    }

    /* Cartes avec bordures color√©es et fond blanc */
    .metric-card {
        background: #ffffff !important;
        border: 2px solid #e8f0fe;
        border-left: 5px solid #4285f4;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        color: #333333 !important;
    }

    .metric-card h3 {
        color: #1a73e8 !important;
        font-size: 1.1rem !important;
        margin-bottom: 0.5rem !important;
    }

    /* Cartes d'articles avec fond blanc */
    .article-card {
        background: #ffffff !important;
        border: 1px solid #dadce0;
        border-radius: 8px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        color: #333333 !important;
    }

    /* Titre d'article en noir */
    .article-title {
        color: #202124 !important;
        font-size: 1.2rem !important;
        font-weight: 600 !important;
        margin-bottom: 0.8rem !important;
        line-height: 1.4 !important;
    }

    /* M√©ta infos en gris */
    .article-meta {
        color: #5f6368 !important;
        font-size: 0.9rem !important;
        margin-bottom: 1rem !important;
    }

    /* Badges d'action plus simples */
    .badge-acheter {
        background: #34a853 !important;
        color: white !important;
        padding: 0.7rem 1.5rem !important;
        border-radius: 6px !important;
        font-weight: bold !important;
        font-size: 1rem !important;
        display: inline-block !important;
        margin-bottom: 1rem !important;
    }

    .badge-surveiller {
        background: #fbbc04 !important;
        color: #333333 !important;
        padding: 0.7rem 1.5rem !important;
        border-radius: 6px !important;
        font-weight: bold !important;
        font-size: 1rem !important;
        display: inline-block !important;
        margin-bottom: 1rem !important;
    }

    .badge-vendre {
        background: #ea4335 !important;
        color: white !important;
        padding: 0.7rem 1.5rem !important;
        border-radius: 6px !important;
        font-weight: bold !important;
        font-size: 1rem !important;
        display: inline-block !important;
        margin-bottom: 1rem !important;
    }

    .badge-ignorer {
        background: #9aa0a6 !important;
        color: white !important;
        padding: 0.7rem 1.5rem !important;
        border-radius: 6px !important;
        font-weight: bold !important;
        font-size: 1rem !important;
        display: inline-block !important;
        margin-bottom: 1rem !important;
    }

    /* M√©triques en ligne plus visibles */
    .inline-metric {
        background: #f8f9fa !important;
        border: 1px solid #e0e0e0 !important;
        padding: 0.8rem !important;
        border-radius: 6px !important;
        margin: 0.3rem !important;
        color: #333333 !important;
        font-size: 0.9rem !important;
    }

    .inline-metric strong {
        color: #1a73e8 !important;
    }

    /* Section headers plus clairs */
    .section-header {
        background: #f8f9fa !important;
        border: 1px solid #e0e0e0 !important;
        border-left: 4px solid #4285f4 !important;
        padding: 1rem 1.5rem !important;
        border-radius: 6px !important;
        margin: 1.5rem 0 1rem 0 !important;
        color: #333333 !important;
    }

    .section-header h3 {
        color: #1a73e8 !important;
        margin: 0 !important;
    }

    /* Am√©liorer les selectbox */
    .stSelectbox > div > div {
        background-color: #ffffff !important;
        border: 2px solid #dadce0 !important;
        border-radius: 6px !important;
        color: #333333 !important;
    }

    /* Forcer le texte en noir partout */
    .stMarkdown, .stText, p, span, div {
        color: #333333 !important;
    }

    /* Onglets plus visibles */
    .stTabs [data-baseweb="tab-list"] {
        background-color: #f8f9fa !important;
        border-radius: 6px !important;
        padding: 0.5rem !important;
    }

    .stTabs [data-baseweb="tab"] {
        background-color: transparent !important;
        color: #5f6368 !important;
        font-weight: 500 !important;
    }

    .stTabs [data-baseweb="tab"][aria-selected="true"] {
        background-color: #ffffff !important;
        color: #1a73e8 !important;
        font-weight: 600 !important;
    }
</style>
""",
    unsafe_allow_html=True,
)

# =============================================================================
# FONCTIONS DE CACHE ET DONN√âES
# =============================================================================


@st.cache_data(ttl=30)  # Cache pendant 30 secondes pour live feed
def get_articles_with_decisions():
    """R√©cup√®re tous les articles avec leurs d√©cisions"""
    conn = sqlite3.connect("berzerk.db")
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    cursor.execute(
        """
        SELECT * FROM articles
        ORDER BY published_date DESC
    """
    )

    articles = [dict(row) for row in cursor.fetchall()]
    conn.close()
    return articles


@st.cache_data(ttl=30)
def get_dashboard_stats():
    """R√©cup√®re les statistiques pour le tableau de bord - VERSION SIMPLIFI√âE"""
    try:
        conn = sqlite3.connect("berzerk.db")
        cursor = conn.cursor()

        # M√©triques principales
        cursor.execute("SELECT COUNT(*) FROM articles")
        total_articles = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM articles WHERE status = 'analyzed'")
        analyzed_articles = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM articles WHERE status = 'pending'")
        pending_articles = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM articles WHERE status = 'error'")
        error_count = cursor.fetchone()[0]

        # D√©cisions d'achat (recherche dans decision_json)
        cursor.execute(
            """
            SELECT COUNT(*) FROM articles
            WHERE status = 'analyzed'
            AND (decision_json LIKE '%"action": "ACHETER"%' OR decision_json LIKE '%"decision": "ACHETER"%')
        """
        )
        buy_decisions = cursor.fetchone()[0]

        # Derni√®re analyse
        cursor.execute(
            """
            SELECT analyzed_at FROM articles
            WHERE status = 'analyzed' AND analyzed_at IS NOT NULL
            ORDER BY analyzed_at DESC LIMIT 1
        """
        )
        last_analysis = cursor.fetchone()

        # Calculer les minutes depuis la derni√®re analyse
        last_analysis_minutes = 999
        if last_analysis and last_analysis[0]:
            try:
                last_time = datetime.fromisoformat(last_analysis[0])
                time_diff = datetime.now() - last_time
                last_analysis_minutes = int(time_diff.total_seconds() // 60)
            except Exception:
                last_analysis_minutes = 999

        conn.close()

        return {
            "total_articles": total_articles,
            "analyzed_articles": analyzed_articles,
            "pending_articles": pending_articles,
            "error_count": error_count,
            "buy_decisions": buy_decisions,
            "last_analysis_minutes": last_analysis_minutes,
        }

    except Exception as e:
        st.error(f"Erreur lors de la r√©cup√©ration des statistiques: {e}")
        return {
            "total_articles": 0,
            "analyzed_articles": 0,
            "pending_articles": 0,
            "error_count": 0,
            "buy_decisions": 0,
            "last_analysis_minutes": 999,
        }


@st.cache_data(ttl=300)  # Cache pendant 5 minutes
def get_backtest_data():
    """R√©cup√®re et traite les donn√©es de backtest"""
    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()

    # R√©cup√©rer les d√©cisions d'achat
    cursor.execute(
        """
        SELECT id, title, published_date, decision_json
        FROM articles
        WHERE decision_json IS NOT NULL
        AND status = "analyzed"
        ORDER BY published_date DESC
    """
    )

    rows = cursor.fetchall()
    conn.close()

    buy_decisions = []

    for row in rows:
        article_id, title, published_date, decision_json = row

        try:
            decision = json.loads(decision_json)
            action = decision.get("action", decision.get("decision", "")).upper()

            if action in ["ACHETER", "ACHAT", "BUY"]:
                ticker = decision.get("ticker")

                if ticker:
                    buy_decisions.append(
                        {
                            "article_id": article_id,
                            "title": title,
                            "ticker": ticker,
                            "decision_date": datetime.fromisoformat(published_date),
                            "action": action,
                            "justification": decision.get(
                                "justification", "Aucune justification"
                            ),
                            "allocation": decision.get(
                                "allocation_pourcentage",
                                decision.get("allocation_percent", 0.0),
                            ),
                            "confiance": decision.get(
                                "confiance", decision.get("confidence", "INCONNUE")
                            ),
                        }
                    )
        except Exception:
            continue

    return buy_decisions


def simulate_trade_performance(
    ticker: str, decision_date: datetime, holding_days: int = 7
) -> dict | None:
    """Simule la performance d'un trade"""
    try:
        # Calculer les dates
        buy_date = decision_date + timedelta(days=1)
        sell_date = buy_date + timedelta(days=holding_days)

        # T√©l√©charger les donn√©es
        stock = yf.Ticker(ticker)
        start_date = buy_date - timedelta(days=10)
        end_date = datetime.now() + timedelta(days=2)

        hist = stock.history(start=start_date, end=end_date)

        if hist.empty:
            return None

        # Trouver les prix
        buy_price = None
        sell_price = None

        # Prix d'achat
        for date, row in hist.iterrows():
            if date.date() >= buy_date.date():
                buy_price = row["Open"]
                break

        if buy_price is None:
            buy_price = hist.iloc[-1]["Close"]

        # Prix de vente
        if datetime.now().date() < sell_date.date():
            sell_price = hist.iloc[-1]["Close"]
        else:
            for date, row in hist.iterrows():
                if date.date() >= sell_date.date():
                    sell_price = row["Open"]
                    break

            if sell_price is None:
                sell_price = hist.iloc[-1]["Close"]

        # Calculer la performance
        roi_percent = ((sell_price - buy_price) / buy_price) * 100

        return {
            "ticker": ticker,
            "buy_price": round(buy_price, 2),
            "sell_price": round(sell_price, 2),
            "roi_percent": round(roi_percent, 2),
            "is_profitable": roi_percent > 0,
            "decision_date": decision_date,
            "buy_date": buy_date,
            "sell_date": sell_date,
        }

    except Exception:
        return None


# =============================================================================
# FONCTIONS D'AFFICHAGE
# =============================================================================


def parse_decision_json(decision_json: str) -> dict:
    """Parse le JSON de d√©cision de mani√®re s√©curis√©e"""
    if not decision_json:
        return {}
    try:
        return json.loads(decision_json)
    except Exception:
        return {}


def get_decision_color(action: str) -> str:
    """Retourne la couleur associ√©e √† une action"""
    colors = {
        "ACHETER": "#28a745",
        "VENDRE": "#dc3545",
        "SURVEILLER": "#ffc107",
        "IGNORER": "#6c757d",
    }
    return colors.get(action, "#6c757d")


def display_simple_article_card(article: dict):
    """Affiche une carte d'article ULTRA SIMPLE et LISIBLE"""
    decision = parse_decision_json(article.get("decision_json", "{}"))

    # Container principal
    st.markdown('<div class="article-card">', unsafe_allow_html=True)

    # TITRE de l'article (gros et lisible)
    title = article["title"]
    if len(title) > 80:
        title = title[:80] + "..."

    st.markdown(f'<div class="article-title">{title}</div>', unsafe_allow_html=True)

    # INFOS RAPIDES
    source = article.get("source", "Bloomberg")
    date_str = article.get("published_date", "")
    if date_str:
        try:
            date_obj = datetime.fromisoformat(date_str)
            date_display = date_obj.strftime("%d/%m √† %H:%M")
        except Exception:
            date_display = "Date inconnue"
    else:
        date_display = "Date inconnue"

    st.markdown(
        f'<div class="article-meta">üì∞ {source} ‚Ä¢ üìÖ {date_display}</div>',
        unsafe_allow_html=True,
    )

    # CONTENU PRINCIPAL selon le statut
    if article["status"] == "analyzed" and decision:
        # === ARTICLE ANALYS√â ===

        # Action principale (gros badge visible)
        action = decision.get("action", decision.get("decision", "INCONNUE")).upper()
        ticker = decision.get("ticker", "N/A")

        if action == "ACHETER":
            badge_class = "badge-acheter"
            message = "‚úÖ ACHETER"
            if ticker != "N/A":
                message += f" ‚Ä¢ {ticker}"
        elif action == "SURVEILLER":
            badge_class = "badge-surveiller"
            message = "üëÄ SURVEILLER"
            if ticker != "N/A":
                message += f" ‚Ä¢ {ticker}"
        elif action == "VENDRE":
            badge_class = "badge-vendre"
            message = "‚ùå VENDRE"
            if ticker != "N/A":
                message += f" ‚Ä¢ {ticker}"
        else:
            badge_class = "badge-ignorer"
            message = "‚ö™ IGNORER"

        st.markdown(
            f'<div class="{badge_class}">{message}</div>', unsafe_allow_html=True
        )

        # D√©tails importants (3 colonnes)
        col1, col2, col3 = st.columns(3)

        with col1:
            confidence = decision.get("confidence", decision.get("confiance", "N/A"))
            st.markdown(
                f'<div class="inline-metric"><strong>Confiance:</strong><br/>{confidence}</div>',
                unsafe_allow_html=True,
            )

        with col2:
            allocation = decision.get(
                "allocation_pourcentage", decision.get("allocation_percent", 0.0)
            )
            st.markdown(
                f'<div class="inline-metric"><strong>Allocation:</strong><br/>{allocation}%</div>',
                unsafe_allow_html=True,
            )

        with col3:
            if ticker != "N/A":
                st.markdown(
                    f'<div class="inline-metric"><strong>Titre:</strong><br/>{ticker}</div>',
                    unsafe_allow_html=True,
                )
            else:
                st.markdown(
                    '<div class="inline-metric"><strong>Statut:</strong><br/>Pas de titre</div>',
                    unsafe_allow_html=True,
                )

        # Justification (simple)
        justification = decision.get("justification", "")
        if len(justification) > 20:
            with st.expander("üìã Voir le raisonnement complet"):
                st.write(justification)

    else:
        # === ARTICLE NON ANALYS√â ===
        if article["status"] == "pending":
            st.markdown("**üïí EN ATTENTE D'ANALYSE**")
            st.info("Cet article sera analys√© bient√¥t.")
        elif article["status"] == "in_progress":
            st.markdown("**‚ö° ANALYSE EN COURS**")
            st.info("L'IA analyse cet article maintenant.")
        elif article["status"] == "error":
            st.markdown("**‚ùå ERREUR**")
            st.error("Probl√®me lors de l'analyse.")
        else:
            st.markdown(f'**‚ùì STATUT: {article["status"].upper()}**')

    st.markdown("</div>", unsafe_allow_html=True)
    st.markdown("---")  # S√©parateur visible


def display_live_feed_tab():
    """Affiche l'onglet Live Feed ultra-simplifi√©"""

    # R√©cup√©ration des statistiques
    stats = get_dashboard_stats()

    # EN-T√äTE SIMPLE
    st.markdown("# üìà Analyses en Temps R√©el")
    st.markdown("Surveillance automatique des actualit√©s financi√®res Bloomberg")
    st.markdown("---")

    # Controls rapides
    col1, col2 = st.columns([1, 3])

    with col1:
        if st.button("üîÑ Actualiser", type="primary"):
            st.cache_data.clear()
            st.rerun()

    with col2:
        auto_refresh = st.checkbox(
            "üîÅ Auto-actualisation",
            value=False,
            help="Actualise automatiquement toutes les 30 secondes",
        )
        if auto_refresh:
            time.sleep(30)
            st.rerun()

    # TABLEAU DE BORD SIMPLE
    st.markdown("## üìä Situation Actuelle")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(
            "üì∞ Articles Total",
            stats["total_articles"],
            help="Nombre total d'articles dans la base",
        )

    with col2:
        analyzed_count = stats["analyzed_articles"]
        st.metric("‚úÖ Analys√©s", analyzed_count, help="Articles analys√©s par l'IA")

    with col3:
        buy_count = stats.get("buy_decisions", 0)
        st.metric(
            "üéØ Opportunit√©s", buy_count, help="Recommandations d'achat d√©tect√©es"
        )

    # FILTRES SIMPLES
    st.markdown("---")
    st.markdown("## üîç Filtres")

    col1, col2 = st.columns(2)

    with col1:
        show_filter = st.selectbox(
            "Afficher:",
            [
                "Tous les articles",
                "Seulement les analys√©s",
                "Seulement les recommandations d'achat",
            ],
        )

    with col2:
        period_filter = st.selectbox(
            "P√©riode:", ["Toutes", "Derni√®res 24h", "Cette semaine"]
        )

    # R√âCUP√âRATION ET FILTRAGE DES ARTICLES
    articles = get_articles_with_decisions()

    # Application des filtres
    if show_filter == "Seulement les analys√©s":
        articles = [a for a in articles if a["status"] == "analyzed"]
    elif show_filter == "Seulement les recommandations d'achat":
        articles = [
            a
            for a in articles
            if a["status"] == "analyzed"
            and "ACHETER" in str(a.get("decision_json", ""))
        ]

    if period_filter != "Toutes":
        days_map = {"Derni√®res 24h": 1, "Cette semaine": 7}
        days = days_map[period_filter]
        cutoff_date = datetime.now() - timedelta(days=days)
        articles = [
            a
            for a in articles
            if datetime.fromisoformat(a.get("published_date", "1970-01-01"))
            > cutoff_date
        ]

    # AFFICHAGE DES ARTICLES
    st.markdown("---")
    st.markdown(f"## üìã Articles ({len(articles)} r√©sultats)")

    if len(articles) == 0:
        st.info("üîç Aucun article trouv√© avec ces filtres.")
    else:
        for article in articles:
            display_simple_article_card(article)


def display_performance_tab():
    """Affiche l'onglet Performance & Backtest"""
    st.markdown(
        '<div class="main-header"><h1>üèÜ Performance & Backtest</h1></div>',
        unsafe_allow_html=True,
    )

    # Boutons de contr√¥le
    col1, col2 = st.columns([1, 5])

    with col1:
        if st.button("üîÑ Actualiser Performance", type="primary"):
            st.cache_data.clear()
            st.rerun()

    # R√©cup√©ration des donn√©es de backtest
    buy_decisions = get_backtest_data()

    if not buy_decisions:
        st.warning("Aucune d√©cision d'achat trouv√©e pour effectuer le backtest.")
        return

    st.info(f"üìä {len(buy_decisions)} d√©cisions d'achat trouv√©es pour le backtest")

    # Simulation des trades
    with st.spinner("üîÑ Simulation des trades en cours..."):
        trade_results = []

        progress_bar = st.progress(0)

        for i, decision in enumerate(buy_decisions):
            result = simulate_trade_performance(
                decision["ticker"], decision["decision_date"]
            )

            if result:
                result.update(
                    {
                        "title": decision["title"],
                        "allocation": decision["allocation"],
                        "confidence": decision["confiance"],
                    }
                )
                trade_results.append(result)

            progress_bar.progress((i + 1) / len(buy_decisions))

        progress_bar.empty()

    if not trade_results:
        st.error("Aucun trade n'a pu √™tre simul√©.")
        return

    # Calcul des KPIs
    total_trades = len(trade_results)
    winning_trades = len([t for t in trade_results if t["is_profitable"]])
    losing_trades = total_trades - winning_trades
    win_rate = (winning_trades / total_trades) * 100 if total_trades > 0 else 0

    total_roi = sum(t["roi_percent"] for t in trade_results)
    avg_roi = total_roi / total_trades if total_trades > 0 else 0

    best_trade = max(trade_results, key=lambda x: x["roi_percent"])
    worst_trade = min(trade_results, key=lambda x: x["roi_percent"])

    # A. KPIs de Performance
    st.markdown("### üìà KPIs de Performance")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "üéØ Taux de R√©ussite",
            f"{win_rate:.1f}%",
            delta=f"{winning_trades}/{total_trades}",
            help="Pourcentage de trades rentables",
        )

    with col2:
        st.metric(
            "üìä ROI Moyen",
            f"{avg_roi:+.2f}%",
            help="Retour sur investissement moyen par trade",
        )

    with col3:
        st.metric(
            "‚úÖ Trades Gagnants", winning_trades, help="Nombre de trades profitables"
        )

    with col4:
        st.metric("‚ùå Trades Perdants", losing_trades, help="Nombre de trades en perte")

    # B. Graphique de Performance Cumul√©e
    st.markdown("### üìà Performance Cumul√©e")

    # Calcul de la performance cumul√©e
    cumulative_performance = []
    capital = 100  # Capital initial de 100‚Ç¨

    for i, trade in enumerate(trade_results):
        capital = capital * (1 + trade["roi_percent"] / 100)
        cumulative_performance.append(
            {
                "Trade": i + 1,
                "Capital": capital,
                "Date": trade["decision_date"],
                "Ticker": trade["ticker"],
                "ROI": trade["roi_percent"],
            }
        )

    df_perf = pd.DataFrame(cumulative_performance)

    # Graphique Plotly
    fig = go.Figure()

    fig.add_trace(
        go.Scatter(
            x=df_perf["Trade"],
            y=df_perf["Capital"],
            mode="lines+markers",
            name="Capital Cumul√©",
            line={"color": "#2a5298", "width": 3},
            marker={"size": 6},
            hovertemplate="<b>Trade %{x}</b><br>"
            + "Capital: %{y:.2f}‚Ç¨<br>"
            + "ROI: %{customdata:.2f}%<extra></extra>",
            customdata=df_perf["ROI"],
        )
    )

    fig.add_hline(
        y=100,
        line_dash="dash",
        line_color="gray",
        annotation_text="Capital Initial (100‚Ç¨)",
    )

    fig.update_layout(
        title="üöÄ √âvolution du Capital (100‚Ç¨ initial)",
        xaxis_title="Num√©ro de Trade",
        yaxis_title="Capital (‚Ç¨)",
        height=500,
        showlegend=True,
        hovermode="x unified",
    )

    st.plotly_chart(fig, use_container_width=True)

    # M√©triques finales
    final_capital = df_perf["Capital"].iloc[-1]
    total_return = ((final_capital - 100) / 100) * 100

    col1, col2 = st.columns(2)
    with col1:
        st.metric(
            "üí∞ Capital Final", f"{final_capital:.2f}‚Ç¨", delta=f"{total_return:+.2f}%"
        )

    with col2:
        st.metric(
            "üéØ Performance Totale",
            f"{total_return:+.2f}%",
            help="Performance totale depuis le d√©but",
        )

    # C. Tableau des Trades D√©taill√©s
    st.markdown("### üìã Tableau des Trades D√©taill√©s")

    # Pr√©paration du DataFrame
    df_trades = pd.DataFrame(trade_results)

    # Formatage des colonnes
    df_trades["decision_date"] = pd.to_datetime(df_trades["decision_date"]).dt.strftime(
        "%Y-%m-%d"
    )
    df_trades["buy_date"] = pd.to_datetime(df_trades["buy_date"]).dt.strftime(
        "%Y-%m-%d"
    )
    df_trades["Performance"] = df_trades["roi_percent"].apply(lambda x: f"{x:+.2f}%")

    # S√©lection des colonnes √† afficher
    display_columns = [
        "ticker",
        "title",
        "decision_date",
        "buy_price",
        "sell_price",
        "Performance",
        "confidence",
    ]
    df_display = df_trades[display_columns].copy()

    # Renommage des colonnes
    df_display.columns = [
        "Ticker",
        "Titre",
        "Date D√©cision",
        "Prix Achat",
        "Prix Vente",
        "Performance",
        "Confiance",
    ]

    # Style conditionnel
    def highlight_performance(row):
        if "Performance" in row:
            if "+" in str(row["Performance"]):
                return ["background-color: #d4edda"] * len(row)
            else:
                return ["background-color: #f8d7da"] * len(row)
        return [""] * len(row)

    # Affichage du tableau styl√©
    styled_df = df_display.style.apply(highlight_performance, axis=1)
    st.dataframe(styled_df, use_container_width=True, height=400)

    # D. Meilleurs et Pires Trades
    st.markdown("### üèÜ Meilleurs et Pires Trades")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### ü•á Meilleur Trade")
        st.success(f"**{best_trade['ticker']}** - {best_trade['roi_percent']:+.2f}%")
        st.write(f"üìÖ {best_trade['decision_date'].strftime('%Y-%m-%d')}")
        st.write(f"üí∞ {best_trade['buy_price']} ‚Üí {best_trade['sell_price']}")
        st.write(f"üì∞ {best_trade['title'][:50]}...")

    with col2:
        st.markdown("#### üìâ Pire Trade")
        st.error(f"**{worst_trade['ticker']}** - {worst_trade['roi_percent']:+.2f}%")
        st.write(f"üìÖ {worst_trade['decision_date'].strftime('%Y-%m-%d')}")
        st.write(f"üí∞ {worst_trade['buy_price']} ‚Üí {worst_trade['sell_price']}")
        st.write(f"üì∞ {worst_trade['title'][:50]}...")


# =============================================================================
# INTERFACE PRINCIPALE
# =============================================================================


def main():
    """Interface principale du BERZERK Command Center"""

    # Navigation par onglets
    tab1, tab2 = st.tabs(["üìà Live Feed", "üèÜ Performance & Backtest"])

    with tab1:
        display_live_feed_tab()

    with tab2:
        display_performance_tab()


if __name__ == "__main__":
    main()
</file>

<file path="berzerk_lab.py">
import sqlite3
from datetime import datetime

import feedparser
import requests
import streamlit as st
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field

# LangChain Imports
from langchain_google_genai import ChatGoogleGenerativeAI

# NOUVEAU : Import depuis notre module d'agents
from agents import route_to_agents, run_agent_analysis

# --- CONFIGURATION & SETUP ---
load_dotenv()


def init_db():
    """Initialise la base de donn√©es SQLite et cr√©e la table articles."""
    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()
    # On cr√©e une table pour stocker les articles.
    # Le lien (link) est UNIQUE pour √©viter les doublons.
    cursor.execute(
        """
        CREATE TABLE IF NOT EXISTS articles (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            source TEXT NOT NULL,
            title TEXT NOT NULL,
            link TEXT NOT NULL UNIQUE,
            published_str TEXT,
            published_date DATETIME NOT NULL,
            fetched_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            status TEXT DEFAULT 'pending',
            decision_json TEXT,
            analyzed_at DATETIME
        )
    """
    )

    # Ajouter les nouvelles colonnes si elles n'existent pas (pour les anciennes bases)
    try:
        cursor.execute("ALTER TABLE articles ADD COLUMN status TEXT DEFAULT 'pending'")
    except sqlite3.OperationalError:
        pass  # La colonne existe d√©j√†

    try:
        cursor.execute("ALTER TABLE articles ADD COLUMN decision_json TEXT")
    except sqlite3.OperationalError:
        pass  # La colonne existe d√©j√†

    try:
        cursor.execute("ALTER TABLE articles ADD COLUMN analyzed_at DATETIME")
    except sqlite3.OperationalError:
        pass  # La colonne existe d√©j√†

    conn.commit()
    conn.close()


# D√©finition de la structure de sortie attendue
class Analysis(BaseModel):
    resume: str = Field(description="R√©sum√© de la news en 3 phrases maximum.")
    impact: int = Field(
        description="Note d'impact de 1 (faible) √† 10 (tr√®s fort) sur les march√©s."
    )
    evaluation: str = Field(
        description="Une cha√Æne de caract√®res: 'Positif', 'N√©gatif' ou 'Neutre'."
    )
    entites: list[str] = Field(
        description="Liste de tickers d'actions (ex: ['AAPL', 'TSLA']), de noms de soci√©t√©s et de secteurs concern√©s."
    )


# Initialisation du mod√®le LLM via LangChain
try:
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-lite-preview-06-17", temperature=0
    )
except Exception as e:
    st.error(
        f"Erreur d'initialisation du mod√®le LangChain. V√©rifiez votre GOOGLE_API_KEY. Erreur: {e}"
    )
    llm = None

# Liste des flux RSS fonctionnels (apr√®s notre diagnostic)
RSS_FEEDS = {"Bloomberg": "https://feeds.bloomberg.com/markets/news.rss"}

# --- FONCTIONS CORE ---


def fetch_and_store_news(feeds):
    """Parcourt les flux RSS et ins√®re les nouveaux articles dans la DB."""
    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    new_articles_found = 0
    for source, url in feeds.items():
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                feed = feedparser.parse(response.content)
                for entry in feed.entries:
                    # On r√©cup√®re la date et on la convertit en objet datetime
                    # feedparser a une structure pratique pour √ßa dans "published_parsed"
                    published_tuple = entry.get("published_parsed")
                    if published_tuple:
                        dt_object = datetime(*published_tuple[:6])
                    else:
                        dt_object = datetime.now()  # Fallback si pas de date

                    # INSERT OR IGNORE est la cl√© : il n'ins√®re que si le lien n'existe pas d√©j√†
                    cursor.execute(
                        """
                        INSERT OR IGNORE INTO articles (source, title, link, published_str, published_date)
                        VALUES (?, ?, ?, ?, ?)
                    """,
                        (
                            source,
                            entry.title,
                            entry.link,
                            entry.get("published", "N/A"),
                            dt_object,
                        ),
                    )

                    if cursor.rowcount > 0:
                        new_articles_found += 1

        except Exception as e:
            print(f"Erreur lors de la r√©cup√©ration du flux de {source}: {e}")

    conn.commit()
    conn.close()
    return new_articles_found


def get_articles_from_db():
    """R√©cup√®re tous les articles de la DB, tri√©s par date de publication."""
    conn = sqlite3.connect("berzerk.db")
    # On force la connexion √† retourner des dictionnaires au lieu de tuples, c'est plus pratique
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    cursor.execute("SELECT * FROM articles ORDER BY published_date DESC")
    articles = [dict(row) for row in cursor.fetchall()]

    conn.close()
    return articles


def get_article_text(url):
    # (Cette fonction ne change pas)
    try:
        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        soup = BeautifulSoup(response.content, "html.parser")
        paragraphs = soup.find_all("p")
        article_text = " ".join([p.get_text() for p in paragraphs])
        return article_text
    except Exception as e:
        print(f"Erreur de r√©cup√©ration de l'article √† l'URL {url}: {e}")
        return None


def analyze_news_with_llm(article_text: str):
    """Analyse un article en utilisant une cha√Æne LangChain."""
    if not llm or not article_text:
        return None

    parser = JsonOutputParser(pydantic_object=Analysis)
    prompt_template = """Tu es un analyste financier expert pour le syst√®me BERSERK. Analyse l'article de presse suivant et extrais les informations cl√©s.
    {format_instructions}
    Voici l'article :
    ---
    {article}
    ---"""
    prompt = PromptTemplate(
        template=prompt_template,
        input_variables=["article"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
    )
    chain = prompt | llm | parser

    try:
        analysis_result = chain.invoke({"article": article_text})
        return analysis_result
    except Exception as e:
        st.error(f"Erreur lors de l'ex√©cution de la cha√Æne LangChain : {e}")
        return None


# --- INTERFACE UTILISATEUR (STREAMLIT) ---

st.set_page_config(page_title="BERSERK Labo", layout="wide")
st.title("üìò BERSERK - Labo d'Analyse (Phase 2)")
st.caption("Moteur: LangChain + Gemini + Agents IA | Monitoring: LangSmith")

# NOUVEAU : On initialise la DB au d√©marrage de l'app
init_db()

if "articles" not in st.session_state:
    # Au premier chargement, on remplit la liste depuis la DB
    st.session_state.articles = get_articles_from_db()
if "selected_article_link" not in st.session_state:
    st.session_state.selected_article_link = None
if "analysis_result" not in st.session_state:
    st.session_state.analysis_result = None

# NOUVEAU : Ajouter ces lignes pour g√©rer l'√©tat des agents
if "agent_team" not in st.session_state:
    st.session_state.agent_team = None
if "agent_analyses" not in st.session_state:
    st.session_state.agent_analyses = None

left_column, right_column = st.columns([1, 2])

with left_column:
    st.header("Flux d'actualit√©s")

    if st.button("üîÑ Charger les derni√®res actualit√©s", use_container_width=True):
        with st.spinner("Recherche de nouveaux articles..."):
            # 1. On cherche et stocke les nouveaux articles
            new_count = fetch_and_store_news(RSS_FEEDS)
            st.toast(f"{new_count} nouvel(s) article(s) trouv√©(s) !")
            # 2. On recharge la liste COMPL√àTE et TRI√âE depuis la DB
            st.session_state.articles = get_articles_from_db()
            st.session_state.selected_article_link = None
            st.session_state.analysis_result = None
            # NOUVEAU : R√©initialiser aussi les agents
            st.session_state.agent_team = None
            st.session_state.agent_analyses = None
        st.rerun()

    # On affiche les articles de st.session_state, qui est maintenant toujours tri√©
    if st.session_state.articles:
        for article in st.session_state.articles:
            with st.container(border=True):
                st.markdown(f"**{article['title']}**")

                # NOUVEAU : On affiche la source et l'heure de publication
                # On reformate l'objet datetime pour un affichage lisible
                pub_date = datetime.fromisoformat(article["published_date"])
                st.caption(
                    f"Source: {article['source']} | Publi√© le: {pub_date.strftime('%d/%m/%Y √† %H:%M')}"
                )

                if st.button("ü§ñ Analyser", key=article["link"]):
                    st.session_state.selected_article_link = article["link"]
                    st.session_state.analysis_result = None
                    # NOUVEAU : R√©initialiser aussi les agents
                    st.session_state.agent_team = None
                    st.session_state.agent_analyses = None
                    st.rerun()
    else:
        st.info(
            "Aucun article en base. Cliquez sur 'Charger les derni√®res actualit√©s' pour commencer."
        )

with right_column:
    st.header("üî¨ Analyse de l'IA")

    if st.session_state.selected_article_link:
        if st.session_state.analysis_result is None:
            with st.spinner("Analyse en cours (LangChain)..."):
                link = st.session_state.selected_article_link
                text = get_article_text(link)
                if text:
                    st.session_state.analysis_result = analyze_news_with_llm(text)
                else:
                    st.session_state.analysis_result = {"error": "Contenu inaccessible"}
            st.rerun()

        analysis = st.session_state.analysis_result
        if analysis:
            if "error" in analysis:
                st.error(analysis["error"])
            else:
                st.success("Analyse termin√©e !")

                # MISE EN FORME COMME SUR TON SCREENSHOT
                st.subheader("üìù R√©sum√©")
                st.write(analysis.get("resume", "N/A"))

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("√âvaluation", analysis.get("evaluation", "N/A"))
                with col2:
                    st.metric("Impact Potentiel", f"{analysis.get('impact', 0)}/10")

                st.subheader("üìà Entit√©s Concern√©es")
                # st.write(analysis.get('entites', [])) # Moins joli
                st.json(analysis.get("entites", []))  # Plus joli

                st.divider()  # Ajoute une ligne de s√©paration visuelle

                # --- NOUVELLE SECTION : ORCHESTRATION DES AGENTS ---

                # Si l'√©quipe n'a pas encore √©t√© recrut√©e, afficher le bouton
                if st.session_state.agent_team is None:
                    if st.button(
                        "üë• Recruter l'√âquipe d'Agents Sp√©cialis√©s",
                        use_container_width=True,
                    ):
                        with st.spinner("Le Chef d'Orchestre recrute l'√©quipe..."):
                            # On r√©cup√®re les entit√©s et le r√©sum√© de l'analyse initiale
                            entities = analysis.get("entites", [])
                            summary = analysis.get("resume", "")
                            # On appelle notre routeur intelligent
                            st.session_state.agent_team = route_to_agents(
                                entities, summary
                            )
                        st.rerun()

                # Si l'√©quipe est recrut√©e, on l'affiche et on lance les analyses
                if st.session_state.agent_team is not None:
                    st.subheader("üë• √âquipe d'Agents Recrut√©e")

                    # Afficher l'√©quipe
                    for agent in st.session_state.agent_team:
                        st.info(
                            f"**{agent['agent_type'].replace('_', ' ').title()}** recrut√© avec le focus : *{agent['focus']}*"
                        )

                    # Si les analyses ne sont pas encore faites, afficher le bouton pour les lancer
                    if st.session_state.agent_analyses is None:
                        if st.button(
                            "üöÄ Lancer les Analyses de l'√âquipe",
                            type="primary",
                            use_container_width=True,
                        ):
                            st.session_state.agent_analyses = []

                            # On r√©cup√®re le texte complet de l'article UNE SEULE FOIS
                            full_text = get_article_text(
                                st.session_state.selected_article_link
                            )

                            if full_text:
                                # On boucle sur chaque agent recrut√© pour lancer son analyse
                                with st.spinner(
                                    "Les agents travaillent... Cette op√©ration peut prendre un certain temps."
                                ):
                                    for agent in st.session_state.agent_team:
                                        # On appelle la fonction d'ex√©cution de notre module agents.py
                                        single_analysis = run_agent_analysis(
                                            agent_type=agent["agent_type"],
                                            focus=agent["focus"],
                                            news_summary=analysis.get("resume", ""),
                                            full_article_text=full_text,
                                        )
                                        st.session_state.agent_analyses.append(
                                            {
                                                "agent_type": agent["agent_type"],
                                                "focus": agent["focus"],
                                                "analysis": single_analysis,
                                            }
                                        )
                            else:
                                st.error(
                                    "Impossible de r√©cup√©rer le texte complet de l'article pour les agents."
                                )
                                st.session_state.agent_analyses = (
                                    []
                                )  # Pour √©viter de relancer
                            st.rerun()

                # Si les analyses sont termin√©es, on les affiche
                if st.session_state.agent_analyses is not None:
                    st.subheader("üìù Debriefing de l'√âquipe")
                    for result in st.session_state.agent_analyses:
                        with st.expander(
                            f"**Analyse du {result['agent_type'].replace('_', ' ').title()}** - Focus : *{result['focus']}*"
                        ):
                            st.markdown(result["analysis"])
    else:
        st.info("Cliquez sur 'Analyser' sur une news pour commencer.")
</file>

<file path="diagnostic_db.py">
#!/usr/bin/env python3
"""
üîç DIAGNOSTIC BASE DE DONN√âES BERZERK
====================================
Script simple pour analyser les d√©cisions stock√©es
"""

import json
import sqlite3


def diagnostic_db():
    """Analyse le contenu de la base de donn√©es"""
    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()

    # Compter les articles avec d√©cisions
    cursor.execute("SELECT COUNT(*) FROM articles WHERE decision_json IS NOT NULL")
    total_analyzed = cursor.fetchone()[0]

    # Compter les articles avec statut "analyzed"
    cursor.execute('SELECT COUNT(*) FROM articles WHERE status = "analyzed"')
    status_analyzed = cursor.fetchone()[0]

    print(f"üìä Total articles avec d√©cisions: {total_analyzed}")
    print(f"üìä Articles avec statut 'analyzed': {status_analyzed}")

    # Examiner les d√©cisions
    cursor.execute(
        "SELECT id, title, decision_json FROM articles WHERE decision_json IS NOT NULL LIMIT 5"
    )
    decisions = cursor.fetchall()

    print(f"\nüîç √âchantillon de {len(decisions)} d√©cisions:")
    print("-" * 60)

    achat_count = 0
    for article_id, title, decision_json in decisions:
        print(f"\nüì∞ Article {article_id}: {title[:50]}...")
        try:
            decision = json.loads(decision_json)

            # V√©rifier le format de la d√©cision
            if isinstance(decision, dict):
                action = decision.get("action", "N/A")
                ticker = decision.get("ticker", "N/A")

                print(f"   üéØ Action: {action}")
                print(f"   üìà Ticker: {ticker}")

                if action and action.upper() == "ACHETER":
                    achat_count += 1
                    print("   ‚úÖ D√âCISION D'ACHAT TROUV√âE!")

            else:
                print(f"   ‚ö†Ô∏è  Format inattendu: {type(decision)}")

        except json.JSONDecodeError as e:
            print(f"   ‚ùå Erreur JSON: {e}")

    print(f"\nüìà R√©sum√©: {achat_count} d√©cision(s) d'ACHAT trouv√©e(s)")

    conn.close()


if __name__ == "__main__":
    diagnostic_db()
</file>

<file path="real_time_rss_monitor.py">
#!/usr/bin/env python3
"""
üöÄ BERZERK Real-Time RSS Monitor - Surveillance RSS Quasi-Instantan√©e
=====================================================================

Ce syst√®me avanc√© surveille les flux RSS en temps quasi-r√©el avec :
- Polling haute fr√©quence (30-60 secondes)
- Optimisations HTTP (ETags, Last-Modified, conditional requests)
- Threading asynchrone pour √©viter les blocages
- D√©tection intelligente des changements
- Analyse automatique instantan√©e

Architecture Temps R√©el :
- Pas d'attente bloquante (utilise threading)
- R√©activit√© √©v√©nementielle
- Gestion des erreurs robuste
- Int√©gration avec le pipeline BERZERK existant

Usage: python real_time_rss_monitor.py [poll_interval_seconds]
Arr√™t: Ctrl+C
"""

import hashlib
import json
import sqlite3
import sys
import threading
import time
from dataclasses import dataclass
from datetime import datetime
from email.utils import parsedate_to_datetime

import feedparser
import requests

# Import des modules BERZERK
from berzerk_lab import RSS_FEEDS, init_db
from orchestrator import run_berzerk_pipeline


@dataclass
class FeedState:
    """√âtat d'un flux RSS avec optimisations HTTP"""

    url: str
    last_modified: str | None = None
    etag: str | None = None
    last_check: datetime | None = None
    last_content_hash: str | None = None
    consecutive_errors: int = 0
    # articles_cache supprim√© - causait des doublons apr√®s red√©marrage

    def should_check(self, min_interval: int) -> bool:
        """D√©termine si le flux doit √™tre v√©rifi√© maintenant"""
        if self.last_check is None:
            return True

        # Algorithme adaptatif : plus d'erreurs = moins de v√©rifications
        if self.consecutive_errors > 0:
            penalty = min(self.consecutive_errors * 30, 300)  # Max 5 minutes de penalty
            return (datetime.now() - self.last_check).total_seconds() > (
                min_interval + penalty
            )

        return (datetime.now() - self.last_check).total_seconds() >= min_interval


class RealTimeRSSMonitor:
    """Surveillant RSS temps r√©el avec optimisations avanc√©es"""

    def __init__(self, poll_interval: int = 30, capital: float = 25000.0):
        self.poll_interval = poll_interval  # En secondes
        self.capital = capital
        self.feeds_state: dict[str, FeedState] = {}
        self.running = False
        self.processed_articles: set[str] = set()
        self.stats = {
            "total_checks": 0,
            "new_articles_found": 0,
            "analyses_completed": 0,
            "errors": 0,
            "start_time": datetime.now(),
        }

        # Configuration des requ√™tes HTTP optimis√©es
        self.session = requests.Session()
        self.session.headers.update(
            {
                "User-Agent": "BERZERK-RSS-Monitor/1.0 (Real-Time News Analysis)",
                "Accept": "application/rss+xml, application/xml, text/xml",
                "Accept-Encoding": "gzip, deflate",
                "Connection": "keep-alive",
            }
        )

        # Initialisation
        self.init_feeds_state()
        self.load_processed_articles()

        print("üöÄ BERZERK Real-Time RSS Monitor initialis√©")
        print(f"   ‚ö° Polling: {poll_interval} secondes (haute fr√©quence)")
        print(f"   üìà Flux RSS: {len(RSS_FEEDS)} source (Bloomberg uniquement)")
        for feed_name, feed_url in RSS_FEEDS.items():
            print(f"   üì° {feed_name}: {feed_url}")
        print(f"   üí∞ Capital: {capital:,.2f}‚Ç¨")
        print("   üîÑ Optimisations: ETags, Last-Modified, Threading")
        print(f"   üìä Articles d√©j√† trait√©s: {len(self.processed_articles)}")
        print("-" * 70)

    def init_feeds_state(self):
        """Initialise l'√©tat de chaque flux RSS"""
        for _feed_name, feed_url in RSS_FEEDS.items():
            self.feeds_state[feed_url] = FeedState(url=feed_url)

    def load_processed_articles(self):
        """Charge les articles d√©j√† trait√©s depuis la base de donn√©es"""
        try:
            conn = sqlite3.connect("berzerk.db")
            cursor = conn.cursor()
            # Charger TOUS les articles existants (peu importe le statut)
            cursor.execute("SELECT link FROM articles")
            self.processed_articles = {row[0] for row in cursor.fetchall()}
            conn.close()

            self.log(f"üì• {len(self.processed_articles)} articles existants charg√©s")
            self.log("üéØ Seuls les vrais nouveaux articles RSS seront trait√©s")
        except Exception as e:
            self.log(f"‚ö†Ô∏è Erreur lors du chargement des articles trait√©s: {e}")
            self.processed_articles = set()

    def log(self, message: str, level: str = "INFO"):
        """Logger avec timestamp et niveau"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        level_emoji = {
            "INFO": "‚ÑπÔ∏è",
            "SUCCESS": "‚úÖ",
            "WARNING": "‚ö†Ô∏è",
            "ERROR": "‚ùå",
            "DETECTION": "üîç",
        }.get(level, "üìù")
        print(f"‚ö° [{timestamp}] {level_emoji} {message}")

    def calculate_content_hash(self, content: str) -> str:
        """Calcule un hash du contenu pour d√©tecter les changements"""
        return hashlib.md5(content.encode("utf-8")).hexdigest()

    def check_feed_optimized(self, feed_state: FeedState) -> list[dict]:
        """V√©rifie un flux RSS avec optimisations HTTP"""
        try:
            headers = {}

            # Optimisations HTTP conditionnelles
            if feed_state.etag:
                headers["If-None-Match"] = feed_state.etag
            if feed_state.last_modified:
                headers["If-Modified-Since"] = feed_state.last_modified

            # Requ√™te HTTP avec timeout court
            response = self.session.get(feed_state.url, headers=headers, timeout=10)

            feed_state.last_check = datetime.now()
            self.stats["total_checks"] += 1

            # Gestion des codes de statut HTTP
            if response.status_code == 304:
                # Not Modified - aucun changement
                self.log(f"üîÑ Pas de changement: {feed_state.url[:50]}...")
                feed_state.consecutive_errors = 0
                return []

            if response.status_code != 200:
                raise Exception(f"HTTP {response.status_code}")

            # Mise √† jour des m√©tadonn√©es de cache
            feed_state.etag = response.headers.get("ETag")
            feed_state.last_modified = response.headers.get("Last-Modified")

            # V√©rification du hash du contenu
            content_hash = self.calculate_content_hash(response.text)
            if feed_state.last_content_hash == content_hash:
                self.log(f"üîÑ Contenu identique: {feed_state.url[:50]}...")
                feed_state.consecutive_errors = 0
                return []

            feed_state.last_content_hash = content_hash

            # Parsing RSS
            feed = feedparser.parse(response.text)

            if feed.bozo:
                self.log(f"‚ö†Ô∏è Feed mal form√©: {feed_state.url[:50]}...")

            # Filtrage des nouveaux articles - LOGIQUE SIMPLIFI√âE
            new_articles = []
            for entry in feed.entries:
                article_link = entry.get("link", "")

                # ‚úÖ CORRECTION : Ne v√©rifier que processed_articles (pas articles_cache)
                if article_link and article_link not in self.processed_articles:

                    # Marquer imm√©diatement comme trait√© pour √©viter les doublons
                    self.processed_articles.add(article_link)

                    # Extraction des m√©tadonn√©es
                    published_date = None
                    if hasattr(entry, "published_parsed") and entry.published_parsed:
                        published_date = datetime(*entry.published_parsed[:6])
                    elif hasattr(entry, "published"):
                        try:
                            published_date = parsedate_to_datetime(entry.published)
                        except Exception:
                            published_date = datetime.now()
                    else:
                        published_date = datetime.now()

                    article = {
                        "title": entry.get("title", "Titre non disponible"),
                        "link": article_link,
                        "published_date": published_date,
                        "summary": entry.get("summary", ""),
                        "source": feed_state.url,
                        "discovered_at": datetime.now(),
                    }

                    new_articles.append(article)

            # Succ√®s - reset des erreurs
            feed_state.consecutive_errors = 0

            if new_articles:
                self.log(
                    f"üéØ {len(new_articles)} VRAIS nouveaux articles d√©tect√©s sur {feed_state.url[:50]}...",
                    "DETECTION",
                )
                self.stats["new_articles_found"] += len(new_articles)

            return new_articles

        except Exception as e:
            feed_state.consecutive_errors += 1
            self.stats["errors"] += 1
            self.log(f"‚ùå Erreur sur {feed_state.url[:50]}: {e}")
            return []

    def store_article(self, article: dict):
        """Stocke un article dans la base de donn√©es"""
        try:
            conn = sqlite3.connect("berzerk.db")
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT OR IGNORE INTO articles
                (title, link, published_date, source, status, published_str)
                VALUES (?, ?, ?, ?, 'pending', ?)
            """,
                (
                    article["title"],
                    article["link"],
                    article["published_date"].isoformat(),
                    article["source"],
                    article.get(
                        "summary", "RSS Feed"
                    ),  # Utilise summary comme published_str
                ),
            )

            conn.commit()
            conn.close()

            if cursor.rowcount > 0:
                self.log(f"üíæ Article stock√©: {article['title'][:50]}...")

        except Exception as e:
            self.log(f"‚ùå Erreur stockage: {e}")

    def analyze_article_realtime(self, article: dict) -> dict | None:
        """Analyse un article en temps r√©el avec le pipeline BERZERK"""
        try:
            self.log(f"ü§ñ Analyse TEMPS R√âEL: {article['title'][:50]}...")

            # Lancement du pipeline complet
            result = run_berzerk_pipeline(article["link"], self.capital)

            if result and "final_decision" in result:
                # Sauvegarde de la d√©cision
                self.save_decision_to_db(article["link"], result["final_decision"])

                # Marquer comme trait√©
                self.processed_articles.add(article["link"])

                # Statistiques
                self.stats["analyses_completed"] += 1

                # Affichage du r√©sultat
                decision = result["final_decision"]
                action = decision.get("decision", "INCONNU")

                if action == "ACHETER":
                    self.log(
                        f"üöÄ ACHAT IDENTIFI√â: {article['title'][:50]}...", "SUCCESS"
                    )
                    ticker = decision.get("ticker_cible", "N/A")
                    allocation = decision.get("allocation_pourcentage", 0)
                    self.log(f"   üí∞ Ticker: {ticker}, Allocation: {allocation}%")
                elif action == "SURVEILLER":
                    self.log(f"üëÄ SURVEILLANCE: {article['title'][:50]}...")
                else:
                    self.log(f"‚úÖ Analyse termin√©e: {action}")

                return result
            else:
                self.log(f"‚ö†Ô∏è √âchec d'analyse: {article['title'][:50]}...")
                return None

        except Exception as e:
            self.log(f"‚ùå Erreur analyse temps r√©el: {e}")
            return None

    def save_decision_to_db(self, article_link: str, decision: dict):
        """Sauvegarde la d√©cision dans la base de donn√©es"""
        try:
            conn = sqlite3.connect("berzerk.db")
            cursor = conn.cursor()

            cursor.execute(
                """
                UPDATE articles
                SET decision_json = ?,
                    status = 'analyzed',
                    analyzed_at = ?
                WHERE link = ?
            """,
                (
                    json.dumps(decision, ensure_ascii=False),
                    datetime.now().isoformat(),
                    article_link,
                ),
            )

            conn.commit()
            conn.close()

        except Exception as e:
            self.log(f"‚ùå Erreur sauvegarde d√©cision: {e}")

    def monitoring_thread(self):
        """Thread principal de surveillance"""
        self.log("üîÑ Thread de surveillance d√©marr√©")

        while self.running:
            try:
                # V√©rifier chaque flux RSS
                for _feed_url, feed_state in self.feeds_state.items():
                    if not self.running:
                        break

                    # V√©rifier si le flux doit √™tre contr√¥l√©
                    if feed_state.should_check(self.poll_interval):
                        new_articles = self.check_feed_optimized(feed_state)

                        # Traiter les nouveaux articles
                        for article in new_articles:
                            if not self.running:
                                break

                            # Stockage en base
                            self.store_article(article)

                            # Analyse imm√©diate en arri√®re-plan
                            threading.Thread(
                                target=self.analyze_article_realtime,
                                args=(article,),
                                daemon=True,
                            ).start()

                # Pause courte avant le prochain cycle
                time.sleep(1)

            except Exception as e:
                self.log(f"‚ùå Erreur dans le thread de surveillance: {e}")
                time.sleep(5)  # Pause plus longue en cas d'erreur

        self.log("üõë Thread de surveillance arr√™t√©")

    def display_stats(self):
        """Affiche les statistiques en temps r√©el"""
        uptime = datetime.now() - self.stats["start_time"]

        print("\n" + "=" * 50)
        print("üìä STATISTIQUES TEMPS R√âEL")
        print("=" * 50)
        print(f"‚è±Ô∏è  Uptime: {uptime}")
        print(f"üîÑ V√©rifications totales: {self.stats['total_checks']}")
        print(f"üìà Nouveaux articles: {self.stats['new_articles_found']}")
        print(f"ü§ñ Analyses compl√®tes: {self.stats['analyses_completed']}")
        print(f"‚ùå Erreurs: {self.stats['errors']}")
        print(f"üíæ Articles en cache: {len(self.processed_articles)}")
        print("=" * 50)

    def start(self):
        """D√©marre la surveillance temps r√©el"""
        self.log("üöÄ D√âMARRAGE DE LA SURVEILLANCE TEMPS R√âEL", "SUCCESS")
        self.log(f"‚ö° Polling: {self.poll_interval} secondes")
        self.log("‚èπÔ∏è  Arr√™t: Ctrl+C")

        # Initialiser la base de donn√©es
        init_db()

        # D√©marrer le thread de surveillance
        self.running = True
        monitor_thread = threading.Thread(target=self.monitoring_thread, daemon=True)
        monitor_thread.start()

        try:
            # Boucle principale avec affichage des stats
            while True:
                time.sleep(30)  # Afficher les stats toutes les 30 secondes
                self.display_stats()

        except KeyboardInterrupt:
            self.log("üõë Arr√™t demand√© par l'utilisateur", "WARNING")
        finally:
            self.running = False
            self.log("üëã Surveillance temps r√©el arr√™t√©e", "SUCCESS")
            self.display_stats()


def main():
    """Point d'entr√©e principal"""
    # Configuration par d√©faut
    poll_interval = 30  # 30 secondes par d√©faut
    capital = 25000.0

    # Parsing des arguments
    if len(sys.argv) > 1:
        try:
            poll_interval = int(sys.argv[1])
            if poll_interval < 10:
                raise ValueError("L'intervalle doit √™tre d'au moins 10 secondes")
        except ValueError as e:
            print(f"‚ùå Erreur: {e}")
            print("üí° Usage: python real_time_rss_monitor.py [poll_interval_seconds]")
            print("üìä Exemple: python real_time_rss_monitor.py 30")
            sys.exit(1)

    print("üöÄ BERZERK Real-Time RSS Monitor")
    print("‚ö° Surveillance quasi-instantan√©e avec polling optimis√©")
    print(f"üîÑ Intervalle: {poll_interval} secondes")
    print("-" * 70)

    # Lancement du monitor
    monitor = RealTimeRSSMonitor(poll_interval, capital)
    monitor.start()


if __name__ == "__main__":
    main()
</file>

<file path="requirements.txt">
# Core dependencies
streamlit>=1.30.0
langchain>=0.1.0
langchain-google-genai>=0.0.6
langchain-core>=0.1.0
google-generativeai>=0.3.0
python-dotenv>=1.0.0

# Web scraping and RSS
requests>=2.31.0
beautifulsoup4>=4.12.0
feedparser>=6.0.0

# Finance and data
yfinance>=0.2.0
pandas>=2.0.0

# Search and tools
tavily-python>=0.3.0

# Additional tools
langgraph>=0.0.30
langsmith>=0.0.40

# Utility
pydantic>=2.0.0
typing-extensions>=4.8.0

# Development dependencies (for CI/CD)
pytest>=7.0.0
pytest-mock>=3.12.0
black>=23.0.0
ruff>=0.1.0
</file>

<file path="reset_and_analyze.py">
#!/usr/bin/env python3
"""
üßπ BERZERK RESET & ANALYZE - Nettoyage et Relance des Analyses
==============================================================

Ce script nettoie les anciennes analyses et relance les 20 derni√®res
news avec les nouveaux agents augment√©s (Phase 5).
"""

import json
import sqlite3
from datetime import datetime

from orchestrator import run_berzerk_pipeline


def reset_analyses():
    """
    Nettoie les anciennes analyses de la base de donn√©es
    """
    print("üßπ Nettoyage des anciennes analyses...")

    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()

    # Remettre √† z√©ro les analyses
    cursor.execute(
        """
        UPDATE articles
        SET decision_json = NULL,
            status = "pending",
            analyzed_at = NULL
        WHERE decision_json IS NOT NULL
    """
    )

    updated = cursor.rowcount
    conn.commit()

    # Compter les articles en attente
    cursor.execute('SELECT COUNT(*) FROM articles WHERE status = "pending"')
    pending = cursor.fetchone()[0]

    conn.close()

    print(f"‚úÖ {updated} anciennes analyses supprim√©es")
    print(f"üìù {pending} articles en attente d'analyse")

    return pending


def get_latest_articles(limit=20):
    """
    R√©cup√®re les derniers articles en attente
    """
    print(f"üîç R√©cup√©ration des {limit} derniers articles...")

    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()

    cursor.execute(
        """
        SELECT id, title, link, published_date
        FROM articles
        WHERE status = "pending"
        ORDER BY published_date DESC
        LIMIT ?
    """,
        (limit,),
    )

    articles = cursor.fetchall()
    conn.close()

    print(f"‚úÖ {len(articles)} articles r√©cup√©r√©s")
    return articles


def save_decision_to_db(article_id: int, decision_result: dict) -> bool:
    """
    Sauvegarde une d√©cision d'investissement dans la base de donn√©es
    """
    try:
        conn = sqlite3.connect("berzerk.db")
        cursor = conn.cursor()

        # Extraire les informations cl√©s de la d√©cision
        final_decision = decision_result.get("final_decision", {})

        # Gestion des objets Pydantic pour final_decision
        if hasattr(final_decision, "decision"):
            # Objet Pydantic
            decision_action = final_decision.decision
            decision_ticker = final_decision.ticker
            decision_confiance = final_decision.confiance
            decision_justification = final_decision.justification_synthetique
            decision_allocation = final_decision.allocation_capital_pourcentage
            decision_positifs = final_decision.points_cles_positifs
            decision_negatifs = final_decision.points_cles_negatifs_risques
        else:
            # Dictionnaire classique
            decision_action = final_decision.get("decision", "ERREUR")
            decision_ticker = final_decision.get("ticker", None)
            decision_confiance = final_decision.get("confiance", "INCONNUE")
            decision_justification = final_decision.get(
                "justification_synthetique", "Aucune justification"
            )
            decision_allocation = final_decision.get(
                "allocation_capital_pourcentage", 0.0
            )
            decision_positifs = final_decision.get("points_cles_positifs", [])
            decision_negatifs = final_decision.get("points_cles_negatifs_risques", [])

        # Pr√©parer la d√©cision format√©e pour la base de donn√©es
        decision_data = {
            "action": decision_action,
            "ticker": decision_ticker,
            "confiance": decision_confiance,
            "justification": decision_justification,
            "allocation_pourcentage": decision_allocation,
            "points_positifs": decision_positifs,
            "points_negatifs": decision_negatifs,
            "tickers_identifies": decision_result.get("actionable_tickers", []),
            "timestamp": datetime.now().isoformat(),
        }

        # Sauvegarder dans la base de donn√©es
        cursor.execute(
            """
            UPDATE articles
            SET decision_json = ?,
                status = "analyzed",
                analyzed_at = ?
            WHERE id = ?
        """,
            (json.dumps(decision_data), datetime.now().isoformat(), article_id),
        )

        conn.commit()
        conn.close()

        return True

    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde: {e}")
        return False


def analyze_articles(articles):
    """
    Lance l'analyse des articles avec les nouveaux agents augment√©s
    """
    print("üöÄ Lancement des analyses avec les agents augment√©s...")
    print("-" * 60)

    successful_analyses = 0
    failed_analyses = 0
    saved_decisions = 0

    for i, (article_id, title, link, _published_date) in enumerate(articles, 1):
        print(f"\nüî¨ [{i}/{len(articles)}] Analyse: {title[:50]}...")

        try:
            # Simuler un capital de test
            capital = 10000

            # Lancer le pipeline BERZERK complet
            result = run_berzerk_pipeline(link, capital)

            if result and not result.get("error"):
                successful_analyses += 1
                print("‚úÖ Analyse termin√©e avec succ√®s")

                # Sauvegarder la d√©cision dans la base de donn√©es
                if save_decision_to_db(article_id, result):
                    saved_decisions += 1
                    print("üíæ D√©cision sauvegard√©e dans la base de donn√©es")

                    # Afficher la d√©cision si disponible
                    if result.get("final_decision"):
                        decision = result["final_decision"]
                        action = decision.get("decision", "N/A")
                        ticker = decision.get("ticker", "N/A")
                        allocation = decision.get("allocation_capital_pourcentage", 0)
                        print(f"üéØ D√©cision: {action} {ticker} ({allocation}%)")
                else:
                    print("‚ùå √âchec de la sauvegarde")
            else:
                failed_analyses += 1
                print(
                    f"‚ùå √âchec de l'analyse: {result.get('error', 'Erreur inconnue')}"
                )

        except Exception as e:
            failed_analyses += 1
            print(f"‚ùå Erreur lors de l'analyse: {e}")

    print("\nüìä R√âSULTATS DES ANALYSES")
    print("-" * 30)
    print(f"‚úÖ Analyses r√©ussies: {successful_analyses}")
    print(f"üíæ D√©cisions sauvegard√©es: {saved_decisions}")
    print(f"‚ùå Analyses √©chou√©es: {failed_analyses}")
    print(f"üìà Taux de r√©ussite: {(successful_analyses / len(articles)) * 100:.1f}%")

    return successful_analyses


def main():
    """
    Fonction principale
    """
    print("üéØ BERZERK RESET & ANALYZE")
    print("=" * 50)

    # √âtape 1: Nettoyer les anciennes analyses
    pending_count = reset_analyses()

    if pending_count == 0:
        print("‚ö†Ô∏è  Aucun article en attente d'analyse")
        return

    # √âtape 2: R√©cup√©rer les derniers articles
    articles = get_latest_articles(20)

    if not articles:
        print("‚ùå Aucun article trouv√©")
        return

    # √âtape 3: Analyser les articles
    successful = analyze_articles(articles)

    print("\nüèÅ TERMIN√â !")
    print(f"üìä {successful} nouvelles analyses avec agents augment√©s")
    print("üí° Vous pouvez maintenant relancer: python backtester.py")


if __name__ == "__main__":
    main()
</file>

<file path="start_realtime_monitor.py">
#!/usr/bin/env python3
"""
üöÄ Script de Lancement BERZERK Real-Time Monitor
===============================================

Ce script simplifie le lancement du syst√®me de surveillance RSS temps r√©el.
Il peut √©galement lancer le dashboard en parall√®le pour une visualisation compl√®te.

Usage:
    python start_realtime_monitor.py                    # Surveillance seule
    python start_realtime_monitor.py --with-dashboard   # Surveillance + Dashboard
    python start_realtime_monitor.py --interval 30      # Intervalle personnalis√©
"""

import os
import subprocess
import sys
import time
from datetime import datetime


def log(message: str):
    """Logger avec timestamp"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"üöÄ [{timestamp}] {message}")


def launch_dashboard():
    """Lance le dashboard Streamlit en arri√®re-plan"""
    try:
        log("Lancement du dashboard Streamlit...")

        # Lancer le dashboard
        process = subprocess.Popen(
            [
                sys.executable,
                "-m",
                "streamlit",
                "run",
                "berzerk_dashboard.py",
                "--server.headless",
                "true",
                "--server.port",
                "8501",
                "--browser.gatherUsageStats",
                "false",
            ],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
        )

        # Attendre quelques secondes pour voir si le lancement r√©ussit
        time.sleep(3)

        if process.poll() is None:
            log("‚úÖ Dashboard d√©marr√© sur http://localhost:8501")
            return process
        else:
            log("‚ùå √âchec du d√©marrage du dashboard")
            return None

    except Exception as e:
        log(f"‚ùå Erreur lors du lancement du dashboard: {e}")
        return None


def launch_realtime_monitor(interval: int = 30):
    """Lance le monitor temps r√©el"""
    try:
        log(f"Lancement du monitor temps r√©el (intervalle: {interval}s)...")

        # Lancer le monitor
        process = subprocess.Popen(
            [sys.executable, "real_time_rss_monitor.py", str(interval)]
        )

        return process

    except Exception as e:
        log(f"‚ùå Erreur lors du lancement du monitor: {e}")
        return None


def main():
    """Fonction principale"""

    # Configuration par d√©faut
    interval = 30
    with_dashboard = False

    # Parsing des arguments
    args = sys.argv[1:]

    i = 0
    while i < len(args):
        arg = args[i]

        if arg == "--with-dashboard":
            with_dashboard = True
        elif arg == "--interval":
            if i + 1 < len(args):
                try:
                    interval = int(args[i + 1])
                    i += 1  # Skip next argument
                except ValueError:
                    print("‚ùå Erreur: L'intervalle doit √™tre un nombre entier")
                    sys.exit(1)
            else:
                print("‚ùå Erreur: --interval n√©cessite une valeur")
                sys.exit(1)
        elif arg == "--help" or arg == "-h":
            print(__doc__)
            sys.exit(0)
        else:
            print(f"‚ùå Argument inconnu: {arg}")
            print("üí° Utilisez --help pour voir les options disponibles")
            sys.exit(1)

        i += 1

    # Affichage de la configuration
    print("\n" + "=" * 70)
    print("üöÄ BERZERK Real-Time Monitor - Lancement")
    print("=" * 70)
    print(f"‚ö° Intervalle de surveillance: {interval} secondes")
    print(f"üìä Dashboard inclus: {'Oui' if with_dashboard else 'Non'}")
    print("=" * 70)

    # V√©rification des pr√©requis
    if not os.path.exists("real_time_rss_monitor.py"):
        print("‚ùå Erreur: real_time_rss_monitor.py non trouv√©")
        sys.exit(1)

    if with_dashboard and not os.path.exists("berzerk_dashboard.py"):
        print("‚ùå Erreur: berzerk_dashboard.py non trouv√©")
        sys.exit(1)

    # Lancement des composants
    dashboard_process = None
    monitor_process = None

    try:
        # Lancer le dashboard si demand√©
        if with_dashboard:
            dashboard_process = launch_dashboard()
            if dashboard_process:
                time.sleep(2)  # Laisser le dashboard se stabiliser

        # Lancer le monitor temps r√©el
        monitor_process = launch_realtime_monitor(interval)

        if monitor_process:
            log("‚úÖ Monitor temps r√©el d√©marr√©")

            if with_dashboard:
                log("üåê Acc√©dez au dashboard: http://localhost:8501")

            log("‚èπÔ∏è  Appuyez sur Ctrl+C pour arr√™ter")

            # Attendre la fin du processus principal
            monitor_process.wait()
        else:
            log("‚ùå √âchec du d√©marrage du monitor")

    except KeyboardInterrupt:
        log("üõë Arr√™t demand√© par l'utilisateur")

    except Exception as e:
        log(f"‚ùå Erreur fatale: {e}")

    finally:
        # Nettoyage des processus
        if monitor_process and monitor_process.poll() is None:
            log("Arr√™t du monitor temps r√©el...")
            monitor_process.terminate()
            monitor_process.wait()

        if dashboard_process and dashboard_process.poll() is None:
            log("Arr√™t du dashboard...")
            dashboard_process.terminate()
            dashboard_process.wait()

        log("üëã Tous les processus arr√™t√©s")


if __name__ == "__main__":
    main()
</file>

<file path="test_feeds.py">
import feedparser
import requests

# D√©finition des flux RSS √† tester
RSS_FEEDS = {"Bloomberg": "https://feeds.bloomberg.com/markets/news.rss"}

print("--- Lancement du diagnostic des flux RSS ---")

# On boucle sur chaque flux pour le tester individuellement
for source, url in RSS_FEEDS.items():
    print(f"\n[TEST] Source : {source}")
    print(f"       URL    : {url}")

    try:
        # On simule un navigateur en ajoutant un User-Agent
        # C'est la correction la plus probable
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

        # On t√©l√©charge d'abord le contenu avec requests, qui permet de passer les headers
        response = requests.get(url, headers=headers, timeout=10)

        # On v√©rifie le code de statut HTTP. 200 = OK. 403 = Interdit. 404 = Non trouv√©.
        print(f"       Statut HTTP : {response.status_code}")

        if response.status_code == 200:
            # Si la requ√™te a r√©ussi, on donne le contenu √† feedparser
            feed = feedparser.parse(response.content)

            # On v√©rifie si feedparser a bien trouv√© des articles
            if feed.entries:
                print(f"       ‚úÖ SUCC√àS : {len(feed.entries)} article(s) trouv√©(s).")
            elif feed.bozo:
                # feed.bozo = 1 signifie que le flux est mal form√©
                print(
                    f"       ‚ö†Ô∏è AVERTISSEMENT : Le flux est mal form√©. Erreur : {feed.bozo_exception}"
                )
            else:
                print(
                    "       ‚ö†Ô∏è AVERTISSEMENT : Le flux est valide mais ne contient aucun article."
                )
        else:
            print(
                f"       ‚ùå √âCHEC : Le serveur a refus√© la connexion (Code {response.status_code}). Le flux est probablement prot√©g√© ou mort."
            )

    except Exception as e:
        print(f"       ‚ùå ERREUR : Impossible de se connecter au flux. Erreur : {e}")

print("\n--- Diagnostic termin√© ---")
</file>

<file path="suivi_projet.md">
# üìã Suivi du Projet BERZERK

## üìñ Description G√©n√©rale
**Objectif :** D√©velopper un syst√®me d'analyse automatis√©e d'actualit√©s financi√®res utilisant l'IA pour √©valuer l'impact des news sur les march√©s.

**Public cible :** Analystes financiers et investisseurs cherchant une aide √† la d√©cision rapide et fiable.

**Architecture :** Application Streamlit + LangChain + Gemini AI + Base de donn√©es SQLite

## üìã Plan de T√¢ches

### Phase 1 : Fondations 
- [x] Configuration LangChain + Gemini
- [x] Interface Streamlit basique
- [x] R√©cup√©ration flux RSS
- [x] Analyse LLM des articles
- [x] Int√©gration base de donn√©es SQLite

### Phase 2 : Agents IA Sp√©cialis√©s ‚úÖ
- [x] Cr√©ation module agents.py
- [x] Int√©gration agents dans interface principale
- [x] Agent Investisseur Final (Superviseur)
- [x] Pipeline automatis√© avec LangGraph

### Phase 2.3 : Automatisation Compl√®te ‚úÖ
- [x] Cr√©ation orchestrator.py avec LangGraph
- [x] Tests du pipeline automatis√©
- [x] Transformation du labo en moniteur temps r√©el

### Phase 3 : Architecture Service 24/7 ‚úÖ
- [x] Extension base de donn√©es avec colonnes de suivi
- [x] Service daemon berzerk_service.py
- [x] Surveillance automatique 24/7
- [x] Dashboard temps r√©el berzerk_dashboard.py
- [x] S√©paration backend/frontend

### Phase 4 : Am√©liorations Avanc√©es (√† venir)
- [ ] Filtrage avanc√© des articles
- [ ] Visualisations des tendances
- [ ] Export des r√©sultats
- [ ] API REST pour int√©grations externes

### Phase 5 : Surveillance RSS Temps R√©el ‚úÖ
- [x] Syst√®me de surveillance RSS quasi-instantan√© (30 secondes)
- [x] Optimisations HTTP (ETags, Last-Modified, codes 304)
- [x] Threading asynchrone pour analyses parall√®les
- [x] D√©tection intelligente via hash de contenu
- [x] Gestion d'erreurs adaptative
- [x] **CORRECTION CRITIQUE** : Logique de d√©tection des nouveaux articles simplifi√©e

### Phase 6 : Int√©gration et D√©ploiement Continus (CI/CD) ‚úÖ
- [x] Structure de tests et configuration pytest
- [x] Workflow GitHub Actions pour CI (tests, linting, formatage)
- [x] Tests unitaires avec mocks pour validation automatique
- [x] Workflow GitHub Actions pour CD (d√©ploiement automatis√©)
- [x] Scripts de d√©ploiement sur serveur de production
- [x] Configuration service systemd pour monitoring continu

### Phase 7 : Am√©liorations Avanc√©es (√† venir)
- [ ] Filtrage avanc√© des articles
- [ ] Visualisations des tendances
- [ ] Export des r√©sultats
- [ ] API REST pour int√©grations externes

## üìù Journal des Modifications

### 2024-12-29 - Impl√©mentation CI/CD : Int√©gration et D√©ploiement Continus ‚úÖ
**Objectif :** Automatiser les tests, la validation et le d√©ploiement pour garantir la qualit√© et la rapidit√© des mises √† jour.

**Philosophie DevOps :**
- **Continuous Integration (CI)** : Chaque push d√©clenche automatiquement des v√©rifications de qualit√© et tests
- **Continuous Deployment (CD)** : D√©ploiement automatique en production apr√®s validation CI r√©ussie

**Composants impl√©ment√©s :**
1. ‚úÖ **Pr√©paration de l'environnement** :
   - Ajout des d√©pendances de d√©veloppement (pytest, black, ruff, pytest-mock)
   - Cr√©ation de la structure de tests (`tests/unit/`, `tests/integration/`)
   - Configuration pytest.ini pour standardiser les tests

2. ‚úÖ **Int√©gration Continue (.github/workflows/ci.yml)** :
   - Workflow d√©clench√© sur push/PR vers main
   - Validation formatage avec Black (--check)
   - Linting avec Ruff pour la qualit√© du code
   - Ex√©cution des tests avec Pytest
   - Support multi-version Python (matrice avec Python 3.11)

3. ‚úÖ **Tests Unitaires** :
   - Premier test pour `route_to_agents()` avec mocks LLM
   - √âvite les co√ªts API durant les tests (simulation avec pytest-mock)
   - Structure extensible pour futurs tests

4. ‚úÖ **D√©ploiement Continu (.github/workflows/deploy.yml)** :
   - Workflow d√©clench√© uniquement apr√®s succ√®s de la CI
   - D√©ploiement SSH automatis√© sur serveur de production
   - Mise √† jour Git, d√©pendances et red√©marrage services
   - Gestion des secrets GitHub pour authentification

**Variables et Secrets requis :**
- **Variables GitHub** : `GOOGLE_API_KEY`, `TAVILY_API_KEY` (pour CI)
- **Secrets GitHub** : `PROD_HOST`, `PROD_USERNAME`, `PROD_SSH_KEY` (pour CD)

**R√©sultats :**
- **Qualit√© garantie** : Aucun code non test√© ou mal format√© ne peut atteindre main
- **D√©ploiement automatis√©** : Push ‚Üí Tests ‚Üí D√©ploiement en production
- **Z√©ro downtime** : Red√©marrage intelligent des services
- **√âvolutivit√©** : Structure pr√™te pour tests d'int√©gration et monitoring avanc√©

### 2024-12-29 - Correction Critique : Logique de Prix et Robustesse yfinance ‚úÖ
**Objectif :** R√©soudre les probl√®mes de prix identiques et d'erreurs yfinance sur tickers mal format√©s.

**Diagnostics identifi√©s :**
- **Probl√®me Logique** : Le "prix √† la d√©cision" et le "prix actuel" √©taient identiques car `get_price_at_decision_time()` r√©cup√©rait simplement le dernier prix disponible (prix actuel)
- **Probl√®me de Donn√©es** : L'IA g√©n√©rait parfois des tickers invalides (avec "$", espaces) causant des erreurs yfinance 404/delisted
- **Probl√®me d'Affichage** : La performance s'affichait m√™me avec des prix non fiables (0.00 ou identiques)

**Corrections impl√©ment√©es :**
1. ‚úÖ **Refonte logique de `get_price_at_decision_time()` - Version Optimis√©e** :
   - **Performance** : Utilise uniquement les donn√©es journali√®res (ultra-rapide, 1 seul appel r√©seau par ticker)
   - **Logique intelligente** : Prix de cl√¥ture du jour de d√©cision OU du jour pr√©c√©dent si march√© ferm√©
   - **R√©sout le blocage** : √âvite les appels lents `interval="1m"` qui bloquaient `load_decisions_from_db()`
   - Cache optimis√© (24h) car prix historique ne change pas
   - Nettoyage automatique des tickers (suppression des "$" et espaces)

2. ‚úÖ **Am√©lioration robustesse `get_current_price()`** :
   - Nettoyage automatique des tickers avant requ√™te yfinance
   - Priorit√© aux donn√©es intraday (interval="1m") pour prix plus r√©cent
   - Fallback robuste sur `regularMarketPrice`
   - Gestion silencieuse des erreurs sans crash

3. ‚úÖ **Renforcement `get_sparkline_chart()`** :
   - M√™me logique de nettoyage des tickers pour coh√©rence
   - Gestion d'erreurs am√©lior√©e

4. ‚úÖ **Affichage conditionnel de la performance** :
   - Section "Suivi de la Position" visible UNIQUEMENT si `prix_decision > 0` ET `prix_actuel > 0`
   - Remplacement du container HTML par `st.metric()` standard pour alignement
   - √âvite l'affichage de performances incorrectes (-100%) ou de 0.00

5. ‚úÖ **Renforcement du Ticker Hunter (agents.py)** :
   - R√®gles explicites dans le prompt : tickers = 1-5 lettres majuscules
   - Interdiction formelle des "$", espaces ou phrases
   - R√©duction anticip√©e des tickers mal format√©s √† la source

**R√©sultats attendus :**
- **Chargement ultra-rapide** du dashboard (r√©solution du blocage sur load_decisions_from_db)
- Prix de d√©cision pertinent = cl√¥ture du jour de d√©cision ou jour pr√©c√©dent si march√© ferm√©
- Affichage **instantan√©** de la section performance (prix quasi-syst√©matiquement disponible)
- R√©duction drastique des erreurs yfinance pour tickers invalides
- IA g√©n√©rant des tickers de meilleure qualit√©

**Tests √† effectuer :**
- V√©rifier chargement ultra-rapide du dashboard (plus de blocage)
- Contr√¥ler prix_decision coh√©rent (cl√¥ture jour de d√©cision ou jour pr√©c√©dent)
- V√©rifier affichage instantan√© de la section "Suivi de la Position"
- Tester avec tickers contenant "$" (doivent √™tre nettoy√©s automatiquement)

### 2024-12-07 - Transformation "Carte de Signal 2.0" ‚úÖ
**Objectif :** Transformer les cartes de d√©cision en interface professionnelle dense et intuitive avec informations contextuelles enrichies.

**Diagnostics identifi√©s :**
- Graphiques plats par manque de donn√©es et contexte visuel
- Horizon d'investissement souvent "N/A" ou non fourni par l'IA
- Absence de contexte m√©tier (secteur d'activit√©)
- Densit√© d'information sous-optimale

**Am√©liorations impl√©ment√©es :**
1. ‚úÖ **Am√©lioration du Cerveau IA** :
   - Modification du prompt `investisseur_final_template` pour exiger l'horizon d'investissement
   - Ajout du champ `horizon` au mod√®le Pydantic `InvestmentDecision`
   - Obligation pour l'IA de d√©duire l'horizon depuis le rapport d'analyse

2. ‚úÖ **Graphiques Dynamiques avec Tendance** :
   - Refonte `get_sparkline_chart()` avec couleurs selon tendance (vert=haussier, rouge=baissier)
   - Passage d'intervalle 1h ‚Üí 1d pour plus de robustesse
   - Retour de tuple `(fig, trend)` pour affichage de la tendance

3. ‚úÖ **Enrichissement Contextuel** :
   - R√©cup√©ration automatique du secteur d'activit√© via `yfinance`
   - Int√©gration dans la carte de d√©cision avec 3 KPI : Force du Signal, Horizon, Secteur
   - Cl√© unique pour graphiques Plotly (`key=f"sparkline_{ticker}"`)

4. ‚úÖ **Refonte Interface Compacte** :
   - Design en-t√™te int√©gr√© avec 3 colonnes : Badge Action, Info/News, Graphique
   - Suppression de la section "Tableau de Bord du Signal" s√©par√©e
   - Fusion informations essentielles en une ligne d'impact ultra-dense
   - Graphique sparkline directement dans l'en-t√™te avec indication de tendance

**R√©sultats :**
- Interface professionnelle lisible en 3 secondes
- Contexte m√©tier imm√©diat (secteur)
- Tendance march√© visuelle (couleurs dynamiques)
- Horizon d'investissement syst√©matiquement pr√©sent
- Information dense mais organis√©e

### 2024-01-XX - Impl√©mentation Base de Donn√©es ‚úÖ
**Objectif :** Ajouter une base de donn√©es SQLite pour √©viter les doublons et am√©liorer la gestion des articles.

**Modifications effectu√©es :**
1. ‚úÖ Ajout des imports `datetime` et `sqlite3`
2. ‚úÖ Cr√©ation fonction `init_db()` pour initialiser la base avec table `articles`
3. ‚úÖ Modification `fetch_news_from_feeds()` ‚Üí `fetch_and_store_news()` avec INSERT OR IGNORE
4. ‚úÖ Cr√©ation `get_articles_from_db()` pour r√©cup√©rer les articles tri√©s par date DESC
5. ‚úÖ Am√©lioration interface Streamlit avec dates de publication format√©es
6. ‚úÖ Ajout notification toast pour nouveaux articles trouv√©s
7. ‚úÖ Am√©lioration affichage avec `st.json()` pour les entit√©s

### 2024-01-XX - Cr√©ation Module Agents IA ‚úÖ
**Objectif :** D√©velopper une √©quipe d'agents IA sp√©cialis√©s pour l'analyse approfondie des news.

**Composants impl√©ment√©s :**
1. ‚úÖ **Initialisation LLM** avec temp√©rature 0.3 pour la personnalit√©
2. ‚úÖ **3 Profils d'Agents Sp√©cialis√©s :**
   - `analyste_actions` : Analyse d'actions individuelles avec recommandations
   - `analyste_sectoriel` : Analyse de secteurs et dynamiques concurrentielles
   - `strategiste_geopolitique` : Analyse g√©opolitique et macro√©conomique
3. ‚úÖ **Routeur Intelligent** (`route_to_agents()`) avec fallback automatique
4. ‚úÖ **Ex√©cuteur d'Agent** (`run_agent_analysis()`) avec gestion d'erreurs
5. ‚úÖ **Fonctions Utilitaires** et module de test int√©gr√©
6. ‚úÖ **Type Hints** complets et documentation d√©taill√©e

### 2024-01-XX - Int√©gration Agents dans Interface Principale ‚úÖ
**Objectif :** Int√©grer le syst√®me d'agents IA dans l'interface utilisateur de BERZERK Lab.

**Modifications effectu√©es :**
1. ‚úÖ **Import du module agents** dans `berzerk_lab.py`
2. ‚úÖ **Nouvelles variables de session_state** pour g√©rer l'√©tat des agents
3. ‚úÖ **R√©initialisation des agents** lors du changement d'article
4. ‚úÖ **Interface de recrutement** avec bouton "Recruter l'√âquipe d'Agents Sp√©cialis√©s"
5. ‚úÖ **Affichage de l'√©quipe** avec focus sp√©cifique de chaque agent
6. ‚úÖ **Interface d'ex√©cution** avec bouton "Lancer les Analyses de l'√âquipe"
7. ‚úÖ **Affichage des r√©sultats** avec expanders pour chaque analyse d'agent
8. ‚úÖ **Gestion d'erreurs** et indicateurs de progression optimis√©s
9. ‚úÖ **Interface multi-perspectives** compl√®tement fonctionnelle

### 2024-01-XX - Pipeline Automatis√© avec LangGraph ‚úÖ
**Objectif :** Cr√©er un syst√®me d'orchestration automatis√© pour la cha√Æne compl√®te d'analyse.

**Composants impl√©ment√©s :**
1. ‚úÖ **Agent Investisseur Final** ajout√© dans `agents.py`
   - Prend la d√©cision finale ACHETER/VENDRE/SURVEILLER/IGNORER
   - Calcule l'allocation de capital (% du portefeuille)
   - Format JSON structur√© avec justifications et risques
2. ‚úÖ **Pipeline LangGraph** dans `orchestrator.py`
   - Graphe d'√©tats avec 4 n≈ìuds : Analyse ‚Üí Routage ‚Üí Ex√©cution ‚Üí D√©cision
   - Gestion d'erreurs robuste √† chaque √©tape
   - Logs d'ex√©cution d√©taill√©s avec timestamps
3. ‚úÖ **Fonctions d'orchestration** compl√®tes
   - `run_berzerk_pipeline()` : Point d'entr√©e principal
   - `display_final_results()` : Affichage format√© des r√©sultats
   - Mode test int√©gr√© pour validation
4. ‚úÖ **Types et validation** avec Pydantic
   - `GraphState` : √âtat typ√© circulant dans le graphe
   - `InvestmentDecision` : Validation des d√©cisions finales

### 2024-01-XX - Architecture Service 24/7 ‚úÖ
**Objectif :** Cr√©er un syst√®me de surveillance automatique 24/7 avec s√©paration backend/frontend.

**Architecture finale :**
```
üîÑ berzerk_service.py  ‚Üê  Daemon 24/7
     ‚Üì (analyse automatique)
üóÑÔ∏è berzerk.db         ‚Üê  Base de donn√©es centralis√©e  
     ‚Üë (lecture seule)
üìä berzerk_dashboard.py ‚Üê  Dashboard Streamlit
```

**Composants impl√©ment√©s :**
1. ‚úÖ **Extension Base de Donn√©es**
   - Colonnes `status`, `decision_json`, `analyzed_at` ajout√©es
   - Gestion des migrations automatiques
   - Suivi complet du cycle de vie des articles
2. ‚úÖ **Service Daemon** (`berzerk_service.py`)
   - Surveillance continue des flux RSS (intervalle configurable)
   - D√©tection automatique des nouvelles news
   - Analyse automatique via les agents IA
   - Gestion d'erreurs robuste et logs d√©taill√©s
3. ‚úÖ **Dashboard Temps R√©el** (`berzerk_dashboard.py`)
   - Interface s√©par√©e pour visualisation
   - Statistiques globales et m√©triques
   - Filtres avanc√©s (statut, action, p√©riode)
   - Auto-refresh optionnel
   - Pagination et affichage optimis√©

## üêõ Suivi des Erreurs
*Aucune erreur critique identifi√©e pour le moment*

## ‚úÖ R√©sultats des Tests
*Tests √† effectuer apr√®s impl√©mentation de la base de donn√©es*

## üìö Documentation Consult√©e
- [LangChain Documentation](https://python.langchain.com/docs/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [SQLite Documentation](https://docs.python.org/3/library/sqlite3.html)
- [Feedparser Documentation](https://feedparser.readthedocs.io/)

## üèóÔ∏è Structure du Projet
```
Berzerk/
‚îú‚îÄ‚îÄ berzerk_lab.py          # Interface Streamlit originale (Phases 1-2)
‚îú‚îÄ‚îÄ berzerk_service.py      # Service daemon surveillance 24/7 (Phase 3)
‚îú‚îÄ‚îÄ berzerk_dashboard.py    # Dashboard temps r√©el (Phase 3)
‚îú‚îÄ‚îÄ agents.py               # Agents IA sp√©cialis√©s + Investisseur Final
‚îú‚îÄ‚îÄ orchestrator.py         # Pipeline automatis√© LangGraph (Phase 2.3)
‚îú‚îÄ‚îÄ test_feeds.py           # Tests des flux RSS
‚îú‚îÄ‚îÄ suivi_projet.md         # Documentation du projet
‚îú‚îÄ‚îÄ berzerk.db              # Base de donn√©es SQLite (cr√©√© automatiquement)
‚îú‚îÄ‚îÄ venv/                   # Environnement virtuel
‚îî‚îÄ‚îÄ .env                    # Variables d'environnement
```

### üìã Modes d'Utilisation
1. **Mode Interactif** : `streamlit run berzerk_lab.py` (Phases 1-2)
2. **Mode Service** : `python berzerk_service.py [interval]` (Phase 3)
3. **Mode Dashboard** : `streamlit run berzerk_dashboard.py` (Phase 3)
4. **Mode Pipeline** : `python orchestrator.py <URL> <CAPITAL>` (Phase 2.3)

## ü§î R√©flexions & D√©cisions

### D√©cision Architecture Base de Donn√©es
**Probl√®me :** Articles dupliqu√©s et pas de tri chronologique
**Solution choisie :** SQLite avec contrainte UNIQUE sur les liens
**Justification :** Simple, l√©ger, int√©gr√© Python, parfait pour ce volume de donn√©es

### Contraintes Techniques
- **Gemini API :** Limitation de tokens par requ√™te
- **RSS Feeds :** Certains flux peuvent √™tre instables
- **Parsing HTML :** Variabilit√© des structures selon les sources

## üìä M√©triques de Succ√®s

### Phase 1-2 : Analyse Interactive ‚úÖ
- [x] Z√©ro doublon d'article (contrainte UNIQUE sur les liens)
- [x] Tri chronologique fonctionnel (ORDER BY published_date DESC)
- [x] Persistence des donn√©es entre sessions (SQLite + init_db())
- [x] Temps de r√©ponse < 5 secondes pour l'analyse (LangChain optimis√©)

### Phase 3 : Architecture Service 24/7 ‚úÖ
- [x] Surveillance automatique continue (daemon stable)
- [x] D√©tection temps r√©el des nouvelles news
- [x] Analyse automatique sans intervention humaine
- [x] S√©paration backend/frontend fonctionnelle
- [x] Dashboard temps r√©el avec filtres avanc√©s
- [x] Gestion d'erreurs robuste et logs d√©taill√©s

### Phase 4 : Agent "Ticker Hunter" ‚úÖ
- [x] Transformation r√©volutionnaire du pipeline vers le trading cibl√©
- [x] Identification automatique de 1-5 tickers actionnables par news
- [x] Routage intelligent bas√© sur les tickers identifi√©s
- [x] Service daemon optimis√© avec prise de d√©cision orient√©e tickers
- [x] Passage de "SURVEILLER" syst√©matique √† d√©cisions d'achat cibl√©es

### Phase 5 : Surveillance RSS Temps R√©el ‚úÖ
- [x] Syst√®me de surveillance RSS quasi-instantan√© (30 secondes)
- [x] Optimisations HTTP (ETags, Last-Modified, codes 304)
- [x] Threading asynchrone pour analyses parall√®les
- [x] D√©tection intelligente via hash de contenu
- [x] Gestion d'erreurs adaptative
- [x] **CORRECTION CRITIQUE** : Logique de d√©tection des nouveaux articles simplifi√©e

## üéØ Phase 4 : Agent "Ticker Hunter" - R√©volution Strat√©gique

### Objectif R√©volutionnaire üöÄ
Transformer BERZERK d'un analyseur de news g√©n√©raliste en **machine de trading cibl√©e** via l'identification automatique de tickers actionnables.

### Nouveau Pipeline R√©volutionnaire ‚úÖ
```
Analyse Initiale ‚Üí **[TICKER HUNTER]** ‚Üí Routage des Agents ‚Üí Analyses Sp√©cialis√©es ‚Üí D√©cision Finale
```

### Impl√©mentation Compl√®te ‚úÖ

#### 1. Agent "Ticker Hunter" Ultra-Sp√©cialis√© ‚úÖ
- **Profil expert** : Focus exclusif sur les entreprises cot√©es
- **Prompt directif** : Identification 1-5 tickers maximum par news
- **Validation Pydantic** : Structure JSON stricte avec justifications
- **R√®gles critiques** : Seules les entreprises publiques avec impact direct

#### 2. Orchestrateur LangGraph Enrichi ‚úÖ
- **Nouveau n≈ìud** : `node_find_actionable_tickers()` (√âtape 2)
- **√âtat √©tendu** : `actionable_tickers` dans `GraphState`
- **Flux optimis√©** : 1 (Analyse) ‚Üí 2 (Ticker Hunter) ‚Üí 3 (Routage) ‚Üí 4 (Agents) ‚Üí 5 (D√©cision)
- **Gestion d'erreurs** : Logs d√©taill√©s et fallback automatique

#### 3. Routage Intelligent R√©volutionnaire ‚úÖ
- **Mode PR√âCIS** : 1 analyste actions par ticker identifi√©
- **Mode FALLBACK** : Analyse macro si aucun ticker trouv√©
- **Optimisation sectoriels** : Ajout analyste sectoriel si multiples tickers
- **Limite intelligente** : Maximum 2 agents pour le service automatique

#### 4. Service Daemon 2.0 ‚úÖ
- **Priorisation tickers** : Focus sur le premier ticker identifi√©
- **Allocation cibl√©e** : Maximum 3% pour s√©curit√© (service automatique)
- **Justification enrichie** : Int√©gration ticker + signaux + impact
- **Prise de d√©cision** : Orient√©e trading d'actions sp√©cifiques

#### 5. Affichage R√©sultats Enrichi ‚úÖ
- **Section d√©di√©e** : Affichage des tickers identifi√©s
- **D√©tails complets** : Ticker, entreprise, justification d'impact
- **Logs am√©lior√©s** : Tra√ßabilit√© compl√®te du Ticker Hunter

### R√©volution Strat√©gique üéØ

#### Avant (Phase 3) vs Apr√®s (Phase 4)
| Aspect | Phase 3 | Phase 4 |
|--------|---------|---------|
| **Focus** | Analyse macro g√©n√©rale | Tickers sp√©cifiques |
| **D√©cisions** | 100% "SURVEILLER" | D√©cisions d'achat cibl√©es |
| **Pr√©cision** | Entit√©s vagues | 1-5 tickers maximum |
| **Agents** | Routage bas√© entit√©s | 1 agent par ticker |
| **Efficacit√©** | Analyses redondantes | Analyses hyper-cibl√©es |

#### B√©n√©fices R√©volutionnaires üìà
1. **Hyper-Focus** : Concentration sur actions sp√©cifiques au lieu d'analyses macro vagues
2. **Qualit√© d√©cisionnelle** : Analyses pr√©cises sur tickers identifi√©s
3. **R√©duction du bruit** : √âlimination des analyses g√©n√©rales improductives
4. **Alignement mission** : 100% orient√© trading d'actions
5. **Efficacit√© computationnelle** : Moins d'analyses, plus de qualit√©
6. **Performance attendue** : Passage de "intelligent" √† "redoutable"

### Impact Transformationnel üéØ
- **Fin du "SURVEILLER" syst√©matique** : D√©cisions d'achat/vente cibl√©es
- **Pr√©cision analytique** : Focus sur 1-2 actions maximum par news
- **Pipeline orient√© trading** : Chaque √©tape optimis√©e pour l'investissement
- **Machine de guerre financi√®re** : BERZERK devient un syst√®me d'investissement professionnel

**Cette am√©lioration repr√©sente la transformation la plus importante de BERZERK : d'un analyseur de news √† un syst√®me d'investissement automatis√© de niveau professionnel.**

## üåê Phase 5 : Agents Augment√©s avec Acc√®s Internet ‚úÖ

### Objectif R√©volutionnaire üöÄ
Connecter BERZERK au monde ext√©rieur en donnant aux agents l'acc√®s √† des **outils temps r√©el** pour des analyses ancr√©es dans la r√©alit√© du march√©.

### Probl√®me R√©solu üéØ
**Avant :** Agents "aveugles" travaillant uniquement avec :
- Connaissances pr√©-entra√Æn√©es (potentiellement obsol√®tes)  
- Contenu de l'article analys√©

**Apr√®s :** Agents "conscients du contexte" avec acc√®s √† :
- üîç **Recherche web temps r√©el** (Tavily AI)
- üìä **Donn√©es financi√®res actuelles** (yfinance)
- üí∞ **Prix et variations en direct**
- üìà **Sentiment du march√©** (capitalisation, P/E, volume)

### Impl√©mentation Compl√®te ‚úÖ

#### 1. Outils Externes Int√©gr√©s ‚úÖ
- **TavilySearchResults** : Recherche web intelligente avec 3 r√©sultats max
- **get_stock_price()** : Prix actuel et variation quotidienne  
- **get_market_sentiment()** : Capitalisation, P/E ratio, volume moyen
- **Gestion d'erreurs robuste** : Fallback automatique en cas d'√©chec

#### 2. Agent Augment√© Ultra-Intelligent ‚úÖ
- **create_augmented_analyst()** : Agent avec outils disponibles
- **Prompt syst√®me optimis√©** : Instructions pour usage strat√©gique des outils
- **AgentExecutor configur√©** : Max 5 it√©rations, arr√™t anticip√© intelligent
- **Mode verbose** : Visibilit√© compl√®te du processus de r√©flexion

#### 3. Processus d'Analyse R√©volutionnaire ‚úÖ
```
1. Analyse de la news fournie
2. V√©rification prix actuel et variation (get_stock_price)
3. Recherche informations compl√©mentaires (web_search)
4. Analyse sentiment march√© (get_market_sentiment)
5. Synth√®se avec contexte temps r√©el
```

#### 4. Int√©gration Pipeline Principal ‚úÖ
- **Orchestrateur enrichi** : D√©tection automatique des analyses de tickers
- **Mode hybride** : Agents augment√©s pour tickers + agents classiques pour macro
- **Service daemon optimis√©** : Analyses augment√©es en mode automatique
- **Tra√ßabilit√© compl√®te** : Logs sp√©ciaux pour analyses augment√©es

### Exemple de Processus d'Analyse Augment√©e ü§ñ

**Sc√©nario :** News sur Apple + iPhone sales

**Agent classique (Phase 4) :**
```
"Analyse l'impact sur AAPL. L'article semble positif..."
‚Üí Recommandation bas√©e uniquement sur l'article
```

**Agent augment√© (Phase 5) :**
```
"Analyse l'impact sur AAPL. L'article semble positif..."
üîß Utilise get_stock_price("AAPL")
üí∞ AAPL: 195.20 USD üìà +5.20% vs hier
"Le march√© a d√©j√† fortement r√©agi (+5.2%)..."

üîß Utilise web_search("Apple concurrents smartphone")  
üì∞ "Samsung annonce Galaxy S25 avec IA..."
"La concurrence s'intensifie avec Samsung..."

üîß Utilise get_market_sentiment("AAPL")
üìä AAPL - Cap: 3.0T USD | P/E: 28.5 | Volume moy: 58,000,000
"Valorisation √©lev√©e mais volume normal..."

‚Üí Recommandation nuanc√©e avec contexte march√© complet
```

### Transformation Cognitive üß†

#### Impact sur la Qualit√© D√©cisionnelle
| Aspect | Agents Classiques | Agents Augment√©s |
|--------|------------------|------------------|
| **Contexte temporel** | Fig√© | Temps r√©el |
| **R√©action march√©** | Inconnue | V√©rifi√©e |
| **Informations compl√©mentaires** | Limit√©es √† l'article | Web entier accessible |
| **Valorisation** | Estimation | Donn√©es r√©elles |
| **Timing** | Th√©orique | Pratique |

#### B√©n√©fices Transformationnels üìà
1. **Contextualisation parfaite** : D√©cisions ancr√©es dans la r√©alit√©
2. **D√©tection de sur-r√©action** : √âviter les achats apr√®s forte hausse  
3. **Informations concurrentielles** : Vision √©largie du secteur
4. **Timing optimal** : Prise en compte des mouvements r√©cents
5. **Risque r√©duit** : Analyses plus compl√®tes et nuanc√©es

### Architecture Finale BERZERK 2.0 üèóÔ∏è

```
üì∞ News ‚Üí ü§ñ Ticker Hunter ‚Üí üåê Agents Augment√©s ‚Üí üí∞ D√©cision Finale
              ‚Üì                    ‚Üì
         Tickers cibl√©s      Donn√©es temps r√©el
                                   ‚Üì
                            üîç Web + üìä Finance
```

**BERZERK est d√©sormais un syst√®me d'investissement connect√© au monde r√©el, capable de prendre des d√©cisions inform√©es par le contexte actuel du march√© ! üöÄ** 

## üêõ Correction Critique : Probl√®me de Retraitement des Articles

### Probl√®me Identifi√©
**Sympt√¥me :** Le syst√®me `real_time_rss_monitor.py` retraitait des articles d√©j√† analys√©s, causant une perte de tokens inutile √† chaque red√©marrage.

**Cause Racine :** Double logique de cache probl√©matique :
- `processed_articles` : charg√© depuis la base de donn√©es au d√©marrage ‚úÖ
- `articles_cache` : r√©initialis√© √† vide √† chaque red√©marrage ‚ùå

**Impact :** 
- Perte de tokens API
- Analyses redondantes
- Pollution des logs
- Performance d√©grad√©e

### Solution Impl√©ment√©e ‚úÖ
**Strat√©gie :** Simplification de la logique de d√©tection des nouveaux articles

**Modifications dans `real_time_rss_monitor.py` :**
1. **Suppression de `articles_cache`** dans la classe `FeedState`
2. **Logique simplifi√©e** : `if article_link and article_link not in self.processed_articles:`
3. **Marquage imm√©diat** : `self.processed_articles.add(article_link)` d√®s la d√©tection
4. **Nettoyage des imports** : suppression de `field` non utilis√©

**R√©sultat :** 
- ‚úÖ Seuls les VRAIS nouveaux articles sont trait√©s
- ‚úÖ Pas de retraitement apr√®s red√©marrage
- ‚úÖ √âconomie de tokens API
- ‚úÖ Logs plus propres 

## üéØ Mise √† Jour Majeure : Focus Bloomberg et Nettoyage Projet

### Phase 6 : Simplification et Fiabilit√© ‚úÖ
**Objectif :** Concentrer les analyses uniquement sur le flux RSS de Bloomberg (plus fiable) et nettoyer le projet.

**Modifications appliqu√©es :**
1. **Flux RSS simplifi√©** : Seul Bloomberg conserv√© dans `RSS_FEEDS`
   - ‚úÖ `berzerk_lab.py` : Bloomberg uniquement
   - ‚úÖ `test_feeds.py` : Bloomberg uniquement  
   - ‚úÖ `real_time_rss_monitor.py` : Messages mis √† jour
2. **Nettoyage des fichiers obsol√®tes** :
   - ‚úÖ Suppression de `auto_monitor.py` (redondant)
   - ‚úÖ Suppression de `berzerk_service.py` (redondant)
3. **Fichiers de configuration ajout√©s** :
   - ‚úÖ `requirements.txt` : Toutes les d√©pendances Python
   - ‚úÖ `env.example` : Variables d'environnement document√©es

**Justification :** Bloomberg est plus fiable et coh√©rent que Yahoo Finance. Cette simplification am√©liore la qualit√© des analyses et la reproductibilit√© du projet.

## üöÄ Phase 7 : Transformation BERZERK "TAC AU TAC" - Mode Pure Pr√©diction ‚úÖ

### R√©volution Philosophique : Du "Prudent" au "Visionnaire" üéØ

**Probl√®me strat√©gique identifi√© :** Le pipeline BERZERK, dans sa version "augment√©e", √©tait devenu un **analyste prudent** qui v√©rifiait si le march√© avait d√©j√† r√©agi √† la news avant de prendre position. Cette approche, bien que sens√©e pour un humain, allait √† l'encontre de la philosophie "tac au tac" de BERZERK : agir **AVANT** que le march√© n'int√®gre l'information.

#### Diagnostic des "Freins" Identifi√©s üîç

**Composants "contaminants" supprim√©s :**
1. **`get_stock_price()`** - Calculait les variations vs jour pr√©c√©dent ‚ùå
2. **`get_market_sentiment()`** - R√©cup√©rait P/E, volume, capitalisation ‚ùå
3. **Prompt agent augment√©** - "Mentionne si le march√© a d√©j√† r√©agi" ‚ùå
4. **Pipeline orchestrateur** - Appelait `run_augmented_analysis()` ‚ùå

**R√©sultat :** L'IA agissait comme un **co-pilote prudent** qui regardait dans le r√©troviseur au lieu d'√™tre un **moteur de pr√©diction** focalis√© sur la route √† venir.

### Impl√©mentation du Mode "Pure Pr√©diction" ‚úÖ

#### 1. Nouvel Agent Visionnaire (`agents.py`) ‚úÖ
**Fonction :** `create_pure_prediction_analyst()`
- **Philosophie :** Pr√©diction PURE bas√©e uniquement sur le potentiel de la news
- **Outils disponibles :** UNIQUEMENT `web_search_tool` pour contexte qualitatif
- **Interdictions :** Aucune donn√©e de prix, volume, ou r√©action de march√©
- **Prompt :** "IGNORE TOTALEMENT si le march√© a d√©j√† r√©agi ou non"

**Fonction :** `run_pure_prediction_analysis()`
- **Mission :** Analyse pr√©dictive sans pollution de donn√©es historiques
- **Focale :** Impact business fondamental pr√©dit
- **Vitesse :** Moins d'it√©rations (4 max) pour d√©cision rapide

#### 2. Orchestrateur Transform√© (`orchestrator.py`) ‚úÖ
**Modification cl√© :** Ligne 267 
```python
# AVANT (mode prudent)
analysis = run_augmented_analysis(ticker=ticker, ...)
"agent_type": agent['agent_type'] + "_augmented"
"üöÄ Analyse AUGMENT√âE pour {ticker} (avec outils temps r√©el)"

# APR√àS (mode visionnaire)  
analysis = run_pure_prediction_analysis(ticker=ticker, ...)
"agent_type": agent['agent_type'] + "_pure_prediction"  
"üöÄ Analyse PURE PREDICTION pour {ticker} (mode 'tac au tac')"
```

#### 3. Pipeline R√©volutionn√© üîÑ
**Nouveau flux :**
```
News ‚Üí Ticker Hunter ‚Üí Agent Pure Pr√©diction ‚Üí D√©cision Visionnaire
        ‚Üì               ‚Üì                       ‚Üì
   Tickers cibl√©s   Impact pr√©dit          Action imm√©diate
                  (SANS donn√©es prix)
```

### Transformation Cognitive Fondamentale üß†

#### Ancien vs Nouveau Paradigme
| Aspect | Mode "Augment√©" (Prudent) | Mode "Pure Pr√©diction" (Visionnaire) |
|--------|---------------------------|--------------------------------------|
| **Base d√©cision** | News + donn√©es march√© | News + contexte qualitatif SEUL |
| **Question cl√©** | "Le march√© a-t-il r√©agi ?" | "Quel est l'impact futur ?" |
| **Timing** | Apr√®s analyse du mouvement | AVANT r√©action du march√© |
| **Philosophie** | Co-pilote prudent | Machine pr√©dictive |
| **Vitesse** | Mod√©r√©e (5 it√©rations) | Rapide (4 it√©rations) |
| **Donn√©es interdites** | ‚úÖ Prix, P/E, volume | ‚ùå AUCUNE donn√©e financi√®re |

#### B√©n√©fices R√©volutionnaires üéØ
1. **Alignement strat√©gique** : 100% fid√®le √† la mission "tac au tac"
2. **Puret√© du signal** : D√©cision non "pollu√©e" par la volatilit√© court terme
3. **Vitesse de d√©cision** : Plus rapide (suppression appels API financiers)
4. **Audace retrouv√©e** : BERZERK redevient un syst√®me offensif
5. **Avantage comp√©titif** : Agit AVANT la masse des investisseurs

### Validation Technique ‚úÖ
**Test pipeline complet :** 
- ‚úÖ Import `run_pure_prediction_analysis` r√©ussi
- ‚úÖ Orchestrateur modifi√© op√©rationnel  
- ‚úÖ Logs "PURE PREDICTION (mode 'tac au tac')" confirm√©s
- ‚úÖ Pipeline ex√©cutable sans erreur de code

### Impact Transformationnel Final üöÄ

**BERZERK a retrouv√© son √¢me de guerrier financier :** 
- **AVANT :** "Analysons si le march√© a d√©j√† boug√©..."
- **APR√àS :** "Que va provoquer cette information ?"

Cette transformation repr√©sente le **retour aux sources** de BERZERK : un syst√®me d'investissement **visionnaire et offensif** qui parie sur l'intelligence artificielle pure plut√¥t que sur la prudence humaine.

## ü§î R√©flexions & D√©cisions - Phase 7

### D√©cision Strat√©gique Majeure
**Probl√®me :** Tension entre s√©curit√© (donn√©es march√©) et performance (pr√©diction pure)
**Solution choisie :** Mode pure pr√©diction avec possibilit√© de retour au mode augment√©
**Justification :** L'IA doit exploiter son avantage pr√©dictif, pas imiter la prudence humaine

### Flexibilit√© Pr√©serv√©e üîß
- **Code augment√© conserv√©** : `run_augmented_analysis()` disponible si besoin
- **Basculement facile** : Une ligne √† modifier dans l'orchestrateur
- **Choix utilisateur** : Possibilit√© d'impl√©menter un param√®tre de mode

**BERZERK 2.0 EST N√â : Machine de guerre financi√®re pure et visionnaire ! üéØ** 

## üé® Phase 8 : Interface "Decision Feed" - Clart√© Radicale ‚úÖ

### Vision R√©volutionnaire : De l'Ancien Dashboard au Decision Feed üéØ

**Probl√®me identifi√© :** L'ancien `berzerk_dashboard.py` √©tait complexe, avec de multiples onglets et une hi√©rarchie d'information confuse. L'utilisateur voulait une **interface √©pur√©e, priorit√© √† l'action, simplicit√© maximale**.

#### Philosophie "Clart√© Radicale" Impl√©ment√©e üöÄ

**Principes de Design :**
1. **Priorit√© √† l'action** : D√©cision (ACHETER/VENDRE) visible instantan√©ment
2. **Simplicit√©** : Pas d'onglets, flux vertical unique
3. **Hi√©rarchie** : Essentiel visible, d√©tails en un clic (expander)

#### Sp√©cifications Techniques Respect√©es ‚úÖ

**Structure de Donn√©es :**
- ‚úÖ **Format standard** : `action`, `ticker`, `nom_entreprise`, `news_title`, etc.
- ‚úÖ **Int√©gration DB** : Lecture directe de `decision_json` depuis `berzerk.db`
- ‚úÖ **Prix temps r√©el** : yfinance pour calcul performance

**Layout Exact :**
- ‚úÖ **Configuration** : `st.set_page_config(layout="wide")`
- ‚úÖ **En-t√™te** : "‚ö° BERZERK - Decision Feed" + sous-titre
- ‚úÖ **Barre statut** : 3 m√©triques (Statut, D√©cisions 24h, Achats 24h)
- ‚úÖ **Flux principal** : Cartes de d√©cision avec `display_decision_card()`

**Carte de D√©cision (sp√©cifications exactes) :**
- ‚úÖ **Layout [1, 8]** : Badge action color√© + infos principales
- ‚úÖ **Couleurs CSS** : Vert #28a745, Rouge #dc3545, Jaune #ffc107, Gris #6c757d
- ‚úÖ **Section performance** : Prix d√©cision, Prix actuel, Performance % avec emoji
- ‚úÖ **Expander d√©tails** : Justification IA, Points +/-, Allocation, Lien article

#### Fonctionnalit√©s Cl√©s Impl√©ment√©es üîß

**1. Gestion des Donn√©es :**
```python
def load_decisions_from_db() -> List[Dict[str, Any]]
```
- Lecture automatique depuis `berzerk.db`
- Filtrage des 7 derniers jours
- Fallback sur exemples si pas de donn√©es

**2. Affichage des Cartes :**
```python
def display_decision_card(decision: Dict[str, Any])
```
- Badge d'action color√© avec CSS
- Calcul automatique de performance
- Expander pour d√©tails complets

**3. Prix Temps R√©el :**
```python
def get_current_price(ticker: str) -> float
```
- Int√©gration yfinance
- Calcul automatique de performance vs prix de d√©cision
- Gestion d'erreurs robuste

#### Validation Utilisateur ‚úÖ

**Feedback :** *"ok j'aime le visuel gardons le comme ca pour l'instant"*

‚úÖ **Interface valid√©e et pr√™te pour utilisation**

#### Impact sur l'Architecture BERZERK üìä

**Ancien vs Nouveau :**
- ‚ùå **Ancien** : `berzerk_dashboard.py` - Complexe, multi-onglets
- ‚úÖ **Nouveau** : `berzerk_decision_feed.py` - √âpur√©, flux unique

**Int√©gration :**
- ‚úÖ Compatible avec pipeline BERZERK 2.0 (mode pure pr√©diction)
- ‚úÖ Lecture directe des d√©cisions stock√©es
- ‚úÖ Interface responsive et moderne

#### Prochaines √âtapes Sugg√©r√©es üöÄ

1. **Test avec donn√©es r√©elles** : Lancer monitoring + interface
2. **Optimisations performance** : Cache pour prix, refresh automatique
3. **Fonctionnalit√©s avanc√©es** : Filtres, recherche, export
4. **Mode sombre** : Th√®me alternatif si demand√©

---

## üìà Bilan Global - BERZERK Phase 8

**√âtat Actuel : OP√âRATIONNEL ‚úÖ**

- ‚úÖ **Pipeline Pure Pr√©diction** : Mode "tac au tac" fonctionnel
- ‚úÖ **Interface Decision Feed** : Design "Clart√© Radicale" valid√©
- ‚úÖ **Architecture compl√®te** : De la collecte RSS √† l'affichage d√©cisions

**BERZERK** est maintenant une **machine de guerre pr√©dictive compl√®te** avec interface utilisateur de qualit√© professionnelle.
</file>

<file path="agents.py">
"""
Module d'Agents IA Sp√©cialis√©s pour le Projet BERZERK
====================================================

Ce module contient une √©quipe d'agents IA sp√©cialis√©s pour analyser les news financi√®res
sous diff√©rents angles. Chaque agent a une expertise unique et apporte sa perspective
√† l'analyse globale.

Auteur: BERZERK Team
Phase: 2 - Agents IA Sp√©cialis√©s
"""

import yfinance as yf
from dotenv import load_dotenv
from langchain.agents import AgentExecutor, create_tool_calling_agent

# Imports pour les outils
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.tools import tool

# LangChain Imports
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import BaseModel, Field

# --- CONFIGURATION & SETUP ---
load_dotenv()

# Initialisation du LLM avec temp√©rature plus √©lev√©e pour la personnalit√© des agents
try:
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-lite-preview-06-17",
        temperature=0.3,
        # Le param√®tre convert_system_message_to_human est maintenant g√©r√© automatiquement
    )
    print("‚úÖ LLM initialis√© avec succ√®s pour les agents IA")
except Exception as e:
    print(f"‚ùå Erreur d'initialisation du LLM pour les agents: {e}")
    llm = None

# --- OUTILS POUR AGENTS AUGMENT√âS ---

# 1. Outil de recherche web avec Tavily
try:
    web_search_tool = TavilySearchResults(
        max_results=3,  # Limiter pour √©viter la surcharge d'informations
        search_depth="basic",  # Recherche basique pour √™tre plus rapide
    )
    print("‚úÖ Outil de recherche web (Tavily) initialis√©")
except Exception as e:
    print(f"‚ùå Erreur d'initialisation de Tavily: {e}")
    web_search_tool = None


# 2. Outil de donn√©es financi√®res avec yfinance
@tool
def get_stock_price(ticker: str) -> str:
    """R√©cup√®re le prix actuel et la variation journali√®re pour un ticker donn√©."""
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="2d")  # 2 jours pour calculer la variation
        if hist.empty:
            return f"‚ùå Donn√©es non trouv√©es pour {ticker}"

        # Prix actuel (derni√®re cl√¥ture)
        current_price = hist["Close"].iloc[-1]

        # Variation par rapport √† la veille
        if len(hist) >= 2:
            previous_price = hist["Close"].iloc[-2]
            change_percent = ((current_price - previous_price) / previous_price) * 100
            change_symbol = (
                "üìà" if change_percent > 0 else "üìâ" if change_percent < 0 else "‚û°Ô∏è"
            )

            return f"üí∞ {ticker}: {current_price:.2f} USD {change_symbol} {change_percent:+.2f}% vs hier"
        else:
            return f"üí∞ {ticker}: {current_price:.2f} USD (variation non disponible)"

    except Exception as e:
        return f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es pour {ticker}: {str(e)}"


@tool
def get_market_sentiment(ticker: str) -> str:
    """R√©cup√®re des informations sur le sentiment du march√© pour un ticker."""
    try:
        stock = yf.Ticker(ticker)
        info = stock.info

        # Informations cl√©s
        market_cap = info.get("marketCap", "N/A")
        pe_ratio = info.get("trailingPE", "N/A")
        volume = info.get("averageVolume", "N/A")

        # Formatage des grandes valeurs
        if isinstance(market_cap, int | float):
            if market_cap > 1e12:
                market_cap_str = f"{market_cap/1e12:.1f}T USD"
            elif market_cap > 1e9:
                market_cap_str = f"{market_cap/1e9:.1f}B USD"
            else:
                market_cap_str = f"{market_cap/1e6:.1f}M USD"
        else:
            market_cap_str = "N/A"

        return (
            f"üìä {ticker} - Cap: {market_cap_str} | P/E: {pe_ratio} | Volume moy: {volume:,}"
            if isinstance(volume, int)
            else f"üìä {ticker} - Cap: {market_cap_str} | P/E: {pe_ratio} | Volume moy: {volume}"
        )

    except Exception as e:
        return f"‚ùå Erreur sentiment march√© pour {ticker}: {str(e)}"


print("‚úÖ Outils financiers (yfinance) initialis√©s")

# --- MOD√àLES PYDANTIC POUR LA VALIDATION ---


class AgentSelection(BaseModel):
    """Mod√®le pour la s√©lection d'agents par le routeur."""

    agents: list[dict[str, str]] = Field(
        description="Liste des agents s√©lectionn√©s avec leur type et focus"
    )


class TickerIdentification(BaseModel):
    """Mod√®le pour la sortie de l'agent Ticker Hunter."""

    ticker: str = Field(description="Symbole boursier de l'entreprise")
    nom_entreprise: str = Field(description="Nom complet de l'entreprise")
    justification_impact: str = Field(
        description="Justification de l'impact sur cette entreprise"
    )


class TickerHunterResult(BaseModel):
    """Mod√®le pour la sortie compl√®te de l'agent Ticker Hunter."""

    tickers_identifies: list[TickerIdentification] = Field(
        description="Liste des tickers identifi√©s avec leurs justifications"
    )


# --- PROFILS D'AGENTS SP√âCIALIS√âS ---

# Ticker Hunter - Agent sp√©cialis√© dans l'identification de tickers actionnables
ticker_hunter_template = PromptTemplate(
    input_variables=["news_summary", "full_article_text"],
    template="""
Tu es "The Ticker Hunter", un analyste financier redoutable pour le fonds BERZERK. Ta seule et unique mission est d'identifier des opportunit√©s de trading actionnables √† partir d'informations. Tu ignores les concepts vagues et tu te concentres sur les entreprises cot√©es.

Analyse le r√©sum√© et le texte complet de l'article ci-dessous.

**R√©sum√© :**
{news_summary}

**Texte Complet :**
{full_article_text}

---
**TACHE :**
Identifie les 1 √† 5 entreprises cot√©es en bourse (et leurs tickers boursiers) les plus directement et significativement impact√©es par cette news.
Pour chaque entreprise, fournis une justification concise expliquant POURQUOI elle est impact√©e.

R√©ponds IMP√âRATIVEMENT au format JSON suivant, et rien d'autre. Si aucune action n'est clairement identifiable, retourne une liste vide.

{{
    "tickers_identifies": [
        {{
            "ticker": "AAPL",
            "nom_entreprise": "Apple Inc.",
            "justification_impact": "L'article mentionne des probl√®mes dans la cha√Æne d'approvisionnement des iPhones en Chine."
        }},
        {{
            "ticker": "QCOM",
            "nom_entreprise": "Qualcomm",
            "justification_impact": "En tant que fournisseur cl√© d'Apple, Qualcomm serait directement affect√© par un ralentissement de la production."
        }}
    ]
}}

**R√àGLES CRITIQUES :**
- Seules les entreprises publiques avec des tickers boursiers r√©els (NYSE, NASDAQ, etc.)
- Un ticker est une courte cha√Æne de 1 √† 5 lettres majuscules (ex: GOOGL, MSFT), parfois avec un suffixe de march√© (ex: .HK, .PA).
- Le ticker ne doit JAMAIS contenir de '$', d'espaces ou √™tre une phrase.
- Impact direct et mesurable sur le business
- Justification factuelle bas√©e sur le contenu de l'article
- Maximum 5 tickers pour rester focus
- Si aucun ticker n'est clairement identifiable, retourne une liste vide
""",
)

# Analyste Actions - Sp√©cialis√© dans l'analyse d'actions individuelles
analyste_actions_template = PromptTemplate(
    input_variables=["focus", "news_summary", "full_article_text"],
    template="""
Tu es un Analyste Financier Senior sp√©cialis√© en actions pour le fonds d'investissement BERZERK.

**Ton Focus Exclusif : L'action {focus}.**

Ta mission est d'√©valuer l'impact d'une nouvelle sur cette action sp√©cifique. Ignore les autres aspects.
Tu dois analyser avec pr√©cision l'impact potentiel sur le cours de l'action, les volumes, et les perspectives.

R√©sum√© de la news :
{news_summary}

Texte complet de l'article :
{full_article_text}

---
Produis une analyse concise au format Markdown avec les sections suivantes :

### üéØ √âvaluation sur {focus}
- **Sentiment :** (Positif, N√©gatif, Neutre)
- **Impact (1-10) :** (Note l'impact potentiel sur le cours de l'action)
- **Justification :** (Explique ton raisonnement en 2-3 phrases claires, en te basant sur des faits de l'article.)

### üìä Analyse Technique
- **Catalyseurs identifi√©s :** (√âl√©ments qui pourraient faire bouger le cours)
- **Risques potentiels :** (√âl√©ments n√©gatifs √† surveiller)

### üéØ Recommandation d'Action
- **Horizon :** (Court Terme, Moyen Terme, Long Terme)
- **Action :** (Surveiller, Renforcer la position, All√©ger la position, Ne rien faire)
- **Niveau de confiance :** (Faible, Moyen, √âlev√©)
""",
)

# Analyste Sectoriel - Sp√©cialis√© dans l'analyse de secteurs d'activit√©
analyste_sectoriel_template = PromptTemplate(
    input_variables=["focus", "news_summary", "full_article_text"],
    template="""
Tu es un Analyste Sectoriel Expert pour le fonds d'investissement BERZERK.

**Ton Focus Exclusif : Le secteur {focus}.**

Ta mission est d'analyser l'impact d'une nouvelle sur l'ensemble du secteur. Tu dois identifier les tendances,
les dynamiques concurrentielles et les implications pour toutes les entreprises du secteur.

R√©sum√© de la news :
{news_summary}

Texte complet de l'article :
{full_article_text}

---
Produis une analyse sectorielle au format Markdown avec les sections suivantes :

### üè≠ Impact Sectoriel sur {focus}
- **Sentiment Global :** (Positif, N√©gatif, Neutre)
- **Ampleur d'Impact (1-10) :** (Note l'impact sur l'ensemble du secteur)
- **Justification :** (Explique les m√©canismes d'impact sur le secteur)

### üîÑ Dynamiques Concurrentielles
- **Gagnants potentiels :** (Quelles entreprises/sous-secteurs pourraient b√©n√©ficier)
- **Perdants potentiels :** (Quelles entreprises/sous-secteurs pourraient souffrir)
- **Changements structurels :** (√âvolutions durables attendues)

### üéØ Implications Strat√©giques
- **Opportunit√©s d'investissement :** (Nouvelles opportunit√©s cr√©√©es)
- **Risques sectoriels :** (Nouveaux risques √† surveiller)
- **Horizon temporel :** (Court/Moyen/Long terme pour les impacts)
""",
)

# Strat√©giste G√©opolitique - Sp√©cialis√© dans l'analyse g√©opolitique et macro√©conomique
strategiste_geopolitique_template = PromptTemplate(
    input_variables=["focus", "news_summary", "full_article_text"],
    template="""
Tu es un Strat√©giste G√©opolitique Senior pour le fonds d'investissement BERZERK.

**Ton Focus Exclusif : {focus}.**

Ta mission est d'analyser les implications g√©opolitiques et macro√©conomiques d'une nouvelle.
Tu dois identifier les ramifications sur les relations internationales, les politiques √©conomiques,
et les flux de capitaux mondiaux.

R√©sum√© de la news :
{news_summary}

Texte complet de l'article :
{full_article_text}

---
Produis une analyse g√©opolitique au format Markdown avec les sections suivantes :

### üåç Analyse G√©opolitique : {focus}
- **Sentiment G√©opolitique :** (Stabilisant, D√©stabilisant, Neutre)
- **Niveau de Risque (1-10) :** (Impact sur la stabilit√© g√©opolitique)
- **Justification :** (Explique les m√©canismes g√©opolitiques en jeu)

### üó∫Ô∏è Implications R√©gionales
- **R√©gions affect√©es :** (Zones g√©ographiques principales concern√©es)
- **Acteurs cl√©s :** (Pays, institutions, alliances impliqu√©s)
- **Tensions potentielles :** (Nouveaux conflits ou r√©solutions possibles)

### üí∞ Impact sur les March√©s
- **Devises affect√©es :** (Monnaies qui pourraient √™tre impact√©es)
- **Secteurs sensibles :** (Industries particuli√®rement expos√©es)
- **Flux de capitaux :** (R√©allocations d'investissement attendues)

### üéØ Recommandations Strat√©giques
- **Positionnement recommand√© :** (D√©fensif, Offensif, Neutre)
- **Horizon d'impact :** (Court/Moyen/Long terme)
- **Indicateurs √† surveiller :** (Signaux d'alerte ou d'opportunit√©)
""",
)

# Agent Investisseur Final - Le superviseur qui prend la d√©cision finale
investisseur_final_template = PromptTemplate(
    input_variables=["debriefing_equipe", "capital_disponible", "actionable_tickers"],
    template="""
Tu es l'Agent Investisseur en chef du fonds BERZERK. Tu es froid, logique, et uniquement guid√© par la performance et la gestion du risque.

Ta mission est de prendre la d√©cision finale d'investissement bas√©e sur le rapport consolid√© de ton √©quipe d'analystes sp√©cialis√©s.

**Tickers Identifi√©s par le Ticker Hunter :**
{actionable_tickers}

**Rapport de l'√âquipe d'Analystes :**
---
{debriefing_equipe}
---

**Contexte Financier Actuel :**
- Capital total disponible pour de nouveaux trades : {capital_disponible} ‚Ç¨

**TACHE FINALE :**
Sur la base EXCLUSIVE des informations ci-dessus, produis une d√©cision d'investissement structur√©e au format JSON. Ne rien ajouter d'autre.

**PRIORIT√â :** Concentre-toi sur les tickers sp√©cifiques identifi√©s par le Ticker Hunter. Ignore les analyses macro g√©n√©rales.

Le format JSON doit contenir les cl√©s suivantes :
- "decision": "ACHETER", "VENDRE", "SURVEILLER" ou "IGNORER".
- "ticker": Le ticker de l'action concern√©e (string, ou null si IGNORER).
- "confiance": "√âLEV√âE", "MOYENNE", "FAIBLE" (string).
- "horizon": "Court Terme", "Moyen Terme", ou "Long Terme". D√âDUIS-LE du rapport.
- "justification_synthetique": Une phrase unique et directe expliquant la d√©cision.
- "allocation_capital_pourcentage": Le pourcentage du capital disponible √† allouer √† ce trade (nombre flottant, de 0.0 √† 5.0). Allouer 0 si la d√©cision n'est pas "ACHETER". Une allocation typique pour une confiance MOYENNE est 1%, √âLEV√âE est 2-3%.
- "points_cles_positifs": Une liste de 2-3 points cl√©s positifs tir√©s du rapport.
- "points_cles_negatifs_risques": Une liste de 2-3 risques ou points n√©gatifs tir√©s du rapport.
""",
)

# Dictionnaire des profils d'agents
AGENT_PROFILES = {
    "ticker_hunter": ticker_hunter_template,
    "analyste_actions": analyste_actions_template,
    "analyste_sectoriel": analyste_sectoriel_template,
    "strategiste_geopolitique": strategiste_geopolitique_template,
    "investisseur_final": investisseur_final_template,
}

# --- FONCTIONS PRINCIPALES ---


def route_to_agents(entities: list[str], news_summary: str) -> list[dict[str, str]]:
    """
    Routeur intelligent qui s√©lectionne les agents appropri√©s selon les entit√©s d√©tect√©es.

    Args:
        entities: Liste des entit√©s d√©tect√©es (tickers, secteurs, concepts)
        news_summary: R√©sum√© de la news

    Returns:
        Liste de dictionnaires avec agent_type et focus pour chaque agent s√©lectionn√©
    """
    if not llm:
        print("‚ùå LLM non disponible pour le routage")
        return []

    # Prompt pour le routeur intelligent
    router_template = PromptTemplate(
        input_variables=["entities", "news_summary", "available_agents"],
        template="""
Tu es le Chef d'Orchestre du syst√®me d'analyse BERZERK. Ta mission est de s√©lectionner
la meilleure √©quipe d'agents IA pour analyser une news financi√®re.

**Agents disponibles :**
{available_agents}

**Entit√©s d√©tect√©es dans la news :**
{entities}

**R√©sum√© de la news :**
{news_summary}

**Instructions :**
1. Analyse les entit√©s et le contenu de la news
2. S√©lectionne 1 √† 3 agents maximum (√©vite la redondance)
3. Pour chaque agent, d√©finis un focus pr√©cis bas√© sur les entit√©s

**Crit√®res de s√©lection :**
- **analyste_actions** : Si des tickers d'actions sp√©cifiques sont mentionn√©s (ex: AAPL, TSLA)
- **analyste_sectoriel** : Si des secteurs d'activit√© sont concern√©s (ex: Tech, Pharma, √ânergie)
- **strategiste_geopolitique** : Si des aspects g√©opolitiques, mon√©taires ou macro√©conomiques sont pr√©sents

**Format de r√©ponse attendu (JSON strict) :**
{{
    "agents": [
        {{"agent_type": "analyste_actions", "focus": "AAPL"}},
        {{"agent_type": "analyste_sectoriel", "focus": "Technologie"}},
        {{"agent_type": "strategiste_geopolitique", "focus": "Relations commerciales USA-Chine"}}
    ]
}}

Assure-toi que chaque focus soit sp√©cifique et pertinent pour l'agent s√©lectionn√©.
""",
    )

    try:
        # Pr√©paration des donn√©es
        available_agents = """
- analyste_actions : Analyse d'actions individuelles et de tickers sp√©cifiques
- analyste_sectoriel : Analyse de secteurs d'activit√© et industries
- strategiste_geopolitique : Analyse g√©opolitique et macro√©conomique
"""

        # Configuration du parser JSON
        parser = JsonOutputParser(pydantic_object=AgentSelection)

        # Cr√©ation de la cha√Æne LangChain
        chain = router_template | llm | parser

        # Ex√©cution du routage
        result = chain.invoke(
            {
                "entities": ", ".join(entities),
                "news_summary": news_summary,
                "available_agents": available_agents,
            }
        )

        selected_agents = result.get("agents", [])
        print(f"‚úÖ Routeur : {len(selected_agents)} agent(s) s√©lectionn√©(s)")

        return selected_agents

    except Exception as e:
        print(f"‚ùå Erreur dans le routage des agents: {e}")
        # Fallback : s√©lection basique bas√©e sur les entit√©s
        fallback_agents = []

        # Recherche de tickers (g√©n√©ralement en majuscules, 2-5 caract√®res)
        tickers = [
            entity for entity in entities if entity.isupper() and 2 <= len(entity) <= 5
        ]
        if tickers:
            fallback_agents.append(
                {"agent_type": "analyste_actions", "focus": tickers[0]}
            )

        # Recherche de secteurs (mots-cl√©s courants)
        secteurs = [
            "tech",
            "technologie",
            "√©nergie",
            "finance",
            "sant√©",
            "pharma",
            "automobile",
        ]
        for entity in entities:
            if any(secteur in entity.lower() for secteur in secteurs):
                fallback_agents.append(
                    {"agent_type": "analyste_sectoriel", "focus": entity}
                )
                break

        return fallback_agents


def run_agent_analysis(
    agent_type: str, focus: str, news_summary: str, full_article_text: str
) -> str:
    """
    Ex√©cute l'analyse d'un agent sp√©cifique.

    Args:
        agent_type: Type d'agent (cl√© du dictionnaire AGENT_PROFILES)
        focus: Focus sp√©cifique pour l'analyse
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article

    Returns:
        Analyse format√©e en Markdown ou message d'erreur
    """
    if not llm:
        return "‚ùå **Erreur :** LLM non disponible pour l'analyse"

    if agent_type not in AGENT_PROFILES:
        return f"‚ùå **Erreur :** Agent '{agent_type}' non reconnu"

    try:
        # R√©cup√©ration du template de l'agent
        agent_prompt = AGENT_PROFILES[agent_type]

        # Cr√©ation de la cha√Æne LangChain
        chain = agent_prompt | llm

        # Ex√©cution de l'analyse
        analysis_result = chain.invoke(
            {
                "focus": focus,
                "news_summary": news_summary,
                "full_article_text": full_article_text,
            }
        )

        print(f"‚úÖ Analyse termin√©e - Agent: {agent_type}, Focus: {focus}")
        return (
            analysis_result.content
            if hasattr(analysis_result, "content")
            else str(analysis_result)
        )

    except Exception as e:
        error_msg = f"‚ùå **Erreur lors de l'analyse** - Agent: {agent_type}, Focus: {focus}\n**D√©tail:** {str(e)}"
        print(error_msg)
        return error_msg


def run_ticker_hunter(
    news_summary: str, full_article_text: str
) -> dict[str, list[dict]]:
    """
    Ex√©cute l'agent Ticker Hunter pour identifier les tickers actionnables.

    Args:
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article

    Returns:
        Dictionnaire avec la liste des tickers identifi√©s
    """
    if not llm:
        print("‚ùå LLM non disponible pour le Ticker Hunter")
        return {"tickers_identifies": []}

    try:
        # Configuration du parser JSON avec validation Pydantic
        parser = JsonOutputParser(pydantic_object=TickerHunterResult)

        # R√©cup√©ration du template du Ticker Hunter
        ticker_hunter_prompt = AGENT_PROFILES["ticker_hunter"]

        # Cr√©ation de la cha√Æne LangChain
        chain = ticker_hunter_prompt | llm | parser

        # Ex√©cution de l'analyse
        result = chain.invoke(
            {"news_summary": news_summary, "full_article_text": full_article_text}
        )

        tickers_found = result.get("tickers_identifies", [])
        print(f"‚úÖ Ticker Hunter : {len(tickers_found)} ticker(s) identifi√©(s)")

        if tickers_found:
            for ticker_info in tickers_found:
                # Gestion des objets Pydantic ET des dictionnaires
                if hasattr(ticker_info, "ticker"):
                    ticker = ticker_info.ticker
                    company = ticker_info.nom_entreprise
                else:
                    ticker = ticker_info.get("ticker", "N/A")
                    company = ticker_info.get("nom_entreprise", "N/A")
                print(f"   üéØ {ticker} - {company}")

        return result

    except Exception as e:
        print(f"‚ùå Erreur dans le Ticker Hunter: {e}")
        return {"tickers_identifies": []}


# --- AGENTS AUGMENT√âS (AVEC OUTILS) ---


def create_augmented_analyst(focus_ticker: str = None) -> AgentExecutor:
    """
    Cr√©e un agent analyste augment√© avec acc√®s √† des outils web et financiers.

    Args:
        focus_ticker: Ticker √† analyser en priorit√© (optionnel)

    Returns:
        AgentExecutor configur√© avec les outils
    """
    if not llm:
        raise ValueError("LLM non disponible pour cr√©er l'agent augment√©")

    # D√©finition des outils disponibles
    tools = []

    # Ajout des outils disponibles
    if web_search_tool:
        tools.append(web_search_tool)

    tools.extend([get_stock_price, get_market_sentiment])

    # Prompt syst√®me pour l'agent augment√©
    focus_instruction = (
        f" Tu te concentres principalement sur {focus_ticker}." if focus_ticker else ""
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                f"""Tu es un analyste financier expert du fonds BERZERK avec acc√®s √† des outils temps r√©el.{focus_instruction}

**Tes outils disponibles :**
- web_search_tool : Recherche d'informations compl√©mentaires sur le web
- get_stock_price : Prix actuel et variation des actions
- get_market_sentiment : Informations sur capitalisation, P/E, volume

**Ton processus d'analyse :**
1. Analyse d'abord la news fournie
2. Utilise tes outils pour v√©rifier le contexte actuel du march√©
3. Recherche des informations compl√©mentaires si n√©cessaire
4. Produis une analyse compl√®te et nuanc√©e

**R√®gles importantes :**
- Utilise tes outils de mani√®re strat√©gique (pas syst√©matiquement)
- Mentionne si le march√© a d√©j√† r√©agi √† la news
- Contextualise tes recommandations avec les donn√©es temps r√©el
- Sois pr√©cis et actionnable dans tes conclusions""",
            ),
            ("user", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ]
    )

    # Cr√©ation de l'agent
    agent = create_tool_calling_agent(llm, tools, prompt)

    # Cr√©ation de l'ex√©cuteur
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,  # Pour voir le processus de r√©flexion
        max_iterations=5,  # Limiter les it√©rations pour √©viter les boucles
        early_stopping_method="generate",  # Arr√™t anticip√© si n√©cessaire
    )

    return agent_executor


def run_augmented_analysis(
    ticker: str, news_summary: str, full_article_text: str
) -> str:
    """
    Ex√©cute une analyse augment√©e avec acc√®s aux outils externes.

    Args:
        ticker: Ticker √† analyser
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article

    Returns:
        Analyse compl√®te avec donn√©es temps r√©el
    """
    try:
        # Cr√©ation de l'agent augment√© pour ce ticker
        agent_executor = create_augmented_analyst(focus_ticker=ticker)

        # Pr√©paration de la requ√™te
        query = f"""
        Analyse l'impact de cette news sur l'action {ticker}.

        **R√©sum√© de la news :**
        {news_summary}

        **Texte complet :**
        {full_article_text[:2000]}...  # Limitation pour √©viter les tokens excessifs

        **Ta mission :**
        1. V√©rifie le prix actuel et la variation de {ticker}
        2. Recherche des informations compl√©mentaires si n√©cessaire
        3. √âvalue si le march√© a d√©j√† int√©gr√© cette news
        4. Produis une recommandation d'investissement pr√©cise

        Utilise tes outils pour avoir une vision compl√®te du contexte actuel !
        """

        # Ex√©cution de l'analyse
        result = agent_executor.invoke({"input": query})

        return result.get("output", "Erreur dans l'analyse augment√©e")

    except Exception as e:
        return f"‚ùå **Erreur dans l'analyse augment√©e :** {str(e)}"


# --- AGENTS PURE PREDICTION (MODE BERZERK TAC AU TAC) ---


def create_pure_prediction_analyst(focus_ticker: str = None) -> AgentExecutor:
    """
    Cr√©e un agent analyste "pur" qui se base UNIQUEMENT sur l'analyse textuelle
    et le contexte web, sans acc√®s aux donn√©es de prix en temps r√©el.

    Args:
        focus_ticker: Ticker √† analyser en priorit√© (optionnel)

    Returns:
        AgentExecutor configur√© sans outils financiers
    """
    if not llm:
        raise ValueError("LLM non disponible pour cr√©er l'agent de pr√©diction pure")

    # Outils disponibles : UNIQUEMENT la recherche web pour le contexte qualitatif
    tools = []
    if web_search_tool:
        tools.append(web_search_tool)

    focus_instruction = (
        f" Tu te concentres principalement sur {focus_ticker}." if focus_ticker else ""
    )

    # Un prompt enti√®rement r√©orient√© vers la pr√©diction
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                f"""Tu es un analyste financier visionnaire pour le fonds BERZERK. Ta mission est de pr√©dire l'impact FUTUR d'une news, SANS te soucier de la r√©action pass√©e du march√©. Tu agis "tac au tac".{focus_instruction}

**Ton seul outil disponible :**
- web_search_tool : Pour obtenir plus de contexte QUALITATIF sur la news (produits, concurrents, technologie).

**Ton processus de pr√©diction :**
1. Analyse en profondeur la news fournie.
2. Si n√©cessaire, utilise la recherche web pour comprendre le contexte (ex: "Qu'est-ce que la technologie X mentionn√©e ?"). N'UTILISE PAS la recherche pour les prix.
3. Sur la base EXCLUSIVE de l'information et de son contexte, produis une pr√©diction d'impact et une recommandation d'action imm√©diate.

**R√®gles CRITIQUES :**
- IGNORE TOTALEMENT si le march√© a d√©j√† r√©agi ou non.
- Ta d√©cision doit √™tre une PURE PR√âDICTION bas√©e sur le potentiel de la news.
- Sois d√©cisif et direct. Le but est d'agir avant tout le monde.
- Base tes recommandations sur l'impact business fondamental pr√©dit.""",
            ),
            ("user", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ]
    )

    # Cr√©ation de l'agent
    agent = create_tool_calling_agent(llm, tools, prompt)

    # Cr√©ation de l'ex√©cuteur
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,  # Pour voir le processus de r√©flexion
        max_iterations=4,  # Moins d'it√©rations pour √™tre plus rapide
        early_stopping_method="generate",  # Arr√™t anticip√© si n√©cessaire
    )

    return agent_executor


def run_pure_prediction_analysis(
    ticker: str, news_summary: str, full_article_text: str
) -> str:
    """
    Ex√©cute une analyse de pr√©diction pure sans donn√©es de march√© historiques.

    Args:
        ticker: Ticker √† analyser
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article

    Returns:
        Analyse de pr√©diction pure
    """
    try:
        # Cr√©ation de l'agent de pr√©diction pure pour ce ticker
        agent_executor = create_pure_prediction_analyst(focus_ticker=ticker)

        # Pr√©paration de la requ√™te orient√©e pr√©diction
        query = f"""
        Analyse l'impact pr√©dictif de cette news sur l'action {ticker}.

        **R√©sum√© de la news :**
        {news_summary}

        **Texte complet :**
        {full_article_text[:2000]}...

        **Ta mission PURE PREDICTION :**
        1. √âvalue la magnitude de cette information sur le business futur.
        2. D√©termine le sentiment pr√©dictif (tr√®s positif, positif, neutre, n√©gatif, tr√®s n√©gatif).
        3. Produis une recommandation d'action imm√©diate (Acheter, Vendre, Surveiller) et une justification bas√©e sur ta pr√©diction.
        4. Si n√©cessaire, recherche des informations contextuelles qualitatives (technologie, secteur, concurrence).

        INTERDIT : Aucune donn√©e de prix, volume ou r√©action de march√©. Ta d√©cision doit √™tre instantan√©e et visionnaire.
        """

        # Ex√©cution de l'analyse
        result = agent_executor.invoke({"input": query})

        return result.get("output", "Erreur dans l'analyse de pr√©diction pure.")

    except Exception as e:
        return f"‚ùå **Erreur dans l'analyse de pr√©diction pure :** {str(e)}"


# --- FONCTIONS UTILITAIRES ---


def get_available_agents() -> list[str]:
    """Retourne la liste des agents disponibles."""
    return list(AGENT_PROFILES.keys())


def get_agent_description(agent_type: str) -> str:
    """Retourne une description d'un agent sp√©cifique."""
    descriptions = {
        "analyste_actions": "Sp√©cialis√© dans l'analyse d'actions individuelles et de tickers sp√©cifiques",
        "analyste_sectoriel": "Expert en analyse de secteurs d'activit√© et dynamiques industrielles",
        "strategiste_geopolitique": "Sp√©cialis√© dans l'analyse g√©opolitique et macro√©conomique",
    }
    return descriptions.get(agent_type, "Agent non reconnu")


# --- FONCTION DE TEST ---


def test_agents_module():
    """Fonction de test pour v√©rifier le bon fonctionnement du module."""
    print("üß™ Test du module agents.py")
    print("-" * 50)

    # Test 1: V√©rification des profils
    print(f"‚úÖ {len(AGENT_PROFILES)} profils d'agents charg√©s")
    for agent_type in AGENT_PROFILES.keys():
        print(f"   - {agent_type}: {get_agent_description(agent_type)}")

    # Test 2: Test du routeur
    test_entities = ["AAPL", "TSLA", "Technologie", "Intelligence Artificielle"]
    test_summary = "Apple et Tesla annoncent un partenariat dans l'IA automobile"

    print(f"\nüîÄ Test du routeur avec entit√©s: {test_entities}")
    selected_agents = route_to_agents(test_entities, test_summary)
    print(f"‚úÖ Agents s√©lectionn√©s: {selected_agents}")

    print("\nüéØ Module agents.py pr√™t √† l'emploi !")


if __name__ == "__main__":
    test_agents_module()
</file>

<file path="berzerk_dashboard.py">
#!/usr/bin/env python3
"""
‚ö° BERZERK - Decision Feed
========================

Interface √©pur√©e "Clart√© Radicale" pour le suivi des d√©cisions d'investissement IA.
Philosophie : Priorit√© √† l'action, simplicit√©, hi√©rarchie claire.

Auteur: BERZERK Team
Phase: 8.1 - Ajout du suivi de performance instantan√©
"""

import hashlib
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Any

import plotly.graph_objects as go
import streamlit as st
import yfinance as yf

# Configuration de la page
st.set_page_config(
    page_title="BERZERK Decision Feed",
    page_icon="‚ö°",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# --- NOUVELLES FONCTIONS DE PERFORMANCE ---


@st.cache_data(ttl=86400)  # Cache de 1 jour, car ce prix historique ne changera pas.
def get_price_at_decision_time(ticker: str, decision_time_str: str) -> float:
    """
    R√©cup√®re le prix de cl√¥ture du jour de la d√©cision (ou du jour pr√©c√©dent si march√© ferm√©).
    Cette m√©thode est extr√™mement rapide car elle n'utilise que des donn√©es journali√®res.
    """
    ticker = ticker.strip().replace("$", "")
    if not ticker:
        return 0.0

    try:
        decision_dt = datetime.fromisoformat(decision_time_str.replace("Z", "+00:00"))
        decision_date = decision_dt.date()

        stock = yf.Ticker(ticker)

        # On t√©l√©charge une petite plage de donn√©es journali√®res autour de la date de d√©cision. C'est tr√®s rapide.
        hist = stock.history(
            start=decision_date - timedelta(days=7),
            end=decision_date + timedelta(days=1),
        )

        if hist.empty:
            return 0.0

        # On cherche les donn√©es pour le jour exact de la d√©cision
        day_data = hist[hist.index.date == decision_date]

        # CAS 1: Le march√© √©tait ouvert ce jour-l√†. On prend le prix de cl√¥ture.
        if not day_data.empty:
            return float(day_data["Close"].iloc[0])

        # CAS 2: Le march√© √©tait ferm√© (weekend/jour f√©ri√©). On prend la cl√¥ture du jour d'avant.
        else:
            previous_days_data = hist[hist.index.date < decision_date]
            if not previous_days_data.empty:
                return float(previous_days_data["Close"].iloc[-1])

        return 0.0
    except Exception:
        return 0.0


@st.cache_data(ttl=60)  # Cache 1 minute pour les prix actuels
def get_current_price(ticker: str) -> float:
    """R√©cup√®re le prix actuel d'une action via yfinance (version robuste)."""
    ticker = ticker.strip().replace("$", "")  # Nettoyage du ticker
    if not ticker:
        return 0.0

    try:
        stock = yf.Ticker(ticker)
        data = stock.history(
            period="1d", interval="1m"
        )  # On prend la derni√®re minute pour le prix le plus r√©cent
        if not data.empty:
            return float(data["Close"].iloc[-1])

        # Fallback si les donn√©es intraday ne sont pas dispo
        price = stock.info.get("regularMarketPrice")
        if price:
            return float(price)

        return 0.0
    except Exception:
        # Gestion silencieuse des erreurs
        return 0.0


# --- FONCTIONS EXISTANTES (MODIFI√âES ET CONSERV√âES) ---


def display_confidence_signal(confidence: str):
    """Affiche un indicateur visuel de force du signal."""
    confidence_map = {"√âLEV√âE": 3, "MOYENNE": 2, "FAIBLE": 1}
    level = confidence_map.get(confidence.upper(), 0)

    bars = "".join(
        [
            f'<div class="signal-bar {"filled" if i < level else ""}"></div>'
            for i in range(3)
        ]
    )

    st.markdown(
        f"""
        <div class="signal-container">
            <div class="signal-bars">{bars}</div>
            <span class="signal-text">{confidence.capitalize()}</span>
        </div>
    """,
        unsafe_allow_html=True,
    )


@st.cache_data(ttl=900)  # Cache de 15 minutes pour les graphiques
def get_sparkline_chart(ticker: str):
    """G√©n√®re un mini-graphique (sparkline) avec couleur de tendance."""
    ticker = ticker.strip().replace("$", "")  # Nettoyage du ticker
    if not ticker:
        return None, "N/A"

    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="7d", interval="1d")

        if len(hist) < 2:
            return None, "N/A"

        start_price = hist["Close"].iloc[0]
        end_price = hist["Close"].iloc[-1]

        color = "#28a745" if end_price > start_price else "#dc3545"
        fill_color = (
            "rgba(40, 167, 69, 0.1)"
            if end_price > start_price
            else "rgba(220, 53, 69, 0.1)"
        )
        trend = "Haussier" if end_price > start_price else "Baissier"

        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                x=hist.index,
                y=hist["Close"],
                mode="lines",
                line={"color": color, "width": 2.5},
                fill="tozeroy",
                fillcolor=fill_color,
            )
        )
        fig.update_layout(
            height=50,
            margin={"l": 0, "r": 0, "t": 5, "b": 0},
            xaxis={"visible": False},
            yaxis={"visible": False},
            paper_bgcolor="rgba(0,0,0,0)",
            plot_bgcolor="rgba(0,0,0,0)",
            showlegend=False,
        )
        return fig, trend
    except Exception:
        # Gestion silencieuse des erreurs
        return None, "N/A"


@st.cache_data(ttl=60)  # Cache de 60 secondes
def load_decisions_from_db() -> list[dict[str, Any]]:
    """Charge les d√©cisions depuis la DB et les enrichit avec les donn√©es de performance."""
    try:
        conn = sqlite3.connect("berzerk.db")
        cursor = conn.cursor()

        cursor.execute(
            """
            SELECT title, link, published_date, decision_json, analyzed_at
            FROM articles
            WHERE decision_json IS NOT NULL AND status = 'analyzed'
            AND analyzed_at >= datetime('now', '-30 days')
            ORDER BY analyzed_at DESC
        """
        )

        rows = cursor.fetchall()
        conn.close()

        decisions = []
        for title, link, _published_date, decision_json, analyzed_at in rows:
            try:
                decision_data = json.loads(decision_json)
                action = decision_data.get(
                    "action", decision_data.get("decision", "INCONNUE")
                ).upper()
                ticker = decision_data.get("ticker", None)

                if action == "INCONNUE" or not ticker:
                    continue

                # Cr√©er un identifiant unique bas√© sur analyzed_at pour √©viter les cl√©s dupliqu√©es
                unique_id = hashlib.md5(f"{analyzed_at}_{link}".encode()).hexdigest()[
                    :8
                ]

                # --- ENRICHISSEMENT AVEC DONN√âES DE PERFORMANCE ---
                prix_decision = get_price_at_decision_time(ticker, analyzed_at)
                prix_actuel = get_current_price(ticker)

                decision = {
                    "action": action,
                    "ticker": ticker,
                    "unique_id": unique_id,  # Identifiant unique pour √©viter les doublons
                    "nom_entreprise": decision_data.get(
                        "nom_entreprise", f"Entreprise {ticker}"
                    ),
                    "news_title": title,
                    "analyzed_at": analyzed_at,
                    # NOUVELLES DONN√âES DE PERFORMANCE
                    "prix_decision": prix_decision,
                    "prix_actuel": prix_actuel,
                    # ---
                    "justification": decision_data.get(
                        "justification_synthetique",
                        decision_data.get(
                            "justification", "Analyse automatique BERZERK"
                        ),
                    ),
                    "points_positifs": decision_data.get(
                        "points_cles_positifs", ["Analyse favorable"]
                    ),
                    "points_negatifs": decision_data.get(
                        "points_cles_negatifs_risques", ["Risques standards"]
                    ),
                    "allocation_pct": decision_data.get(
                        "allocation_capital_pourcentage",
                        decision_data.get("allocation_pourcentage", 0.0),
                    ),
                    "confiance": decision_data.get("confiance", "MOYENNE"),
                    "horizon": decision_data.get("horizon", "Court Terme"),
                    "article_link": link,
                }
                decisions.append(decision)

            except (json.JSONDecodeError, KeyError) as e:
                print(f"Erreur parsing JSON pour '{title}': {e}")
                continue

        return decisions

    except Exception as e:
        st.error(f"Erreur critique chargement donn√©es : {e}")
        return []


def get_sample_decisions() -> list[dict[str, Any]]:
    """G√©n√®re des d√©cisions d'exemple pour la d√©monstration (avec donn√©es de performance)."""
    return [
        {
            "action": "ACHETER",
            "ticker": "AAPL",
            "unique_id": "sample001",
            "nom_entreprise": "Apple Inc.",
            "news_title": "Apple annonce des avanc√©es majeures dans l'IA pour l'iPhone 17.",
            "analyzed_at": "2024-12-07T14:32:00",
            "prix_decision": 195.50,
            "prix_actuel": get_current_price("AAPL"),
            "justification": "L'annonce d'une nouvelle puce IA devrait booster les ventes et donner un avantage concurrentiel significatif √† Apple sur le march√© des smartphones.",
            "points_positifs": [
                "Avantage concurrentiel IA",
                "Cycle de remplacement acc√©l√©r√©",
                "Marges √©lev√©es",
            ],
            "points_negatifs": [
                "Risques d'ex√©cution",
                "Valorisation d√©j√† √©lev√©e",
                "Concurrence intense",
            ],
            "allocation_pct": 2.5,
            "confiance": "√âLEV√âE",
            "horizon": "Moyen Terme",
            "article_link": "https://example.com/apple-ai-news",
        },
        {
            "action": "VENDRE",
            "ticker": "XOM",
            "unique_id": "sample002",
            "nom_entreprise": "ExxonMobil Corporation",
            "news_title": "OPEC+ augmente la production, craintes de surabondance p√©troli√®re",
            "analyzed_at": "2024-12-07T12:15:00",
            "prix_decision": 118.75,
            "prix_actuel": get_current_price("XOM"),
            "justification": "La surabondance de l'offre p√©troli√®re et les craintes sur la demande exercent une pression baissi√®re directe sur la rentabilit√© future de XOM.",
            "points_positifs": ["Dividende stable", "Gestion financi√®re solide"],
            "points_negatifs": [
                "Pression sur les prix du p√©trole",
                "Surabondance de l'offre",
                "Demande incertaine",
            ],
            "allocation_pct": 0.0,
            "confiance": "MOYENNE",
            "horizon": "Court Terme",
            "article_link": "https://example.com/opec-oil-news",
        },
        {
            "action": "SURVEILLER",
            "ticker": "NVDA",
            "unique_id": "sample003",
            "nom_entreprise": "NVIDIA Corporation",
            "news_title": "NVIDIA pr√©sente ses nouveaux processeurs IA de nouvelle g√©n√©ration",
            "analyzed_at": "2024-12-07T10:45:00",
            "prix_decision": 485.20,
            "prix_actuel": get_current_price("NVDA"),
            "justification": "Innovation prometteuse mais valorisation d√©j√† √©lev√©e. Attendre une correction pour une meilleure opportunit√© d'entr√©e.",
            "points_positifs": [
                "Leadership IA",
                "Innovation continue",
                "Demande croissante",
            ],
            "points_negatifs": [
                "Valorisation excessive",
                "Volatilit√© √©lev√©e",
                "D√©pendance cyclique",
            ],
            "allocation_pct": 1.0,
            "confiance": "FAIBLE",
            "horizon": "Long Terme",
            "article_link": "https://example.com/nvidia-ai-news",
        },
    ]


def display_decision_card(decision: dict[str, Any]):
    """Affiche une carte de d√©cision 2.1 avec suivi de performance int√©gr√©."""
    action = decision["action"]
    color_map = {
        "ACHETER": "#28a745",
        "VENDRE": "#dc3545",
        "SURVEILLER": "#ffc107",
        "IGNORER": "#6c757d",
    }

    with st.container(border=True):

        # === EN-T√äTE INT√âGR√â (INFO + GRAPHIQUE) ===
        header_cols = st.columns([1, 2.5, 2])

        with header_cols[0]:
            # Badge d'action
            st.markdown(
                f"""
                <div style="background-color: {color_map.get(action, '#6c757d')}; color: white; padding: 12px; text-align: center; border-radius: 8px; font-weight: bold; font-size: 1.1rem; height: 100%;">
                    {action}
                </div>
            """,
                unsafe_allow_html=True,
            )

        with header_cols[1]:
            # Ticker, Nom et News
            st.subheader(f"{decision['ticker']} - {decision['nom_entreprise']}")
            st.write(f"_{decision['news_title']}_")
            analyzed_dt = datetime.fromisoformat(
                decision["analyzed_at"].replace("Z", "+00:00")
            )
            st.caption(f"Analyse du {analyzed_dt.strftime('%d/%m/%y %H:%M')}")

        with header_cols[2]:
            # Sparkline avec cl√© unique
            sparkline_fig, trend = get_sparkline_chart(decision["ticker"])
            if sparkline_fig:
                # Cl√© unique utilisant ticker + unique_id pour √©viter les doublons
                unique_key = f"sparkline_{decision['ticker']}_{decision['unique_id']}"
                st.plotly_chart(sparkline_fig, use_container_width=True, key=unique_key)
                st.caption(f"Tendance 7J: {trend}")
            else:
                st.caption("Tendance 7J: Donn√©es indisponibles")

        # --- NOUVELLE SECTION : SUIVI DE PERFORMANCE (AVEC CONDITION) ---
        # On affiche la performance SEULEMENT si on a un prix de d√©cision valide (> 0)
        if decision["prix_decision"] > 0 and decision["prix_actuel"] > 0:
            st.markdown("---")
            st.markdown(
                '<div class="key-indicator-title" style="text-align:left; margin-bottom: 0.5rem;">üìä Suivi de la Position</div>',
                unsafe_allow_html=True,
            )

            perf_cols = st.columns(3)

            # Calcul de la performance
            perf_pct = 0
            if decision["action"] == "ACHETER":
                perf_pct = (
                    (decision["prix_actuel"] - decision["prix_decision"])
                    / decision["prix_decision"]
                ) * 100
            elif decision["action"] == "VENDRE":  # Vente √† d√©couvert
                perf_pct = (
                    (decision["prix_decision"] - decision["prix_actuel"])
                    / decision["prix_decision"]
                ) * 100


            with perf_cols[0]:
                st.metric("Prix √† la d√©cision", f"{decision['prix_decision']:.2f} $")
            with perf_cols[1]:
                st.metric("Prix actuel", f"{decision['prix_actuel']:.2f} $")
            with perf_cols[2]:
                # On remplace le conteneur de performance par une m√©trique standard pour un meilleur alignement
                st.metric(
                    "Performance",
                    f"{perf_pct:+.2f}%",
                    delta_color="normal" if perf_pct >= 0 else "inverse",
                )

        st.markdown("---")
        # --- FIN DE LA SECTION MODIFI√âE ---

        # === INDICATEURS CL√âS ===
        kpi_cols = st.columns(3)

        # R√©cup√©ration du secteur via yfinance (gestion silencieuse des erreurs)
        sector = "N/A"
        try:
            stock_info = yf.Ticker(decision["ticker"]).info
            sector = stock_info.get("sector", "N/A")
        except Exception:
            pass

        with kpi_cols[0]:
            st.markdown(
                '<div class="key-indicator-title">Force du Signal</div>',
                unsafe_allow_html=True,
            )
            display_confidence_signal(decision.get("confiance", "INCONNUE"))

        with kpi_cols[1]:
            st.markdown(
                '<div class="key-indicator-title">Horizon</div>', unsafe_allow_html=True
            )
            st.markdown(
                f'<div class="key-indicator-value">{decision.get("horizon", "N/A")}</div>',
                unsafe_allow_html=True,
            )

        with kpi_cols[2]:
            st.markdown(
                '<div class="key-indicator-title">Secteur</div>', unsafe_allow_html=True
            )
            st.markdown(
                f'<div class="key-indicator-value">{sector}</div>',
                unsafe_allow_html=True,
            )

        # === EXPANDER POUR LES D√âTAILS ===
        with st.expander("‚ñº Voir le raisonnement de l'IA et les d√©tails"):
            st.markdown("#### Justification de l'IA")
            st.write(decision["justification"])
            st.markdown("---")
            col_pos, col_neg = st.columns(2)
            with col_pos:
                st.markdown("‚úÖ **Points Cl√©s Positifs**")
                for point in decision["points_positifs"]:
                    st.write(f"‚Ä¢ {point}")
            with col_neg:
                st.markdown("‚ö†Ô∏è **Risques & Points N√©gatifs**")
                for point in decision["points_negatifs"]:
                    st.write(f"‚Ä¢ {point}")
            if decision["action"] == "ACHETER":
                st.info(
                    f"üí° Allocation Sugg√©r√©e: {decision['allocation_pct']}% du capital de trading."
                )
            st.link_button("Consulter l'article original ‚Üó", decision["article_link"])


def main():
    """Fonction principale de l'interface Decision Feed."""

    # === STYLES CSS ENRICHIS ===
    st.markdown(
        """
        <style>
        /* STYLES EXISTANTS POUR LA CARTE AM√âLIOR√âE */
        .signal-container {
            display: flex;
            align-items: center;
            gap: 8px;
        }
        .signal-bars {
            display: flex;
            align-items: flex-end;
            gap: 2px;
        }
        .signal-bar {
            width: 6px;
            background-color: #e0e0e0;
            border-radius: 2px;
        }
        .signal-bar:nth-child(1) { height: 8px; }
        .signal-bar:nth-child(2) { height: 12px; }
        .signal-bar:nth-child(3) { height: 16px; }
        .signal-bar.filled {
            background-color: #34a853;
        }
        .signal-text {
            font-size: 0.9rem;
            font-weight: 500;
        }
        .key-indicator-title {
            font-size: 0.8rem;
            color: #5f6368;
            margin-bottom: 0.3rem;
            text-transform: uppercase;
        }
        .key-indicator-value {
            font-size: 1rem;
            font-weight: 600;
            color: #202124;
        }

        /* NOUVEAUX STYLES POUR LA PERFORMANCE */
        .perf-container {
            border: 1px solid #e0e0e0;
            border-radius: 0.5rem;
            padding: 0.8rem 1rem;
            text-align: center;
            background-color: #f8f9fa;
        }
        .perf-label {
            font-size: 0.75rem;
            color: #5f6368;
            margin-bottom: 0.25rem;
            text-transform: uppercase;
            font-weight: 500;
        }
        .perf-value {
            font-size: 1.2rem;
            font-weight: 700;
        }
        .perf-positive { color: #1e8e3e; }
        .perf-negative { color: #d93025; }
        </style>
    """,
        unsafe_allow_html=True,
    )

    # === EN-T√äTE ===
    st.title("‚ö° BERZERK - Decision Feed")
    st.caption("Analyse IA. D√©cisions Imm√©diates. Suivi de Performance Temps R√©el.")

    # === BARRE DE STATUT ===
    stat_col1, stat_col2, stat_col3 = st.columns(3)

    # Charger les d√©cisions
    decisions = load_decisions_from_db()

    # Si pas de donn√©es r√©elles, utiliser les exemples
    if not decisions:
        st.warning("üîÑ Aucune d√©cision r√©cente dans la base. Affichage des exemples.")
        decisions = get_sample_decisions()

    # Calculs pour les statistiques
    now = datetime.now()
    decisions_24h = len(
        [
            d
            for d in decisions
            if datetime.fromisoformat(d["analyzed_at"].replace("Z", "+00:00"))
            > now - timedelta(hours=24)
        ]
    )
    achats_24h = len(
        [
            d
            for d in decisions
            if d["action"] == "ACHETER"
            and datetime.fromisoformat(d["analyzed_at"].replace("Z", "+00:00"))
            > now - timedelta(hours=24)
        ]
    )

    with stat_col1:
        st.metric("Statut Syst√®me", "üü¢ Op√©rationnel")

    with stat_col2:
        st.metric("D√©cisions 24h", decisions_24h)

    with stat_col3:
        st.metric("Signaux ACHAT 24h", achats_24h)

    st.markdown("---")

    # === FLUX PRINCIPAL ===
    if decisions:
        st.markdown("### üìà Flux de D√©cisions avec Suivi de Performance")

        for decision in decisions:
            display_decision_card(decision)
            st.markdown("")  # Espace entre les cartes
    else:
        st.info("üìä Aucune d√©cision √† afficher pour le moment.")
        st.markdown(
            "Lancez le monitoring pour commencer √† g√©n√©rer des d√©cisions : `python start_realtime_monitor.py`"
        )


if __name__ == "__main__":
    main()
</file>

<file path="orchestrator.py">
"""
Orchestrateur Automatis√© BERZERK - Phase 2.3
============================================

Ce module contient le pipeline automatis√© complet utilisant LangGraph pour orchestrer
l'ensemble de la cha√Æne d'analyse financi√®re : de la news brute √† la d√©cision d'investissement.

Architecture : News ‚Üí Analyse Initiale ‚Üí Routage Agents ‚Üí Analyses Sp√©cialis√©es ‚Üí D√©cision Finale

Auteur: BERZERK Team
Phase: 2.3 - Automatisation Compl√®te
"""

import sys
from datetime import datetime
from typing import Any, TypedDict

from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

# LangGraph Imports
from langgraph.graph import END, StateGraph

from agents import (
    AGENT_PROFILES,
    llm,
    route_to_agents,
    run_agent_analysis,
    run_pure_prediction_analysis,  # NOUVEAU : Agent de pr√©diction pure
    run_ticker_hunter,
)

# Imports depuis nos modules existants
from berzerk_lab import analyze_news_with_llm, get_article_text

# --- D√âFINITION DE L'√âTAT DU GRAPHE ---


class GraphState(TypedDict):
    """√âtat qui circule dans le graphe et est mis √† jour √† chaque √©tape."""

    news_link: str
    news_summary: str
    full_article_text: str
    initial_analysis: dict[str, Any]
    actionable_tickers: list[dict[str, str]]  # Nouveau : R√©sultat du Ticker Hunter
    agent_team: list[dict[str, str]]
    agent_debriefing: str
    final_decision: dict[str, Any]
    capital_disponible: float
    execution_log: list[str]
    timestamp: str


# --- MOD√àLE PYDANTIC POUR LA D√âCISION FINALE ---


class InvestmentDecision(BaseModel):
    """Mod√®le pour valider la d√©cision finale d'investissement."""

    decision: str = Field(description="ACHETER, VENDRE, SURVEILLER ou IGNORER")
    ticker: str = Field(description="Ticker de l'action concern√©e ou null")
    confiance: str = Field(description="√âLEV√âE, MOYENNE ou FAIBLE")
    horizon: str = Field(description="Court Terme, Moyen Terme, ou Long Terme")
    justification_synthetique: str = Field(description="Justification en une phrase")
    allocation_capital_pourcentage: float = Field(
        description="Pourcentage du capital √† allouer (0.0 √† 5.0)"
    )
    points_cles_positifs: list[str] = Field(description="Points positifs cl√©s")
    points_cles_negatifs_risques: list[str] = Field(description="Risques identifi√©s")


# --- FONCTIONS UTILITAIRES ---


def log_step(state: GraphState, message: str) -> None:
    """Ajoute un log √† l'√©tat avec timestamp."""
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_message = f"[{timestamp}] {message}"
    state["execution_log"].append(log_message)
    print(f"üîÑ {log_message}")


def format_debriefing(agent_analyses: list[dict[str, str]]) -> str:
    """Formate les analyses des agents pour le superviseur."""
    debriefing_parts = []
    for i, analysis in enumerate(agent_analyses, 1):
        debriefing_parts.append(
            f"\n--- ANALYSE {i} : {analysis['agent_type'].upper().replace('_', ' ')} ---\n"
            f"Focus : {analysis['focus']}\n\n"
            f"{analysis['analysis']}\n"
            f"{'='*80}"
        )
    return "\n".join(debriefing_parts)


# --- N≈íUDS DU GRAPHE (chaque n≈ìud est une fonction) ---


def node_initial_analysis(state: GraphState) -> GraphState:
    """N≈ìud 1 : R√©cup√®re le texte de l'article et fait l'analyse initiale."""
    log_step(state, "D√âMARRAGE - Analyse Initiale")

    try:
        # R√©cup√©ration du texte complet
        full_text = get_article_text(state["news_link"])
        if not full_text:
            raise ValueError("Impossible de r√©cup√©rer le texte de l'article")

        # Analyse initiale avec LLM
        analysis = analyze_news_with_llm(full_text)
        if not analysis:
            raise ValueError("√âchec de l'analyse initiale")

        # Mise √† jour de l'√©tat
        state["full_article_text"] = full_text
        state["initial_analysis"] = analysis
        state["news_summary"] = analysis.get("resume", "")

        log_step(
            state,
            f"‚úÖ Analyse initiale termin√©e - Impact: {analysis.get('impact', 'N/A')}/10",
        )
        log_step(
            state, f"‚úÖ Entit√©s d√©tect√©es: {', '.join(analysis.get('entites', []))}"
        )

    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans l'analyse initiale: {str(e)}")
        state["initial_analysis"] = {"error": str(e)}

    return state


def node_find_actionable_tickers(state: GraphState) -> GraphState:
    """N≈ìud 2 : Chasse aux Tickers - Identifie les tickers actionnables."""
    log_step(state, "TICKER HUNTER - Identification des tickers actionnables")

    try:
        if "error" in state["initial_analysis"]:
            raise ValueError(
                "Analyse initiale √©chou√©e, impossible d'identifier les tickers"
            )

        # Ex√©cution du Ticker Hunter
        ticker_result = run_ticker_hunter(
            news_summary=state["news_summary"],
            full_article_text=state["full_article_text"],
        )

        actionable_tickers = ticker_result.get("tickers_identifies", [])
        state["actionable_tickers"] = actionable_tickers

        if actionable_tickers:
            log_step(
                state,
                f"üéØ {len(actionable_tickers)} ticker(s) actionnable(s) identifi√©(s)",
            )
            for ticker_info in actionable_tickers:
                # Gestion des objets Pydantic ET des dictionnaires
                if hasattr(ticker_info, "ticker"):
                    ticker = ticker_info.ticker
                    company = ticker_info.nom_entreprise
                else:
                    ticker = ticker_info.get("ticker", "N/A")
                    company = ticker_info.get("nom_entreprise", "N/A")
                log_step(state, f"   ‚Üí {ticker} ({company})")
        else:
            log_step(
                state, "‚ö†Ô∏è  Aucun ticker actionnable identifi√© - Pipeline orient√© macro"
            )

    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans le Ticker Hunter: {str(e)}")
        state["actionable_tickers"] = []

    return state


def node_route_to_agents(state: GraphState) -> GraphState:
    """N≈ìud 3 : Recrute l'√©quipe d'agents bas√©e sur les tickers identifi√©s."""
    log_step(state, "ROUTAGE - Recrutement de l'√©quipe d'agents (bas√© sur tickers)")

    try:
        if "error" in state["initial_analysis"]:
            raise ValueError("Analyse initiale √©chou√©e, impossible de router")

        actionable_tickers = state.get("actionable_tickers", [])

        if actionable_tickers:
            # Mode PR√âCIS : Tickers identifi√©s ‚Üí Agents cibl√©s
            team = []

            # Pour chaque ticker, on cr√©e un analyste d'actions d√©di√©
            for ticker_info in actionable_tickers:
                # Gestion des objets Pydantic ET des dictionnaires
                if hasattr(ticker_info, "ticker"):
                    ticker = ticker_info.ticker
                    company = ticker_info.nom_entreprise
                else:
                    ticker = ticker_info.get("ticker", "")
                    company = ticker_info.get("nom_entreprise", "")

                team.append(
                    {"agent_type": "analyste_actions", "focus": f"{ticker} ({company})"}
                )

            # Ajout d'un analyste sectoriel si multiple tickers
            if len(actionable_tickers) > 1:
                sectors = []
                for ticker_info in actionable_tickers:
                    # Gestion des objets Pydantic ET des dictionnaires
                    if hasattr(ticker_info, "justification_impact"):
                        justification = ticker_info.justification_impact
                    else:
                        justification = ticker_info.get("justification_impact", "")
                    # Extraction de mots-cl√©s sectoriels basiques
                    if any(
                        word in justification.lower()
                        for word in [
                            "tech",
                            "technologie",
                            "intelligence artificielle",
                            "ia",
                        ]
                    ):
                        sectors.append("Technologie")
                    elif any(
                        word in justification.lower()
                        for word in ["auto", "v√©hicule", "transport"]
                    ):
                        sectors.append("Automobile")
                    elif any(
                        word in justification.lower()
                        for word in ["√©nergie", "p√©trole", "gaz"]
                    ):
                        sectors.append("√ânergie")
                    elif any(
                        word in justification.lower()
                        for word in ["finance", "banque", "cr√©dit"]
                    ):
                        sectors.append("Finance")

                if sectors:
                    unique_sectors = list(set(sectors))
                    team.append(
                        {
                            "agent_type": "analyste_sectoriel",
                            "focus": f"Impact sectoriel sur {', '.join(unique_sectors)}",
                        }
                    )

            log_step(
                state,
                f"üéØ Mode PR√âCIS activ√© - {len(actionable_tickers)} ticker(s) cibl√©(s)",
            )

        else:
            # Mode FALLBACK : Analyse macro classique
            entities = state["initial_analysis"].get("entites", [])
            team = route_to_agents(entities, state["news_summary"])
            log_step(state, "‚ö†Ô∏è Mode FALLBACK - Pas de tickers, analyse macro")

        if not team:
            raise ValueError("Aucun agent recrut√© par le routeur")

        state["agent_team"] = team

        log_step(state, f"‚úÖ √âquipe recrut√©e: {len(team)} agent(s)")
        for agent in team:
            log_step(state, f"   - {agent['agent_type']} ‚Üí Focus: {agent['focus']}")

    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans le routage: {str(e)}")
        state["agent_team"] = []

    return state


def node_run_agent_analyses(state: GraphState) -> GraphState:
    """N≈ìud 4 : Ex√©cute les analyses de chaque agent sp√©cialis√© (mode PURE PREDICTION)."""
    log_step(
        state, "EX√âCUTION - Analyses sp√©cialis√©es PURE PREDICTION (mode 'tac au tac')"
    )

    try:
        if not state["agent_team"]:
            raise ValueError("Aucun agent disponible pour l'analyse")

        agent_analyses = []
        actionable_tickers = state.get("actionable_tickers", [])

        for i, agent in enumerate(state["agent_team"], 1):
            log_step(
                state,
                f"Ex√©cution agent {i}/{len(state['agent_team'])}: {agent['agent_type']}",
            )

            # D√©tecter si c'est un agent d'analyse d'actions avec ticker identifi√©
            is_ticker_analysis = (
                agent["agent_type"] == "analyste_actions"
                and actionable_tickers
                and len(actionable_tickers) > 0
            )

            if is_ticker_analysis:
                # Extraire le ticker du focus (format: "AAPL (Apple Inc.)")
                focus_text = agent["focus"]
                ticker = None

                # Chercher le ticker dans les actionable_tickers
                for ticker_info in actionable_tickers:
                    # Gestion des objets Pydantic ET des dictionnaires
                    if hasattr(ticker_info, "ticker"):
                        ticker_value = ticker_info.ticker
                    else:
                        ticker_value = ticker_info.get("ticker", "")

                    if ticker_value in focus_text:
                        ticker = ticker_value
                        break

                if ticker:
                    log_step(
                        state,
                        f"üöÄ Analyse PURE PREDICTION pour {ticker} (mode 'tac au tac')",
                    )

                    # === MODIFICATION CL√â ICI ===
                    # Utiliser l'agent de pure pr√©diction sans donn√©es de prix
                    analysis = run_pure_prediction_analysis(
                        ticker=ticker,
                        news_summary=state["news_summary"],
                        full_article_text=state["full_article_text"],
                    )

                    agent_analyses.append(
                        {
                            "agent_type": agent["agent_type"]
                            + "_pure_prediction",  # Marquer le mode
                            "focus": agent["focus"],
                            "analysis": analysis,
                            "ticker": ticker,
                            "is_augmented": False,  # Il n'est plus "augment√©" avec des donn√©es de prix
                        }
                    )

                    log_step(
                        state, f"‚úÖ Analyse PURE PREDICTION termin√©e pour {ticker}"
                    )
                else:
                    # Fallback vers l'analyse classique
                    log_step(
                        state,
                        f"‚ö†Ô∏è Ticker non trouv√©, analyse classique pour {focus_text}",
                    )
                    analysis = run_agent_analysis(
                        agent_type=agent["agent_type"],
                        focus=agent["focus"],
                        news_summary=state["news_summary"],
                        full_article_text=state["full_article_text"],
                    )

                    agent_analyses.append(
                        {
                            "agent_type": agent["agent_type"],
                            "focus": agent["focus"],
                            "analysis": analysis,
                            "is_augmented": False,
                        }
                    )

                    log_step(
                        state, f"‚úÖ Analyse classique termin√©e: {agent['agent_type']}"
                    )
            else:
                # Agent classique (sectoriel, g√©opolitique, etc.)
                log_step(state, f"üìä Analyse classique pour {agent['agent_type']}")

                analysis = run_agent_analysis(
                    agent_type=agent["agent_type"],
                    focus=agent["focus"],
                    news_summary=state["news_summary"],
                    full_article_text=state["full_article_text"],
                )

                agent_analyses.append(
                    {
                        "agent_type": agent["agent_type"],
                        "focus": agent["focus"],
                        "analysis": analysis,
                        "is_augmented": False,
                    }
                )

                log_step(state, f"‚úÖ Analyse classique termin√©e: {agent['agent_type']}")

        # Formatage du debriefing pour le superviseur
        state["agent_debriefing"] = format_debriefing(agent_analyses)

        # Compter les analyses pure prediction
        pure_prediction_count = sum(
            1 for a in agent_analyses if "pure_prediction" in a.get("agent_type", "")
        )
        log_step(
            state,
            f"‚úÖ Debriefing consolid√© - {len(agent_analyses)} analyses ({pure_prediction_count} pure prediction)",
        )

    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans les analyses d'agents: {str(e)}")
        state["agent_debriefing"] = f"ERREUR: {str(e)}"

    return state


def node_final_investor_decision(state: GraphState) -> GraphState:
    """N≈ìud 5 : Prend la d√©cision finale d'investissement via l'Agent Superviseur."""
    log_step(state, "D√âCISION - Agent Investisseur Final")

    try:
        if not state["agent_debriefing"] or "ERREUR" in state["agent_debriefing"]:
            raise ValueError("Debriefing invalide, impossible de prendre une d√©cision")

        # Configuration du parser JSON
        parser = JsonOutputParser(pydantic_object=InvestmentDecision)

        # R√©cup√©ration du template de l'investisseur final
        investor_prompt = AGENT_PROFILES["investisseur_final"]

        # Formatage des tickers pour l'investisseur final
        actionable_tickers = state.get("actionable_tickers", [])
        tickers_summary = "Aucun ticker sp√©cifique identifi√©"

        if actionable_tickers:
            tickers_list = []
            for ticker_info in actionable_tickers:
                # Gestion des objets Pydantic ET des dictionnaires
                if hasattr(ticker_info, "ticker"):
                    # Objet Pydantic
                    ticker = ticker_info.ticker
                    company = ticker_info.nom_entreprise
                    justification = ticker_info.justification_impact
                else:
                    # Dictionnaire classique (fallback)
                    ticker = ticker_info.get("ticker", "N/A")
                    company = ticker_info.get("nom_entreprise", "N/A")
                    justification = ticker_info.get("justification_impact", "N/A")

                tickers_list.append(f"‚Ä¢ {ticker} ({company}): {justification}")
            tickers_summary = "\n".join(tickers_list)

        # Cr√©ation de la cha√Æne LangChain
        chain = investor_prompt | llm | parser

        # Ex√©cution de la d√©cision
        decision_result = chain.invoke(
            {
                "debriefing_equipe": state["agent_debriefing"],
                "capital_disponible": state["capital_disponible"],
                "actionable_tickers": tickers_summary,
            }
        )

        # --- D√âBUT DE LA CORRECTION ---
        decision_obj = None
        if isinstance(decision_result, list):
            if decision_result:
                # Si le LLM retourne une liste, on prend le premier √©l√©ment
                log_step(
                    state, "‚ö†Ô∏è  Le LLM a retourn√© une liste, prise du premier √©l√©ment."
                )
                decision_obj = decision_result[0]
            else:
                raise ValueError("Le LLM a retourn√© une liste vide.")
        else:
            # Comportement normal (objet Pydantic ou dict)
            decision_obj = decision_result

        # Maintenant, on s'assure que decision_obj est un dictionnaire
        if hasattr(decision_obj, "decision"):
            # C'est un objet Pydantic, convertir en dict
            decision_dict = {
                "decision": decision_obj.decision,
                "ticker": decision_obj.ticker,
                "confiance": decision_obj.confiance,
                "justification_synthetique": decision_obj.justification_synthetique,
                "allocation_capital_pourcentage": decision_obj.allocation_capital_pourcentage,
                "points_cles_positifs": decision_obj.points_cles_positifs,
                "points_cles_negatifs_risques": decision_obj.points_cles_negatifs_risques,
            }
        else:
            # C'est d√©j√† un dictionnaire
            decision_dict = decision_obj
        # --- FIN DE LA CORRECTION ---

        # --- D√âBUT DE LA CORRECTION LOGIQUE ---
        # Si la d√©cision est d'acheter mais que l'allocation est nulle,
        # la confiance est insuffisante. On ram√®ne la d√©cision √† SURVEILLER.
        if (
            decision_dict.get("decision") == "ACHETER"
            and decision_dict.get("allocation_capital_pourcentage", 0.0) == 0.0
        ):

            log_step(
                state,
                "‚ö†Ô∏è  INCOH√âRENCE D√âTECT√âE: ACHAT avec 0% d'allocation. D√©cision r√©trograd√©e √† SURVEILLER.",
            )

            # R√©trograder la d√©cision
            decision_dict["decision"] = "SURVEILLER"
            decision_dict["confiance"] = "FAIBLE"  # Forcer la confiance √† FAIBLE
            decision_dict["justification_synthetique"] = (
                f"[R√©trograd√©] Signal d'achat d√©tect√© mais confiance insuffisante pour une allocation de capital. {decision_dict.get('justification_synthetique', '')}"
            )
        # --- FIN DE LA CORRECTION LOGIQUE ---

        state["final_decision"] = decision_dict

        # Logs d√©taill√©s de la d√©cision
        log_step(state, f"‚úÖ D√âCISION PRISE: {decision_dict.get('decision', 'N/A')}")
        log_step(state, f"   üéØ Ticker: {decision_dict.get('ticker', 'N/A')}")
        log_step(state, f"   üìä Confiance: {decision_dict.get('confiance', 'N/A')}")
        log_step(
            state,
            f"   üí∞ Allocation: {decision_dict.get('allocation_capital_pourcentage', 0)}%",
        )
        log_step(
            state,
            f"   üìù Justification: {decision_dict.get('justification_synthetique', 'N/A')}",
        )

    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans la d√©cision finale: {str(e)}")
        state["final_decision"] = {
            "decision": "ERREUR",
            "ticker": None,
            "confiance": "AUCUNE",
            "justification_synthetique": f"Erreur syst√®me: {str(e)}",
            "allocation_capital_pourcentage": 0.0,
            "points_cles_positifs": [],
            "points_cles_negatifs_risques": ["Erreur syst√®me"],
        }

    return state


# --- CONSTRUCTION DU GRAPHE LANGGRAPH ---


def create_workflow() -> StateGraph:
    """Cr√©e et configure le graphe d'orchestration avec le nouveau Ticker Hunter."""

    workflow = StateGraph(GraphState)

    # Ajout des n≈ìuds (dans l'ordre d'ex√©cution)
    workflow.add_node("initial_analysis", node_initial_analysis)
    workflow.add_node(
        "find_actionable_tickers", node_find_actionable_tickers
    )  # NOUVEAU
    workflow.add_node("route_to_agents", node_route_to_agents)
    workflow.add_node("run_agent_analyses", node_run_agent_analyses)
    workflow.add_node("final_investor_decision", node_final_investor_decision)

    # D√©finition des transitions (nouveau flux avec Ticker Hunter)
    workflow.set_entry_point("initial_analysis")
    workflow.add_edge("initial_analysis", "find_actionable_tickers")  # 1 ‚Üí 2
    workflow.add_edge("find_actionable_tickers", "route_to_agents")  # 2 ‚Üí 3
    workflow.add_edge("route_to_agents", "run_agent_analyses")  # 3 ‚Üí 4
    workflow.add_edge("run_agent_analyses", "final_investor_decision")  # 4 ‚Üí 5
    workflow.add_edge("final_investor_decision", END)  # 5 ‚Üí FIN

    return workflow


# --- FONCTION PRINCIPALE D'ORCHESTRATION ---


def run_berzerk_pipeline(
    news_link: str, capital_disponible: float = 30000.0
) -> dict[str, Any]:
    """
    Ex√©cute le pipeline complet d'analyse BERZERK.

    Args:
        news_link: URL de l'article √† analyser
        capital_disponible: Capital disponible pour l'investissement

    Returns:
        √âtat final avec la d√©cision d'investissement
    """

    print("\n" + "=" * 80)
    print("üöÄ D√âMARRAGE DU PIPELINE AUTOMATIS√â BERZERK")
    print("=" * 80)

    # √âtat initial
    initial_state = GraphState(
        news_link=news_link,
        news_summary="",
        full_article_text="",
        initial_analysis={},
        actionable_tickers=[],  # NOUVEAU : Pour stocker les tickers identifi√©s
        agent_team=[],
        agent_debriefing="",
        final_decision={},
        capital_disponible=capital_disponible,
        execution_log=[],
        timestamp=datetime.now().isoformat(),
    )

    # Cr√©ation et compilation du graphe
    workflow = create_workflow()
    app = workflow.compile()

    # Ex√©cution du pipeline
    try:
        final_state = app.invoke(initial_state)

        print("\n" + "=" * 80)
        print("üéØ PIPELINE TERMIN√â - R√âSULTATS FINAUX")
        print("=" * 80)

        return final_state

    except Exception as e:
        print(f"\n‚ùå ERREUR CRITIQUE DANS LE PIPELINE: {str(e)}")
        return {
            "error": str(e),
            "execution_log": initial_state.get("execution_log", []),
            "final_decision": {
                "decision": "ERREUR_CRITIQUE",
                "justification_synthetique": f"Pipeline interrompu: {str(e)}",
            },
        }


# --- FONCTION D'AFFICHAGE DES R√âSULTATS ---


def display_final_results(final_state: dict[str, Any]) -> None:
    """Affiche les r√©sultats finaux de mani√®re format√©e."""

    # Affichage des tickers identifi√©s
    actionable_tickers = final_state.get("actionable_tickers", [])
    if actionable_tickers:
        print("\nüéØ TICKERS IDENTIFI√âS PAR LE TICKER HUNTER:")
        for ticker_info in actionable_tickers:
            # Gestion des objets Pydantic ET des dictionnaires
            if hasattr(ticker_info, "ticker"):
                ticker = ticker_info.ticker
                company = ticker_info.nom_entreprise
                justification = ticker_info.justification_impact
            else:
                ticker = ticker_info.get("ticker", "N/A")
                company = ticker_info.get("nom_entreprise", "N/A")
                justification = ticker_info.get("justification_impact", "N/A")
            print(f"   üè¢ {ticker} ({company})")
            print(f"      üìù {justification}")
    else:
        print("\n‚ö†Ô∏è AUCUN TICKER ACTIONNABLE IDENTIFI√â")

    decision = final_state.get("final_decision", {})

    print("\nüìä D√âCISION FINALE BERZERK:")
    print(f"   üéØ Action: {decision.get('decision', 'N/A')}")
    print(f"   üìà Ticker: {decision.get('ticker', 'N/A')}")
    print(f"   üîí Confiance: {decision.get('confiance', 'N/A')}")
    print(f"   üí∞ Allocation: {decision.get('allocation_capital_pourcentage', 0)}%")
    print(f"   üìù Justification: {decision.get('justification_synthetique', 'N/A')}")

    positifs = decision.get("points_cles_positifs", [])
    if positifs:
        print("\n‚úÖ Points Positifs:")
        for point in positifs:
            print(f"   ‚Ä¢ {point}")

    risques = decision.get("points_cles_negatifs_risques", [])
    if risques:
        print("\n‚ö†Ô∏è Risques Identifi√©s:")
        for risque in risques:
            print(f"   ‚Ä¢ {risque}")

    print("\nüìã Logs d'ex√©cution:")
    for log in final_state.get("execution_log", []):
        print(f"   {log}")


# --- TESTS ET EX√âCUTION PRINCIPALE ---


def test_pipeline():
    """Fonction de test avec des exemples d'articles."""


    print("üß™ MODE TEST - S√©lection automatique d'un article r√©cent")

    # Pour le test, on peut utiliser un URL simple ou une simulation
    test_url = "https://finance.yahoo.com/news/"  # URL g√©n√©rique pour test

    return run_berzerk_pipeline(news_link=test_url, capital_disponible=25000.0)


if __name__ == "__main__":
    """Point d'entr√©e principal."""

    # V√©rification des arguments de ligne de commande
    if len(sys.argv) > 1:
        news_url = sys.argv[1]
        capital = float(sys.argv[2]) if len(sys.argv) > 2 else 30000.0

        print(f"üì∞ Analyse de: {news_url}")
        print(f"üí∞ Capital disponible: {capital}‚Ç¨")

        final_state = run_berzerk_pipeline(news_url, capital)
        display_final_results(final_state)

    else:
        print("üß™ MODE DEMO - Ex√©cution du pipeline de test")
        final_state = test_pipeline()
        display_final_results(final_state)

        print("\nüí° Usage: python orchestrator.py <URL_NEWS> [CAPITAL]")
        print(
            "   Exemple: python orchestrator.py 'https://finance.yahoo.com/news/apple-ai-news' 25000"
        )
</file>

</files>
