This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.gitignore
agents.py
backtester.py
berzerk_dashboard.py
berzerk_lab.py
diagnostic_db.py
env.example
orchestrator.py
real_time_rss_monitor.py
requirements.txt
reset_and_analyze.py
start_realtime_monitor.py
suivi_projet.md
test_feeds.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="agents.py">
"""
Module d'Agents IA Sp√©cialis√©s pour le Projet BERZERK
====================================================

Ce module contient une √©quipe d'agents IA sp√©cialis√©s pour analyser les news financi√®res
sous diff√©rents angles. Chaque agent a une expertise unique et apporte sa perspective
√† l'analyse globale.

Auteur: BERZERK Team
Phase: 2 - Agents IA Sp√©cialis√©s
"""

import os
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

# LangChain Imports
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.tools import tool
from pydantic import BaseModel, Field

# Imports pour les outils
from langchain_community.tools.tavily_search import TavilySearchResults
import yfinance as yf

# --- CONFIGURATION & SETUP ---
load_dotenv()

# Initialisation du LLM avec temp√©rature plus √©lev√©e pour la personnalit√© des agents
try:
    llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash-lite-preview-06-17", 
    temperature=0.3
    # Le param√®tre convert_system_message_to_human est maintenant g√©r√© automatiquement
)
    print("‚úÖ LLM initialis√© avec succ√®s pour les agents IA")
except Exception as e:
    print(f"‚ùå Erreur d'initialisation du LLM pour les agents: {e}")
    llm = None

# --- OUTILS POUR AGENTS AUGMENT√âS ---

# 1. Outil de recherche web avec Tavily
try:
    web_search_tool = TavilySearchResults(
        max_results=3,  # Limiter pour √©viter la surcharge d'informations
        search_depth="basic"  # Recherche basique pour √™tre plus rapide
    )
    print("‚úÖ Outil de recherche web (Tavily) initialis√©")
except Exception as e:
    print(f"‚ùå Erreur d'initialisation de Tavily: {e}")
    web_search_tool = None

# 2. Outil de donn√©es financi√®res avec yfinance
@tool
def get_stock_price(ticker: str) -> str:
    """R√©cup√®re le prix actuel et la variation journali√®re pour un ticker donn√©."""
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="2d")  # 2 jours pour calculer la variation
        if hist.empty:
            return f"‚ùå Donn√©es non trouv√©es pour {ticker}"
        
        # Prix actuel (derni√®re cl√¥ture)
        current_price = hist['Close'].iloc[-1]
        
        # Variation par rapport √† la veille
        if len(hist) >= 2:
            previous_price = hist['Close'].iloc[-2]
            change_percent = ((current_price - previous_price) / previous_price) * 100
            change_symbol = "üìà" if change_percent > 0 else "üìâ" if change_percent < 0 else "‚û°Ô∏è"
            
            return f"üí∞ {ticker}: {current_price:.2f} USD {change_symbol} {change_percent:+.2f}% vs hier"
        else:
            return f"üí∞ {ticker}: {current_price:.2f} USD (variation non disponible)"
            
    except Exception as e:
        return f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es pour {ticker}: {str(e)}"

@tool
def get_market_sentiment(ticker: str) -> str:
    """R√©cup√®re des informations sur le sentiment du march√© pour un ticker."""
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        
        # Informations cl√©s
        market_cap = info.get('marketCap', 'N/A')
        pe_ratio = info.get('trailingPE', 'N/A')
        volume = info.get('averageVolume', 'N/A')
        
        # Formatage des grandes valeurs
        if isinstance(market_cap, (int, float)):
            if market_cap > 1e12:
                market_cap_str = f"{market_cap/1e12:.1f}T USD"
            elif market_cap > 1e9:
                market_cap_str = f"{market_cap/1e9:.1f}B USD"
            else:
                market_cap_str = f"{market_cap/1e6:.1f}M USD"
        else:
            market_cap_str = "N/A"
            
        return f"üìä {ticker} - Cap: {market_cap_str} | P/E: {pe_ratio} | Volume moy: {volume:,}" if isinstance(volume, int) else f"üìä {ticker} - Cap: {market_cap_str} | P/E: {pe_ratio} | Volume moy: {volume}"
        
    except Exception as e:
        return f"‚ùå Erreur sentiment march√© pour {ticker}: {str(e)}"

print("‚úÖ Outils financiers (yfinance) initialis√©s")

# --- MOD√àLES PYDANTIC POUR LA VALIDATION ---

class AgentSelection(BaseModel):
    """Mod√®le pour la s√©lection d'agents par le routeur."""
    agents: List[Dict[str, str]] = Field(
        description="Liste des agents s√©lectionn√©s avec leur type et focus"
    )

class TickerIdentification(BaseModel):
    """Mod√®le pour la sortie de l'agent Ticker Hunter."""
    ticker: str = Field(description="Symbole boursier de l'entreprise")
    nom_entreprise: str = Field(description="Nom complet de l'entreprise")
    justification_impact: str = Field(description="Justification de l'impact sur cette entreprise")

class TickerHunterResult(BaseModel):
    """Mod√®le pour la sortie compl√®te de l'agent Ticker Hunter."""
    tickers_identifies: List[TickerIdentification] = Field(
        description="Liste des tickers identifi√©s avec leurs justifications"
    )

# --- PROFILS D'AGENTS SP√âCIALIS√âS ---

# Ticker Hunter - Agent sp√©cialis√© dans l'identification de tickers actionnables
ticker_hunter_template = PromptTemplate(
    input_variables=["news_summary", "full_article_text"],
    template="""
Tu es "The Ticker Hunter", un analyste financier redoutable pour le fonds BERZERK. Ta seule et unique mission est d'identifier des opportunit√©s de trading actionnables √† partir d'informations. Tu ignores les concepts vagues et tu te concentres sur les entreprises cot√©es.

Analyse le r√©sum√© et le texte complet de l'article ci-dessous.

**R√©sum√© :**
{news_summary}

**Texte Complet :**
{full_article_text}

---
**TACHE :**
Identifie les 1 √† 5 entreprises cot√©es en bourse (et leurs tickers boursiers) les plus directement et significativement impact√©es par cette news.
Pour chaque entreprise, fournis une justification concise expliquant POURQUOI elle est impact√©e.

R√©ponds IMP√âRATIVEMENT au format JSON suivant, et rien d'autre. Si aucune action n'est clairement identifiable, retourne une liste vide.

{{
    "tickers_identifies": [
        {{
            "ticker": "AAPL",
            "nom_entreprise": "Apple Inc.",
            "justification_impact": "L'article mentionne des probl√®mes dans la cha√Æne d'approvisionnement des iPhones en Chine."
        }},
        {{
            "ticker": "QCOM",
            "nom_entreprise": "Qualcomm",
            "justification_impact": "En tant que fournisseur cl√© d'Apple, Qualcomm serait directement affect√© par un ralentissement de la production."
        }}
    ]
}}

**R√àGLES CRITIQUES :**
- Seules les entreprises publiques avec des tickers boursiers r√©els (NYSE, NASDAQ, etc.)
- Impact direct et mesurable sur le business
- Justification factuelle bas√©e sur le contenu de l'article
- Maximum 5 tickers pour rester focus
- Si aucun ticker n'est clairement identifiable, retourne une liste vide
"""
)

# Analyste Actions - Sp√©cialis√© dans l'analyse d'actions individuelles
analyste_actions_template = PromptTemplate(
    input_variables=["focus", "news_summary", "full_article_text"],
    template="""
Tu es un Analyste Financier Senior sp√©cialis√© en actions pour le fonds d'investissement BERZERK.

**Ton Focus Exclusif : L'action {focus}.**

Ta mission est d'√©valuer l'impact d'une nouvelle sur cette action sp√©cifique. Ignore les autres aspects.
Tu dois analyser avec pr√©cision l'impact potentiel sur le cours de l'action, les volumes, et les perspectives.

R√©sum√© de la news :
{news_summary}

Texte complet de l'article :
{full_article_text}

---
Produis une analyse concise au format Markdown avec les sections suivantes :

### üéØ √âvaluation sur {focus}
- **Sentiment :** (Positif, N√©gatif, Neutre)
- **Impact (1-10) :** (Note l'impact potentiel sur le cours de l'action)
- **Justification :** (Explique ton raisonnement en 2-3 phrases claires, en te basant sur des faits de l'article.)

### üìä Analyse Technique
- **Catalyseurs identifi√©s :** (√âl√©ments qui pourraient faire bouger le cours)
- **Risques potentiels :** (√âl√©ments n√©gatifs √† surveiller)

### üéØ Recommandation d'Action
- **Horizon :** (Court Terme, Moyen Terme, Long Terme)
- **Action :** (Surveiller, Renforcer la position, All√©ger la position, Ne rien faire)
- **Niveau de confiance :** (Faible, Moyen, √âlev√©)
"""
)

# Analyste Sectoriel - Sp√©cialis√© dans l'analyse de secteurs d'activit√©
analyste_sectoriel_template = PromptTemplate(
    input_variables=["focus", "news_summary", "full_article_text"],
    template="""
Tu es un Analyste Sectoriel Expert pour le fonds d'investissement BERZERK.

**Ton Focus Exclusif : Le secteur {focus}.**

Ta mission est d'analyser l'impact d'une nouvelle sur l'ensemble du secteur. Tu dois identifier les tendances,
les dynamiques concurrentielles et les implications pour toutes les entreprises du secteur.

R√©sum√© de la news :
{news_summary}

Texte complet de l'article :
{full_article_text}

---
Produis une analyse sectorielle au format Markdown avec les sections suivantes :

### üè≠ Impact Sectoriel sur {focus}
- **Sentiment Global :** (Positif, N√©gatif, Neutre)
- **Ampleur d'Impact (1-10) :** (Note l'impact sur l'ensemble du secteur)
- **Justification :** (Explique les m√©canismes d'impact sur le secteur)

### üîÑ Dynamiques Concurrentielles
- **Gagnants potentiels :** (Quelles entreprises/sous-secteurs pourraient b√©n√©ficier)
- **Perdants potentiels :** (Quelles entreprises/sous-secteurs pourraient souffrir)
- **Changements structurels :** (√âvolutions durables attendues)

### üéØ Implications Strat√©giques
- **Opportunit√©s d'investissement :** (Nouvelles opportunit√©s cr√©√©es)
- **Risques sectoriels :** (Nouveaux risques √† surveiller)
- **Horizon temporel :** (Court/Moyen/Long terme pour les impacts)
"""
)

# Strat√©giste G√©opolitique - Sp√©cialis√© dans l'analyse g√©opolitique et macro√©conomique
strategiste_geopolitique_template = PromptTemplate(
    input_variables=["focus", "news_summary", "full_article_text"],
    template="""
Tu es un Strat√©giste G√©opolitique Senior pour le fonds d'investissement BERZERK.

**Ton Focus Exclusif : {focus}.**

Ta mission est d'analyser les implications g√©opolitiques et macro√©conomiques d'une nouvelle.
Tu dois identifier les ramifications sur les relations internationales, les politiques √©conomiques,
et les flux de capitaux mondiaux.

R√©sum√© de la news :
{news_summary}

Texte complet de l'article :
{full_article_text}

---
Produis une analyse g√©opolitique au format Markdown avec les sections suivantes :

### üåç Analyse G√©opolitique : {focus}
- **Sentiment G√©opolitique :** (Stabilisant, D√©stabilisant, Neutre)
- **Niveau de Risque (1-10) :** (Impact sur la stabilit√© g√©opolitique)
- **Justification :** (Explique les m√©canismes g√©opolitiques en jeu)

### üó∫Ô∏è Implications R√©gionales
- **R√©gions affect√©es :** (Zones g√©ographiques principales concern√©es)
- **Acteurs cl√©s :** (Pays, institutions, alliances impliqu√©s)
- **Tensions potentielles :** (Nouveaux conflits ou r√©solutions possibles)

### üí∞ Impact sur les March√©s
- **Devises affect√©es :** (Monnaies qui pourraient √™tre impact√©es)
- **Secteurs sensibles :** (Industries particuli√®rement expos√©es)
- **Flux de capitaux :** (R√©allocations d'investissement attendues)

### üéØ Recommandations Strat√©giques
- **Positionnement recommand√© :** (D√©fensif, Offensif, Neutre)
- **Horizon d'impact :** (Court/Moyen/Long terme)
- **Indicateurs √† surveiller :** (Signaux d'alerte ou d'opportunit√©)
"""
)

# Agent Investisseur Final - Le superviseur qui prend la d√©cision finale
investisseur_final_template = PromptTemplate(
    input_variables=["debriefing_equipe", "capital_disponible", "actionable_tickers"],
    template="""
Tu es l'Agent Investisseur en chef du fonds BERZERK. Tu es froid, logique, et uniquement guid√© par la performance et la gestion du risque.

Ta mission est de prendre la d√©cision finale d'investissement bas√©e sur le rapport consolid√© de ton √©quipe d'analystes sp√©cialis√©s.

**Tickers Identifi√©s par le Ticker Hunter :**
{actionable_tickers}

**Rapport de l'√âquipe d'Analystes :**
---
{debriefing_equipe}
---

**Contexte Financier Actuel :**
- Capital total disponible pour de nouveaux trades : {capital_disponible} ‚Ç¨

**TACHE FINALE :**
Sur la base EXCLUSIVE des informations ci-dessus, produis une d√©cision d'investissement structur√©e au format JSON. Ne rien ajouter d'autre.

**PRIORIT√â :** Concentre-toi sur les tickers sp√©cifiques identifi√©s par le Ticker Hunter. Ignore les analyses macro g√©n√©rales.

Le format JSON doit contenir les cl√©s suivantes :
- "decision": "ACHETER", "VENDRE", "SURVEILLER" ou "IGNORER".
- "ticker": Le ticker de l'action concern√©e (string, ou null si IGNORER).
- "confiance": "√âLEV√âE", "MOYENNE", "FAIBLE" (string).
- "justification_synthetique": Une phrase unique et directe expliquant la d√©cision.
- "allocation_capital_pourcentage": Le pourcentage du capital disponible √† allouer √† ce trade (nombre flottant, de 0.0 √† 5.0). Allouer 0 si la d√©cision n'est pas "ACHETER". Une allocation typique pour une confiance MOYENNE est 1%, √âLEV√âE est 2-3%.
- "points_cles_positifs": Une liste de 2-3 points cl√©s positifs tir√©s du rapport.
- "points_cles_negatifs_risques": Une liste de 2-3 risques ou points n√©gatifs tir√©s du rapport.
"""
)

# Dictionnaire des profils d'agents
AGENT_PROFILES = {
    "ticker_hunter": ticker_hunter_template,
    "analyste_actions": analyste_actions_template,
    "analyste_sectoriel": analyste_sectoriel_template,
    "strategiste_geopolitique": strategiste_geopolitique_template,
    "investisseur_final": investisseur_final_template,
}

# --- FONCTIONS PRINCIPALES ---

def route_to_agents(entities: List[str], news_summary: str) -> List[Dict[str, str]]:
    """
    Routeur intelligent qui s√©lectionne les agents appropri√©s selon les entit√©s d√©tect√©es.
    
    Args:
        entities: Liste des entit√©s d√©tect√©es (tickers, secteurs, concepts)
        news_summary: R√©sum√© de la news
    
    Returns:
        Liste de dictionnaires avec agent_type et focus pour chaque agent s√©lectionn√©
    """
    if not llm:
        print("‚ùå LLM non disponible pour le routage")
        return []
    
    # Prompt pour le routeur intelligent
    router_template = PromptTemplate(
        input_variables=["entities", "news_summary", "available_agents"],
        template="""
Tu es le Chef d'Orchestre du syst√®me d'analyse BERZERK. Ta mission est de s√©lectionner
la meilleure √©quipe d'agents IA pour analyser une news financi√®re.

**Agents disponibles :**
{available_agents}

**Entit√©s d√©tect√©es dans la news :**
{entities}

**R√©sum√© de la news :**
{news_summary}

**Instructions :**
1. Analyse les entit√©s et le contenu de la news
2. S√©lectionne 1 √† 3 agents maximum (√©vite la redondance)
3. Pour chaque agent, d√©finis un focus pr√©cis bas√© sur les entit√©s

**Crit√®res de s√©lection :**
- **analyste_actions** : Si des tickers d'actions sp√©cifiques sont mentionn√©s (ex: AAPL, TSLA)
- **analyste_sectoriel** : Si des secteurs d'activit√© sont concern√©s (ex: Tech, Pharma, √ânergie)
- **strategiste_geopolitique** : Si des aspects g√©opolitiques, mon√©taires ou macro√©conomiques sont pr√©sents

**Format de r√©ponse attendu (JSON strict) :**
{{
    "agents": [
        {{"agent_type": "analyste_actions", "focus": "AAPL"}},
        {{"agent_type": "analyste_sectoriel", "focus": "Technologie"}},
        {{"agent_type": "strategiste_geopolitique", "focus": "Relations commerciales USA-Chine"}}
    ]
}}

Assure-toi que chaque focus soit sp√©cifique et pertinent pour l'agent s√©lectionn√©.
"""
    )
    
    try:
        # Pr√©paration des donn√©es
        available_agents = """
- analyste_actions : Analyse d'actions individuelles et de tickers sp√©cifiques
- analyste_sectoriel : Analyse de secteurs d'activit√© et industries
- strategiste_geopolitique : Analyse g√©opolitique et macro√©conomique
"""
        
        # Configuration du parser JSON
        parser = JsonOutputParser(pydantic_object=AgentSelection)
        
        # Cr√©ation de la cha√Æne LangChain
        chain = router_template | llm | parser
        
        # Ex√©cution du routage
        result = chain.invoke({
            "entities": ", ".join(entities),
            "news_summary": news_summary,
            "available_agents": available_agents
        })
        
        selected_agents = result.get("agents", [])
        print(f"‚úÖ Routeur : {len(selected_agents)} agent(s) s√©lectionn√©(s)")
        
        return selected_agents
        
    except Exception as e:
        print(f"‚ùå Erreur dans le routage des agents: {e}")
        # Fallback : s√©lection basique bas√©e sur les entit√©s
        fallback_agents = []
        
        # Recherche de tickers (g√©n√©ralement en majuscules, 2-5 caract√®res)
        tickers = [entity for entity in entities if entity.isupper() and 2 <= len(entity) <= 5]
        if tickers:
            fallback_agents.append({"agent_type": "analyste_actions", "focus": tickers[0]})
        
        # Recherche de secteurs (mots-cl√©s courants)
        secteurs = ["tech", "technologie", "√©nergie", "finance", "sant√©", "pharma", "automobile"]
        for entity in entities:
            if any(secteur in entity.lower() for secteur in secteurs):
                fallback_agents.append({"agent_type": "analyste_sectoriel", "focus": entity})
                break
        
        return fallback_agents

def run_agent_analysis(
    agent_type: str, 
    focus: str, 
    news_summary: str, 
    full_article_text: str
) -> str:
    """
    Ex√©cute l'analyse d'un agent sp√©cifique.
    
    Args:
        agent_type: Type d'agent (cl√© du dictionnaire AGENT_PROFILES)
        focus: Focus sp√©cifique pour l'analyse
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article
    
    Returns:
        Analyse format√©e en Markdown ou message d'erreur
    """
    if not llm:
        return "‚ùå **Erreur :** LLM non disponible pour l'analyse"
    
    if agent_type not in AGENT_PROFILES:
        return f"‚ùå **Erreur :** Agent '{agent_type}' non reconnu"
    
    try:
        # R√©cup√©ration du template de l'agent
        agent_prompt = AGENT_PROFILES[agent_type]
        
        # Cr√©ation de la cha√Æne LangChain
        chain = agent_prompt | llm
        
        # Ex√©cution de l'analyse
        analysis_result = chain.invoke({
            "focus": focus,
            "news_summary": news_summary,
            "full_article_text": full_article_text
        })
        
        print(f"‚úÖ Analyse termin√©e - Agent: {agent_type}, Focus: {focus}")
        return analysis_result.content if hasattr(analysis_result, 'content') else str(analysis_result)
        
    except Exception as e:
        error_msg = f"‚ùå **Erreur lors de l'analyse** - Agent: {agent_type}, Focus: {focus}\n**D√©tail:** {str(e)}"
        print(error_msg)
        return error_msg

def run_ticker_hunter(news_summary: str, full_article_text: str) -> Dict[str, List[Dict]]:
    """
    Ex√©cute l'agent Ticker Hunter pour identifier les tickers actionnables.
    
    Args:
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article
    
    Returns:
        Dictionnaire avec la liste des tickers identifi√©s
    """
    if not llm:
        print("‚ùå LLM non disponible pour le Ticker Hunter")
        return {"tickers_identifies": []}
    
    try:
        # Configuration du parser JSON avec validation Pydantic
        parser = JsonOutputParser(pydantic_object=TickerHunterResult)
        
        # R√©cup√©ration du template du Ticker Hunter
        ticker_hunter_prompt = AGENT_PROFILES["ticker_hunter"]
        
        # Cr√©ation de la cha√Æne LangChain
        chain = ticker_hunter_prompt | llm | parser
        
        # Ex√©cution de l'analyse
        result = chain.invoke({
            "news_summary": news_summary,
            "full_article_text": full_article_text
        })
        
        tickers_found = result.get("tickers_identifies", [])
        print(f"‚úÖ Ticker Hunter : {len(tickers_found)} ticker(s) identifi√©(s)")
        
        if tickers_found:
            for ticker_info in tickers_found:
                # Gestion des objets Pydantic ET des dictionnaires
                if hasattr(ticker_info, 'ticker'):
                    ticker = ticker_info.ticker
                    company = ticker_info.nom_entreprise
                else:
                    ticker = ticker_info.get('ticker', 'N/A')
                    company = ticker_info.get('nom_entreprise', 'N/A')
                print(f"   üéØ {ticker} - {company}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå Erreur dans le Ticker Hunter: {e}")
        return {"tickers_identifies": []}

# --- AGENTS AUGMENT√âS (AVEC OUTILS) ---

def create_augmented_analyst(focus_ticker: str = None) -> AgentExecutor:
    """
    Cr√©e un agent analyste augment√© avec acc√®s √† des outils web et financiers.
    
    Args:
        focus_ticker: Ticker √† analyser en priorit√© (optionnel)
    
    Returns:
        AgentExecutor configur√© avec les outils
    """
    if not llm:
        raise ValueError("LLM non disponible pour cr√©er l'agent augment√©")
    
    # D√©finition des outils disponibles
    tools = []
    
    # Ajout des outils disponibles
    if web_search_tool:
        tools.append(web_search_tool)
    
    tools.extend([get_stock_price, get_market_sentiment])
    
    # Prompt syst√®me pour l'agent augment√©
    focus_instruction = f" Tu te concentres principalement sur {focus_ticker}." if focus_ticker else ""
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", f"""Tu es un analyste financier expert du fonds BERZERK avec acc√®s √† des outils temps r√©el.{focus_instruction}

**Tes outils disponibles :**
- web_search_tool : Recherche d'informations compl√©mentaires sur le web
- get_stock_price : Prix actuel et variation des actions
- get_market_sentiment : Informations sur capitalisation, P/E, volume

**Ton processus d'analyse :**
1. Analyse d'abord la news fournie
2. Utilise tes outils pour v√©rifier le contexte actuel du march√©
3. Recherche des informations compl√©mentaires si n√©cessaire
4. Produis une analyse compl√®te et nuanc√©e

**R√®gles importantes :**
- Utilise tes outils de mani√®re strat√©gique (pas syst√©matiquement)
- Mentionne si le march√© a d√©j√† r√©agi √† la news
- Contextualise tes recommandations avec les donn√©es temps r√©el
- Sois pr√©cis et actionnable dans tes conclusions"""),
        
        ("user", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ])
    
    # Cr√©ation de l'agent
    agent = create_tool_calling_agent(llm, tools, prompt)
    
    # Cr√©ation de l'ex√©cuteur
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,  # Pour voir le processus de r√©flexion
        max_iterations=5,  # Limiter les it√©rations pour √©viter les boucles
        early_stopping_method="generate"  # Arr√™t anticip√© si n√©cessaire
    )
    
    return agent_executor

def run_augmented_analysis(ticker: str, news_summary: str, full_article_text: str) -> str:
    """
    Ex√©cute une analyse augment√©e avec acc√®s aux outils externes.
    
    Args:
        ticker: Ticker √† analyser
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article
    
    Returns:
        Analyse compl√®te avec donn√©es temps r√©el
    """
    try:
        # Cr√©ation de l'agent augment√© pour ce ticker
        agent_executor = create_augmented_analyst(focus_ticker=ticker)
        
        # Pr√©paration de la requ√™te
        query = f"""
        Analyse l'impact de cette news sur l'action {ticker}.
        
        **R√©sum√© de la news :**
        {news_summary}
        
        **Texte complet :**
        {full_article_text[:2000]}...  # Limitation pour √©viter les tokens excessifs
        
        **Ta mission :**
        1. V√©rifie le prix actuel et la variation de {ticker}
        2. Recherche des informations compl√©mentaires si n√©cessaire
        3. √âvalue si le march√© a d√©j√† int√©gr√© cette news
        4. Produis une recommandation d'investissement pr√©cise
        
        Utilise tes outils pour avoir une vision compl√®te du contexte actuel !
        """
        
        # Ex√©cution de l'analyse
        result = agent_executor.invoke({"input": query})
        
        return result.get("output", "Erreur dans l'analyse augment√©e")
        
    except Exception as e:
        return f"‚ùå **Erreur dans l'analyse augment√©e :** {str(e)}"

# --- FONCTIONS UTILITAIRES ---

def get_available_agents() -> List[str]:
    """Retourne la liste des agents disponibles."""
    return list(AGENT_PROFILES.keys())

def get_agent_description(agent_type: str) -> str:
    """Retourne une description d'un agent sp√©cifique."""
    descriptions = {
        "analyste_actions": "Sp√©cialis√© dans l'analyse d'actions individuelles et de tickers sp√©cifiques",
        "analyste_sectoriel": "Expert en analyse de secteurs d'activit√© et dynamiques industrielles",
        "strategiste_geopolitique": "Sp√©cialis√© dans l'analyse g√©opolitique et macro√©conomique"
    }
    return descriptions.get(agent_type, "Agent non reconnu")

# --- FONCTION DE TEST ---

def test_agents_module():
    """Fonction de test pour v√©rifier le bon fonctionnement du module."""
    print("üß™ Test du module agents.py")
    print("-" * 50)
    
    # Test 1: V√©rification des profils
    print(f"‚úÖ {len(AGENT_PROFILES)} profils d'agents charg√©s")
    for agent_type in AGENT_PROFILES.keys():
        print(f"   - {agent_type}: {get_agent_description(agent_type)}")
    
    # Test 2: Test du routeur
    test_entities = ["AAPL", "TSLA", "Technologie", "Intelligence Artificielle"]
    test_summary = "Apple et Tesla annoncent un partenariat dans l'IA automobile"
    
    print(f"\nüîÄ Test du routeur avec entit√©s: {test_entities}")
    selected_agents = route_to_agents(test_entities, test_summary)
    print(f"‚úÖ Agents s√©lectionn√©s: {selected_agents}")
    
    print("\nüéØ Module agents.py pr√™t √† l'emploi !")

if __name__ == "__main__":
    test_agents_module()
</file>

<file path="backtester.py">
#!/usr/bin/env python3
"""
üéØ BERZERK BACKTESTER - Module de Validation de Performance
=====================================================

Ce module analyse les d√©cisions d'ACHAT stock√©es dans la base de donn√©es
et simule leur rentabilit√© pour valider la performance du syst√®me BERZERK.

Strat√©gie de test :
- P√©riode de d√©tention : 7 jours calendaires
- Prix d'achat : Ouverture du jour de bourse suivant la d√©cision
- Prix de vente : Ouverture du jour de bourse apr√®s 7 jours
- M√©triques calcul√©es : ROI, taux de r√©ussite, performance cumul√©e

Auteur : BERZERK System
Date : 2024-01-XX
"""

import sqlite3
import pandas as pd
import yfinance as yf
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import sys

# Configuration
HOLDING_PERIOD_DAYS = 7
DATABASE_PATH = 'berzerk.db'

class BerzerkBacktester:
    """
    Classe principale pour le backtesting des d√©cisions BERZERK
    """
    
    def __init__(self, db_path: str = DATABASE_PATH):
        self.db_path = db_path
        self.results = []
        
    def get_buy_decisions(self) -> List[Dict]:
        """
        R√©cup√®re toutes les d√©cisions d'ACHAT de la base de donn√©es
        """
        print("üîç Recherche des d√©cisions d'ACHAT dans la base de donn√©es...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # R√©cup√©rer tous les articles avec d√©cisions
        cursor.execute('''
            SELECT id, title, link, published_date, decision_json 
            FROM articles 
            WHERE decision_json IS NOT NULL 
            AND status = "analyzed"
            ORDER BY published_date DESC
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        buy_decisions = []
        
        for row in rows:
            article_id, title, link, published_date, decision_json = row
            
            try:
                decision = json.loads(decision_json)
                
                # Nouveau format : chercher dans 'action' 
                action = decision.get('action', '').upper()
                
                # V√©rifier si c'est une d√©cision d'ACHAT
                if action in ['ACHETER', 'ACHAT', 'BUY']:
                    ticker = decision.get('ticker')
                    
                    if ticker:  # Seulement si on a un ticker valide
                        buy_decisions.append({
                            'article_id': article_id,
                            'title': title,
                            'link': link,
                            'ticker': ticker,
                            'decision_date': datetime.fromisoformat(published_date),
                            'action': action,
                            'justification': decision.get('justification', 'Aucune justification'),
                            'allocation': decision.get('allocation_pourcentage', 0.0),
                            'confiance': decision.get('confiance', 'INCONNUE')
                        })
                        print(f"‚úÖ D√©cision d'ACHAT trouv√©e: {ticker} ({title[:30]}...)")
                    else:
                        print(f"‚ö†Ô∏è  D√©cision d'ACHAT sans ticker: {title[:30]}...")
                else:
                    print(f"üìä D√©cision {action}: {title[:30]}...")
                
            except json.JSONDecodeError as e:
                print(f"‚ùå Erreur JSON pour l'article {article_id}: {e}")
            except Exception as e:
                print(f"‚ùå Erreur lors du traitement de l'article {article_id}: {e}")
        
        print(f"\nüìà {len(buy_decisions)} d√©cision(s) d'ACHAT trouv√©e(s)")
        return buy_decisions
    
    def get_next_trading_day(self, date: datetime) -> datetime:
        """
        Trouve le prochain jour de bourse apr√®s une date donn√©e
        
        Args:
            date: Date de d√©part
            
        Returns:
            datetime: Prochain jour de bourse
        """
        # Commencer par le jour suivant
        next_day = date + timedelta(days=1)
        
        # √âviter les weekends (lundi = 0, dimanche = 6)
        while next_day.weekday() >= 5:  # 5 = samedi, 6 = dimanche
            next_day += timedelta(days=1)
            
        return next_day
    
    def simulate_trade(self, trade: Dict) -> Optional[Dict]:
        """
        Simule un trade individuel avec la strat√©gie de d√©tention de 7 jours
        
        Args:
            trade: Dictionnaire contenant les infos du trade
            
        Returns:
            Dict: R√©sultat de la simulation ou None si erreur
        """
        ticker = trade['ticker']
        decision_date = trade['decision_date']
        
        print(f"üìä Simulation du trade {ticker} (d√©cision du {decision_date.strftime('%Y-%m-%d')})")
        
        try:
            # Dates de trading avec ajustement pour les dates tr√®s r√©centes
            buy_date = self.get_next_trading_day(decision_date)
            sell_date = self.get_next_trading_day(buy_date + timedelta(days=HOLDING_PERIOD_DAYS))
            
            # P√©riode de t√©l√©chargement des donn√©es avec marge √©tendue
            start_date = buy_date - timedelta(days=10)  # Plus de marge pour les dates r√©centes
            end_date = datetime.now() + timedelta(days=2)  # Utiliser date actuelle + marge
            
            print(f"   üìÖ P√©riode de donn√©es: {start_date.strftime('%Y-%m-%d')} ‚Üí {end_date.strftime('%Y-%m-%d')}")
            
            # T√©l√©charger les donn√©es historiques
            stock = yf.Ticker(ticker)
            hist = stock.history(start=start_date, end=end_date)
            
            if hist.empty:
                print(f"‚ùå Pas de donn√©es historiques pour {ticker}")
                return None
            
            print(f"   üìä {len(hist)} jours de donn√©es r√©cup√©r√©s")
            
            # Trouver les prix d'achat et de vente
            buy_price = None
            sell_price = None
            actual_buy_date = None
            actual_sell_date = None
            
            # Prix d'achat : premier prix d'ouverture disponible >= buy_date
            for date, row in hist.iterrows():
                if date.date() >= buy_date.date():
                    buy_price = row['Open']
                    actual_buy_date = date
                    print(f"   üí∞ Prix d'achat trouv√©: {buy_price:.2f} USD le {date.strftime('%Y-%m-%d')}")
                    break
            
            # Si pas de prix d'achat exact, prendre le dernier prix disponible
            if buy_price is None:
                if not hist.empty:
                    last_row = hist.iloc[-1]
                    buy_price = last_row['Close']  # Utiliser le prix de cl√¥ture
                    actual_buy_date = hist.index[-1]
                    print(f"   üí∞ Prix d'achat (dernier disponible): {buy_price:.2f} USD le {actual_buy_date.strftime('%Y-%m-%d')}")
                else:
                    print(f"‚ùå Impossible de trouver un prix d'achat pour {ticker}")
                    return None
            
            # Prix de vente : chercher le prix apr√®s la p√©riode de d√©tention
            if datetime.now().date() < sell_date.date():
                # Si la date de vente est dans le futur, utiliser le prix actuel
                try:
                    current_info = stock.info
                    sell_price = current_info.get('regularMarketPrice', buy_price)
                    actual_sell_date = datetime.now()
                    print(f"   üìà Prix de vente (actuel): {sell_price:.2f} USD le {actual_sell_date.strftime('%Y-%m-%d')}")
                except:
                    # Si pas d'info actuelle, utiliser le dernier prix historique
                    sell_price = hist.iloc[-1]['Close']
                    actual_sell_date = hist.index[-1]
                    print(f"   üìà Prix de vente (dernier historique): {sell_price:.2f} USD le {actual_sell_date.strftime('%Y-%m-%d')}")
            else:
                # Prix de vente normal : chercher dans l'historique
                for date, row in hist.iterrows():
                    if date.date() >= sell_date.date():
                        sell_price = row['Open']
                        actual_sell_date = date
                        print(f"   üìà Prix de vente trouv√©: {sell_price:.2f} USD le {date.strftime('%Y-%m-%d')}")
                        break
                
                # Si pas trouv√©, utiliser le dernier prix disponible
                if sell_price is None:
                    sell_price = hist.iloc[-1]['Close']
                    actual_sell_date = hist.index[-1]
                    print(f"   üìà Prix de vente (dernier disponible): {sell_price:.2f} USD le {actual_sell_date.strftime('%Y-%m-%d')}")
            
            if buy_price is None or sell_price is None:
                print(f"‚ùå Impossible de trouver les prix pour {ticker}")
                return None
            
            # Calculer la performance
            roi_percent = ((sell_price - buy_price) / buy_price) * 100
            
            result = {
                'ticker': ticker,
                'title': trade['title'][:50] + "..." if len(trade['title']) > 50 else trade['title'],
                'decision_date': decision_date,
                'buy_date': actual_buy_date,
                'sell_date': actual_sell_date,
                'buy_price': round(buy_price, 2),
                'sell_price': round(sell_price, 2),
                'roi_percent': round(roi_percent, 2),
                'allocation': trade['allocation'],
                'is_profitable': roi_percent > 0,
                'is_partial_simulation': datetime.now().date() < sell_date.date()  # Indicateur si simulation partielle
            }
            
            status = "‚úÖ PROFIT" if roi_percent > 0 else "‚ùå PERTE"
            partial_note = " (‚ö†Ô∏è Simulation partielle)" if result['is_partial_simulation'] else ""
            print(f"üíπ {ticker}: {roi_percent:+.2f}% {status}{partial_note}")
            
            return result
            
        except Exception as e:
            print(f"‚ùå Erreur simulation {ticker}: {e}")
            return None
    
    def run_backtest(self) -> Dict:
        """
        Ex√©cute le backtest complet et g√©n√®re le rapport de performance
        
        Returns:
            Dict: R√©sultats complets du backtest
        """
        print("üöÄ D√âMARRAGE DU BACKTEST BERZERK")
        print("=" * 60)
        
        # √âtape 1 : Extraire les d√©cisions d'ACHAT
        buy_decisions = self.get_buy_decisions()
        
        if not buy_decisions:
            print("‚ùå Aucune d√©cision d'ACHAT trouv√©e dans la base de donn√©es")
            return {'error': 'No buy decisions found'}
        
        # √âtape 2 : Simuler chaque trade
        print(f"\nüéØ Simulation de {len(buy_decisions)} trades...")
        print("-" * 60)
        
        successful_trades = []
        failed_trades = []
        
        for trade in buy_decisions:
            result = self.simulate_trade(trade)
            if result:
                successful_trades.append(result)
            else:
                failed_trades.append(trade)
        
        # √âtape 3 : Calculer les m√©triques
        if not successful_trades:
            print("‚ùå Aucun trade n'a pu √™tre simul√©")
            return {'error': 'No successful simulations'}
        
        # M√©triques de performance
        total_trades = len(successful_trades)
        winning_trades = [t for t in successful_trades if t['is_profitable']]
        losing_trades = [t for t in successful_trades if not t['is_profitable']]
        
        win_rate = (len(winning_trades) / total_trades) * 100
        avg_roi = sum(t['roi_percent'] for t in successful_trades) / total_trades
        total_roi = sum(t['roi_percent'] for t in successful_trades)
        
        best_trade = max(successful_trades, key=lambda x: x['roi_percent'])
        worst_trade = min(successful_trades, key=lambda x: x['roi_percent'])
        
        # Stocker les r√©sultats
        self.results = successful_trades
        
        return {
            'total_trades': total_trades,
            'successful_simulations': len(successful_trades),
            'failed_simulations': len(failed_trades),
            'winning_trades': len(winning_trades),
            'losing_trades': len(losing_trades),
            'win_rate': round(win_rate, 2),
            'avg_roi': round(avg_roi, 2),
            'total_roi': round(total_roi, 2),
            'best_trade': best_trade,
            'worst_trade': worst_trade,
            'trades': successful_trades
        }
    
    def display_results(self, results: Dict):
        """
        Affiche le rapport de performance format√©
        
        Args:
            results: R√©sultats du backtest
        """
        if 'error' in results:
            print(f"‚ùå Erreur : {results['error']}")
            return
        
        print("\n" + "=" * 60)
        print("üìà RAPPORT DE PERFORMANCE BERZERK")
        print("=" * 60)
        
        # Statistiques globales
        print("\nüìä STATISTIQUES GLOBALES")
        print("-" * 30)
        print(f"Total des trades simul√©s    : {results['total_trades']}")
        print(f"Simulations r√©ussies       : {results['successful_simulations']}")
        print(f"Simulations √©chou√©es       : {results['failed_simulations']}")
        print(f"Trades gagnants            : {results['winning_trades']}")
        print(f"Trades perdants            : {results['losing_trades']}")
        print(f"Taux de r√©ussite           : {results['win_rate']:.2f}%")
        print(f"ROI moyen par trade        : {results['avg_roi']:+.2f}%")
        print(f"ROI total cumul√©           : {results['total_roi']:+.2f}%")
        
        # Meilleurs et pires trades
        print(f"\nüèÜ MEILLEUR TRADE")
        print("-" * 20)
        best = results['best_trade']
        print(f"Ticker  : {best['ticker']}")
        print(f"ROI     : {best['roi_percent']:+.2f}%")
        print(f"Achat   : {best['buy_price']:.2f} USD le {best['buy_date'].strftime('%Y-%m-%d')}")
        print(f"Vente   : {best['sell_price']:.2f} USD le {best['sell_date'].strftime('%Y-%m-%d')}")
        
        print(f"\nüìâ PIRE TRADE")
        print("-" * 15)
        worst = results['worst_trade']
        print(f"Ticker  : {worst['ticker']}")
        print(f"ROI     : {worst['roi_percent']:+.2f}%")
        print(f"Achat   : {worst['buy_price']:.2f} USD le {worst['buy_date'].strftime('%Y-%m-%d')}")
        print(f"Vente   : {worst['sell_price']:.2f} USD le {worst['sell_date'].strftime('%Y-%m-%d')}")
        
        # D√©tail de tous les trades
        print(f"\nüìã D√âTAIL DE TOUS LES TRADES")
        print("-" * 40)
        for trade in results['trades']:
            status = "‚úÖ" if trade['is_profitable'] else "‚ùå"
            print(f"{status} {trade['ticker']:<6} | {trade['roi_percent']:+6.2f}% | "
                  f"{trade['buy_date'].strftime('%Y-%m-%d')} ‚Üí {trade['sell_date'].strftime('%Y-%m-%d')} | "
                  f"{trade['title']}")
        
        # Conclusions
        print(f"\nüéØ CONCLUSIONS")
        print("-" * 15)
        if results['win_rate'] > 60:
            print("üî• Performance EXCELLENTE ! Le syst√®me montre une tr√®s bonne capacit√© pr√©dictive.")
        elif results['win_rate'] > 50:
            print("üëç Performance POSITIVE. Le syst√®me bat le hasard.")
        else:
            print("‚ö†Ô∏è  Performance √Ä AM√âLIORER. Revoir les strat√©gies d'analyse.")
        
        if results['avg_roi'] > 2:
            print("üí∞ ROI moyen tr√®s attractif pour une strat√©gie √† 7 jours.")
        elif results['avg_roi'] > 0:
            print("üìà ROI moyen positif, strat√©gie rentable.")
        else:
            print("üìâ ROI moyen n√©gatif, n√©cessite des ajustements.")

def main():
    """
    Fonction principale du backtester
    """
    print("üéØ BERZERK BACKTESTER - Validation de Performance")
    print("=" * 60)
    
    # V√©rifier les pr√©requis
    try:
        import yfinance
        import pandas
    except ImportError as e:
        print(f"‚ùå Erreur : Module manquant {e}")
        print("üí° Installez les d√©pendances : pip install yfinance pandas")
        sys.exit(1)
    
    # Lancer le backtester
    backtester = BerzerkBacktester()
    results = backtester.run_backtest()
    backtester.display_results(results)
    
    print(f"\nüîÑ Backtest termin√© ! P√©riode test√©e : {HOLDING_PERIOD_DAYS} jours")
    print("üìä Utilisez ces r√©sultats pour am√©liorer les strat√©gies BERZERK.")

if __name__ == "__main__":
    main()
</file>

<file path="berzerk_dashboard.py">
#!/usr/bin/env python3
"""
üéØ BERZERK COMMAND CENTER - Dashboard Professionnel
===================================================

Interface Streamlit avanc√©e pour visualiser et analyser les performances
du syst√®me BERZERK avec tableaux de bord interactifs et analytics.

Fonctionnalit√©s:
- üìà Live Feed: Analyses en temps r√©el avec cartes interactives
- üèÜ Performance & Backtest: M√©triques de performance et backtesting
- üìä Graphiques interactifs avec Plotly
- üé® Interface moderne avec couleurs et ic√¥nes
- ‚ö° Cache optimis√© pour performances

Usage: streamlit run berzerk_dashboard.py
"""

import streamlit as st
import sqlite3
import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import yfinance as yf
import time

# Configuration de la page
st.set_page_config(
    page_title="BERZERK Command Center", 
    layout="wide",
    page_icon="üéØ",
    initial_sidebar_state="collapsed"
)

# Styles CSS personnalis√©s
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
    }
    
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #2a5298;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    
    .decision-card {
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
        background: white;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .profit-positive {
        color: #28a745;
        font-weight: bold;
    }
    
    .profit-negative {
        color: #dc3545;
        font-weight: bold;
    }
    
    .status-badge {
        padding: 0.25rem 0.5rem;
        border-radius: 15px;
        font-size: 0.8rem;
        font-weight: bold;
        text-transform: uppercase;
    }
    
    .status-analyzed {
        background: #d4edda;
        color: #155724;
    }
    
    .status-pending {
        background: #fff3cd;
        color: #856404;
    }
    
    .status-error {
        background: #f8d7da;
        color: #721c24;
    }
</style>
""", unsafe_allow_html=True)

# =============================================================================
# FONCTIONS DE CACHE ET DONN√âES
# =============================================================================

@st.cache_data(ttl=30)  # Cache pendant 30 secondes pour live feed
def get_articles_with_decisions():
    """R√©cup√®re tous les articles avec leurs d√©cisions"""
    conn = sqlite3.connect('berzerk.db')
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT * FROM articles 
        ORDER BY published_date DESC
    """)
    
    articles = [dict(row) for row in cursor.fetchall()]
    conn.close()
    return articles

@st.cache_data(ttl=60)  # Cache pendant 1 minute
def get_dashboard_stats():
    """R√©cup√®re les statistiques avanc√©es pour le dashboard"""
    conn = sqlite3.connect('berzerk.db')
    cursor = conn.cursor()
    
    # Statistiques g√©n√©rales
    cursor.execute("SELECT COUNT(*) FROM articles")
    total_articles = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM articles WHERE status = 'analyzed'")
    analyzed_count = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM articles WHERE status = 'pending'")
    pending_count = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM articles WHERE status = 'error'")
    error_count = cursor.fetchone()[0]
    
    # Statistiques des derni√®res 24h
    cursor.execute("""
        SELECT COUNT(*) FROM articles 
        WHERE analyzed_at >= datetime('now', '-1 day')
    """)
    analyzed_24h = cursor.fetchone()[0]
    
    # D√©cisions d'achat
    cursor.execute("""
        SELECT COUNT(*) FROM articles 
        WHERE decision_json LIKE '%"action": "ACHETER"%'
    """)
    buy_decisions = cursor.fetchone()[0]
    
    # Derni√®re analyse
    cursor.execute("""
        SELECT analyzed_at FROM articles 
        WHERE status = 'analyzed' AND analyzed_at IS NOT NULL 
        ORDER BY analyzed_at DESC LIMIT 1
    """)
    last_analysis = cursor.fetchone()
    last_analysis = last_analysis[0] if last_analysis else None
    
    conn.close()
    
    return {
        "total_articles": total_articles,
        "analyzed_count": analyzed_count,
        "pending_count": pending_count,
        "error_count": error_count,
        "analyzed_24h": analyzed_24h,
        "buy_decisions": buy_decisions,
        "last_analysis": last_analysis
    }

@st.cache_data(ttl=300)  # Cache pendant 5 minutes
def get_backtest_data():
    """R√©cup√®re et traite les donn√©es de backtest"""
    conn = sqlite3.connect('berzerk.db')
    cursor = conn.cursor()
    
    # R√©cup√©rer les d√©cisions d'achat
    cursor.execute('''
        SELECT id, title, published_date, decision_json 
        FROM articles 
        WHERE decision_json IS NOT NULL 
        AND status = "analyzed"
        ORDER BY published_date DESC
    ''')
    
    rows = cursor.fetchall()
    conn.close()
    
    buy_decisions = []
    
    for row in rows:
        article_id, title, published_date, decision_json = row
        
        try:
            decision = json.loads(decision_json)
            action = decision.get('action', '').upper()
            
            if action in ['ACHETER', 'ACHAT', 'BUY']:
                ticker = decision.get('ticker')
                
                if ticker:
                    buy_decisions.append({
                        'article_id': article_id,
                        'title': title,
                        'ticker': ticker,
                        'decision_date': datetime.fromisoformat(published_date),
                        'action': action,
                        'justification': decision.get('justification', 'Aucune justification'),
                        'allocation': decision.get('allocation_pourcentage', 0.0),
                        'confiance': decision.get('confiance', 'INCONNUE')
                    })
        except:
            continue
    
    return buy_decisions

def simulate_trade_performance(ticker: str, decision_date: datetime, holding_days: int = 7) -> Optional[Dict]:
    """Simule la performance d'un trade"""
    try:
        # Calculer les dates
        buy_date = decision_date + timedelta(days=1)
        sell_date = buy_date + timedelta(days=holding_days)
        
        # T√©l√©charger les donn√©es
        stock = yf.Ticker(ticker)
        start_date = buy_date - timedelta(days=10)
        end_date = datetime.now() + timedelta(days=2)
        
        hist = stock.history(start=start_date, end=end_date)
        
        if hist.empty:
            return None
        
        # Trouver les prix
        buy_price = None
        sell_price = None
        
        # Prix d'achat
        for date, row in hist.iterrows():
            if date.date() >= buy_date.date():
                buy_price = row['Open']
                break
        
        if buy_price is None:
            buy_price = hist.iloc[-1]['Close']
        
        # Prix de vente
        if datetime.now().date() < sell_date.date():
            sell_price = hist.iloc[-1]['Close']
        else:
            for date, row in hist.iterrows():
                if date.date() >= sell_date.date():
                    sell_price = row['Open']
                    break
            
            if sell_price is None:
                sell_price = hist.iloc[-1]['Close']
        
        # Calculer la performance
        roi_percent = ((sell_price - buy_price) / buy_price) * 100
        
        return {
            'ticker': ticker,
            'buy_price': round(buy_price, 2),
            'sell_price': round(sell_price, 2),
            'roi_percent': round(roi_percent, 2),
            'is_profitable': roi_percent > 0,
            'decision_date': decision_date,
            'buy_date': buy_date,
            'sell_date': sell_date
        }
        
    except Exception as e:
        return None

# =============================================================================
# FONCTIONS D'AFFICHAGE
# =============================================================================

def parse_decision_json(decision_json: str) -> Dict:
    """Parse le JSON de d√©cision de mani√®re s√©curis√©e"""
    if not decision_json:
        return {}
    try:
        return json.loads(decision_json)
    except:
        return {}

def get_decision_color(action: str) -> str:
    """Retourne la couleur associ√©e √† une action"""
    colors = {
        'ACHETER': '#28a745',
        'VENDRE': '#dc3545',
        'SURVEILLER': '#ffc107',
        'IGNORER': '#6c757d'
    }
    return colors.get(action, '#6c757d')

def display_enhanced_article_card(article: Dict):
    """Affiche une carte d'article am√©lior√©e avec design moderne"""
    decision_data = parse_decision_json(article.get('decision_json', '{}'))
    decision = decision_data.get('decision', {})
    
    # Container principal avec bordure
    with st.container():
        st.markdown('<div class="decision-card">', unsafe_allow_html=True)
        
        # Ligne 1: Statut et Titre
        col1, col2 = st.columns([4, 1])
        
        with col1:
            # Titre avec taille adapt√©e
            title = article['title']
            if len(title) > 80:
                title = title[:80] + "..."
            st.markdown(f"**{title}**")
            
            # M√©tadonn√©es
            source = article.get('source', 'Source inconnue')
            date_str = article.get('published_date', '')
            if date_str:
                try:
                    date_obj = datetime.fromisoformat(date_str)
                    date_display = date_obj.strftime('%d/%m/%Y %H:%M')
                except:
                    date_display = date_str
            else:
                date_display = 'Date inconnue'
            
            st.caption(f"üì∞ {source} ‚Ä¢ üìÖ {date_display}")
        
        with col2:
            # Badge de statut
            if article['status'] == 'analyzed':
                action = decision.get('action', 'N/A')
                confidence = decision.get('confidence', 'N/A')
                
                # Badge color√© pour l'action
                color = get_decision_color(action)
                st.markdown(f'<div style="background-color: {color}; color: white; padding: 0.25rem 0.5rem; border-radius: 15px; text-align: center; font-size: 0.8rem; font-weight: bold;">{action}</div>', unsafe_allow_html=True)
                
                # Confiance
                if confidence != 'N/A':
                    st.caption(f"üéØ {confidence}")
            else:
                status_colors = {
                    'pending': '#ffc107',
                    'error': '#dc3545',
                    'in_progress': '#007bff'
                }
                status_icons = {
                    'pending': '‚è≥',
                    'error': '‚ùå',
                    'in_progress': 'üîÑ'
                }
                
                color = status_colors.get(article['status'], '#6c757d')
                icon = status_icons.get(article['status'], '‚ùì')
                st.markdown(f'<div style="background-color: {color}; color: white; padding: 0.25rem 0.5rem; border-radius: 15px; text-align: center; font-size: 0.8rem; font-weight: bold;">{icon} {article["status"].upper()}</div>', unsafe_allow_html=True)
        
        # Ligne 2: M√©triques de d√©cision (si analys√©)
        if article['status'] == 'analyzed' and decision:
            st.markdown("---")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                action = decision.get('action', 'N/A')
                st.metric("üéØ Action", action)
            
            with col2:
                ticker = decision.get('ticker', 'N/A')
                st.metric("üìä Ticker", ticker)
            
            with col3:
                confidence = decision.get('confidence', 'N/A')
                st.metric("üîç Confiance", confidence)
            
            with col4:
                allocation = decision.get('allocation_pourcentage', 0.0)
                st.metric("üí∞ Allocation", f"{allocation}%")
            
            # Ligne 3: Analyse d√©taill√©e (expandable)
            with st.expander("üïµÔ∏è‚Äç‚ôÇÔ∏è Voir l'analyse d√©taill√©e"):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**‚úÖ Points Cl√©s Positifs:**")
                    justification = decision.get('justification', 'Aucune justification disponible')
                    # Simuler l'extraction de points positifs
                    st.write(f"‚Ä¢ {justification[:100]}...")
                    st.write("‚Ä¢ Analyse technique favorable")
                    st.write("‚Ä¢ Contexte de march√© positif")
                
                with col2:
                    st.markdown("**‚ö†Ô∏è Points Cl√©s N√©gatifs & Risques:**")
                    st.write("‚Ä¢ Volatilit√© du march√©")
                    st.write("‚Ä¢ Risques g√©opolitiques")
                    st.write("‚Ä¢ Conditions macro√©conomiques")
                
                # Justification compl√®te
                st.markdown("**üìù Justification Compl√®te:**")
                st.write(justification)
        
        st.markdown('</div>', unsafe_allow_html=True)

def display_live_feed_tab():
    """Affiche l'onglet Live Feed am√©lior√©"""
    st.markdown('<div class="main-header"><h1>üìà Live Feed - Analyses Temps R√©el</h1></div>', unsafe_allow_html=True)
    
    # Boutons de contr√¥le
    col1, col2, col3, col4 = st.columns([1, 1, 1, 5])
    
    with col1:
        if st.button("üîÑ Actualiser", type="primary"):
            st.cache_data.clear()
            st.rerun()
    
    with col2:
        auto_refresh = st.checkbox("Auto-refresh", value=False)
    
    with col3:
        if st.button("üßπ Vider Cache"):
            st.cache_data.clear()
            st.success("Cache vid√© !")
    
    # Statistiques globales am√©lior√©es
    st.markdown("### üìä Tableau de Bord Ex√©cutif")
    stats = get_dashboard_stats()
    
    col1, col2, col3, col4, col5, col6 = st.columns(6)
    
    with col1:
        st.metric(
            "üì∞ Total Articles", 
            stats['total_articles'],
            help="Nombre total d'articles dans la base"
        )
    
    with col2:
        delta_analyzed = stats['analyzed_24h'] if stats['analyzed_24h'] > 0 else None
        st.metric(
            "‚úÖ Analys√©s", 
            stats['analyzed_count'],
            delta=f"+{delta_analyzed} (24h)" if delta_analyzed else None,
            help="Articles analys√©s avec succ√®s"
        )
    
    with col3:
        st.metric(
            "‚è≥ En Attente", 
            stats['pending_count'],
            help="Articles en attente d'analyse"
        )
    
    with col4:
        st.metric(
            "üéØ D√©cisions d'Achat", 
            stats['buy_decisions'],
            help="Nombre total de d√©cisions d'achat"
        )
    
    with col5:
        st.metric(
            "‚ùå Erreurs", 
            stats['error_count'],
            help="Articles avec erreurs d'analyse"
        )
    
    with col6:
        if stats['last_analysis']:
            try:
                last_time = datetime.fromisoformat(stats['last_analysis'].replace('Z', '+00:00'))
                time_diff = datetime.now() - last_time.replace(tzinfo=None)
                minutes_ago = int(time_diff.total_seconds() // 60)
                st.metric(
                    "üïí Derni√®re Analyse", 
                    f"{minutes_ago}min",
                    help="Temps √©coul√© depuis la derni√®re analyse"
                )
            except:
                st.metric("üïí Derni√®re Analyse", "Erreur")
        else:
            st.metric("üïí Derni√®re Analyse", "Jamais")
    
    # Filtres avanc√©s
    st.markdown("### üîç Filtres Avanc√©s")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        status_filter = st.selectbox(
            "Statut", 
            ["Tous", "analyzed", "pending", "in_progress", "error"],
            index=0
        )
    
    with col2:
        action_filter = st.selectbox(
            "Action",
            ["Toutes", "ACHETER", "VENDRE", "SURVEILLER", "IGNORER"],
            index=0
        )
    
    with col3:
        days_filter = st.selectbox(
            "P√©riode",
            ["Tout", "Derni√®res 24h", "7 derniers jours", "30 derniers jours"],
            index=0
        )
    
    with col4:
        confidence_filter = st.selectbox(
            "Confiance",
            ["Toutes", "√âLEV√âE", "MOYENNE", "FAIBLE"],
            index=0
        )
    
    # R√©cup√©ration et filtrage des articles
    articles = get_articles_with_decisions()
    
    # Application des filtres
    if status_filter != "Tous":
        articles = [a for a in articles if a['status'] == status_filter]
    
    if action_filter != "Toutes":
        articles = [a for a in articles if action_filter in str(a.get('decision_json', ''))]
    
    if days_filter != "Tout":
        days_map = {"Derni√®res 24h": 1, "7 derniers jours": 7, "30 derniers jours": 30}
        days = days_map[days_filter]
        cutoff_date = datetime.now() - timedelta(days=days)
        articles = [a for a in articles if datetime.fromisoformat(a.get('published_date', '1970-01-01')) > cutoff_date]
    
    if confidence_filter != "Toutes":
        articles = [a for a in articles if confidence_filter in str(a.get('decision_json', ''))]
    
    # Affichage des articles
    st.markdown(f"### üìã Articles Filtr√©s ({len(articles)} r√©sultats)")
    
    if not articles:
        st.warning("Aucun article ne correspond aux crit√®res de filtrage.")
        return
    
    # Affichage des cartes d'articles
    for article in articles:
        display_enhanced_article_card(article)
    
    # Auto-refresh
    if auto_refresh:
        time.sleep(30)
        st.rerun()

def display_performance_tab():
    """Affiche l'onglet Performance & Backtest"""
    st.markdown('<div class="main-header"><h1>üèÜ Performance & Backtest</h1></div>', unsafe_allow_html=True)
    
    # Boutons de contr√¥le
    col1, col2 = st.columns([1, 5])
    
    with col1:
        if st.button("üîÑ Actualiser Performance", type="primary"):
            st.cache_data.clear()
            st.rerun()
    
    # R√©cup√©ration des donn√©es de backtest
    buy_decisions = get_backtest_data()
    
    if not buy_decisions:
        st.warning("Aucune d√©cision d'achat trouv√©e pour effectuer le backtest.")
        return
    
    st.info(f"üìä {len(buy_decisions)} d√©cisions d'achat trouv√©es pour le backtest")
    
    # Simulation des trades
    with st.spinner("üîÑ Simulation des trades en cours..."):
        trade_results = []
        
        progress_bar = st.progress(0)
        
        for i, decision in enumerate(buy_decisions):
            result = simulate_trade_performance(
                decision['ticker'], 
                decision['decision_date']
            )
            
            if result:
                result.update({
                    'title': decision['title'],
                    'allocation': decision['allocation'],
                    'confidence': decision['confiance']
                })
                trade_results.append(result)
            
            progress_bar.progress((i + 1) / len(buy_decisions))
        
        progress_bar.empty()
    
    if not trade_results:
        st.error("Aucun trade n'a pu √™tre simul√©.")
        return
    
    # Calcul des KPIs
    total_trades = len(trade_results)
    winning_trades = len([t for t in trade_results if t['is_profitable']])
    losing_trades = total_trades - winning_trades
    win_rate = (winning_trades / total_trades) * 100 if total_trades > 0 else 0
    
    total_roi = sum(t['roi_percent'] for t in trade_results)
    avg_roi = total_roi / total_trades if total_trades > 0 else 0
    
    best_trade = max(trade_results, key=lambda x: x['roi_percent'])
    worst_trade = min(trade_results, key=lambda x: x['roi_percent'])
    
    # A. KPIs de Performance
    st.markdown("### üìà KPIs de Performance")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "üéØ Taux de R√©ussite", 
            f"{win_rate:.1f}%",
            delta=f"{winning_trades}/{total_trades}",
            help="Pourcentage de trades rentables"
        )
    
    with col2:
        color = "normal" if avg_roi >= 0 else "inverse"
        st.metric(
            "üìä ROI Moyen", 
            f"{avg_roi:+.2f}%",
            help="Retour sur investissement moyen par trade"
        )
    
    with col3:
        st.metric(
            "‚úÖ Trades Gagnants", 
            winning_trades,
            help="Nombre de trades profitables"
        )
    
    with col4:
        st.metric(
            "‚ùå Trades Perdants", 
            losing_trades,
            help="Nombre de trades en perte"
        )
    
    # B. Graphique de Performance Cumul√©e
    st.markdown("### üìà Performance Cumul√©e")
    
    # Calcul de la performance cumul√©e
    cumulative_performance = []
    capital = 100  # Capital initial de 100‚Ç¨
    
    for i, trade in enumerate(trade_results):
        capital = capital * (1 + trade['roi_percent'] / 100)
        cumulative_performance.append({
            'Trade': i + 1,
            'Capital': capital,
            'Date': trade['decision_date'],
            'Ticker': trade['ticker'],
            'ROI': trade['roi_percent']
        })
    
    df_perf = pd.DataFrame(cumulative_performance)
    
    # Graphique Plotly
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=df_perf['Trade'],
        y=df_perf['Capital'],
        mode='lines+markers',
        name='Capital Cumul√©',
        line=dict(color='#2a5298', width=3),
        marker=dict(size=6),
        hovertemplate='<b>Trade %{x}</b><br>' +
                      'Capital: %{y:.2f}‚Ç¨<br>' +
                      'ROI: %{customdata:.2f}%<extra></extra>',
        customdata=df_perf['ROI']
    ))
    
    fig.add_hline(y=100, line_dash="dash", line_color="gray", 
                  annotation_text="Capital Initial (100‚Ç¨)")
    
    fig.update_layout(
        title="üöÄ √âvolution du Capital (100‚Ç¨ initial)",
        xaxis_title="Num√©ro de Trade",
        yaxis_title="Capital (‚Ç¨)",
        height=500,
        showlegend=True,
        hovermode='x unified'
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # M√©triques finales
    final_capital = df_perf['Capital'].iloc[-1]
    total_return = ((final_capital - 100) / 100) * 100
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric(
            "üí∞ Capital Final", 
            f"{final_capital:.2f}‚Ç¨",
            delta=f"{total_return:+.2f}%"
        )
    
    with col2:
        st.metric(
            "üéØ Performance Totale", 
            f"{total_return:+.2f}%",
            help="Performance totale depuis le d√©but"
        )
    
    # C. Tableau des Trades D√©taill√©s
    st.markdown("### üìã Tableau des Trades D√©taill√©s")
    
    # Pr√©paration du DataFrame
    df_trades = pd.DataFrame(trade_results)
    
    # Formatage des colonnes
    df_trades['decision_date'] = pd.to_datetime(df_trades['decision_date']).dt.strftime('%Y-%m-%d')
    df_trades['buy_date'] = pd.to_datetime(df_trades['buy_date']).dt.strftime('%Y-%m-%d')
    df_trades['Performance'] = df_trades['roi_percent'].apply(lambda x: f"{x:+.2f}%")
    
    # S√©lection des colonnes √† afficher
    display_columns = ['ticker', 'title', 'decision_date', 'buy_price', 'sell_price', 'Performance', 'confidence']
    df_display = df_trades[display_columns].copy()
    
    # Renommage des colonnes
    df_display.columns = ['Ticker', 'Titre', 'Date D√©cision', 'Prix Achat', 'Prix Vente', 'Performance', 'Confiance']
    
    # Style conditionnel
    def highlight_performance(row):
        if 'Performance' in row:
            if '+' in str(row['Performance']):
                return ['background-color: #d4edda'] * len(row)
            else:
                return ['background-color: #f8d7da'] * len(row)
        return [''] * len(row)
    
    # Affichage du tableau styl√©
    styled_df = df_display.style.apply(highlight_performance, axis=1)
    st.dataframe(styled_df, use_container_width=True, height=400)
    
    # D. Meilleurs et Pires Trades
    st.markdown("### üèÜ Meilleurs et Pires Trades")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ü•á Meilleur Trade")
        st.success(f"**{best_trade['ticker']}** - {best_trade['roi_percent']:+.2f}%")
        st.write(f"üìÖ {best_trade['decision_date'].strftime('%Y-%m-%d')}")
        st.write(f"üí∞ {best_trade['buy_price']} ‚Üí {best_trade['sell_price']}")
        st.write(f"üì∞ {best_trade['title'][:50]}...")
    
    with col2:
        st.markdown("#### üìâ Pire Trade")
        st.error(f"**{worst_trade['ticker']}** - {worst_trade['roi_percent']:+.2f}%")
        st.write(f"üìÖ {worst_trade['decision_date'].strftime('%Y-%m-%d')}")
        st.write(f"üí∞ {worst_trade['buy_price']} ‚Üí {worst_trade['sell_price']}")
        st.write(f"üì∞ {worst_trade['title'][:50]}...")

# =============================================================================
# INTERFACE PRINCIPALE
# =============================================================================

def main():
    """Interface principale du BERZERK Command Center"""
    
    # En-t√™te principal
    st.markdown("""
    <div style="text-align: center; background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%); 
                padding: 2rem; border-radius: 10px; margin-bottom: 2rem;">
        <h1 style="color: white; margin: 0;">üéØ BERZERK COMMAND CENTER</h1>
        <p style="color: #e0e0e0; margin: 0;">Analyse Automatis√©e ‚Ä¢ D√©cisions Intelligentes ‚Ä¢ Performance Optimis√©e</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Navigation par onglets
    tab1, tab2 = st.tabs(["üìà Live Feed", "üèÜ Performance & Backtest"])
    
    with tab1:
        display_live_feed_tab()
    
    with tab2:
        display_performance_tab()

if __name__ == "__main__":
    main()
</file>

<file path="berzerk_lab.py">
import streamlit as st
import feedparser
from dotenv import load_dotenv
import requests
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime
import sqlite3

# LangChain Imports
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field

# NOUVEAU : Import depuis notre module d'agents
from agents import route_to_agents, run_agent_analysis

# --- CONFIGURATION & SETUP ---
load_dotenv()

def init_db():
    """Initialise la base de donn√©es SQLite et cr√©e la table articles."""
    conn = sqlite3.connect('berzerk.db')
    cursor = conn.cursor()
    # On cr√©e une table pour stocker les articles.
    # Le lien (link) est UNIQUE pour √©viter les doublons.
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS articles (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            source TEXT NOT NULL,
            title TEXT NOT NULL,
            link TEXT NOT NULL UNIQUE,
            published_str TEXT,
            published_date DATETIME NOT NULL,
            fetched_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            status TEXT DEFAULT 'pending',
            decision_json TEXT,
            analyzed_at DATETIME
        )
    ''')
    
    # Ajouter les nouvelles colonnes si elles n'existent pas (pour les anciennes bases)
    try:
        cursor.execute("ALTER TABLE articles ADD COLUMN status TEXT DEFAULT 'pending'")
    except sqlite3.OperationalError:
        pass  # La colonne existe d√©j√†
    
    try:
        cursor.execute("ALTER TABLE articles ADD COLUMN decision_json TEXT")
    except sqlite3.OperationalError:
        pass  # La colonne existe d√©j√†
        
    try:
        cursor.execute("ALTER TABLE articles ADD COLUMN analyzed_at DATETIME")
    except sqlite3.OperationalError:
        pass  # La colonne existe d√©j√†
    
    conn.commit()
    conn.close()

# D√©finition de la structure de sortie attendue
class Analysis(BaseModel):
    resume: str = Field(description="R√©sum√© de la news en 3 phrases maximum.")
    impact: int = Field(description="Note d'impact de 1 (faible) √† 10 (tr√®s fort) sur les march√©s.")
    evaluation: str = Field(description="Une cha√Æne de caract√®res: 'Positif', 'N√©gatif' ou 'Neutre'.")
    entites: list[str] = Field(description="Liste de tickers d'actions (ex: ['AAPL', 'TSLA']), de noms de soci√©t√©s et de secteurs concern√©s.")

# Initialisation du mod√®le LLM via LangChain
try:
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash-lite-preview-06-17", temperature=0)
except Exception as e:
    st.error(f"Erreur d'initialisation du mod√®le LangChain. V√©rifiez votre GOOGLE_API_KEY. Erreur: {e}")
    llm = None

# Liste des flux RSS fonctionnels (apr√®s notre diagnostic)
RSS_FEEDS = {
    "Bloomberg": "https://feeds.bloomberg.com/markets/news.rss"
}

# --- FONCTIONS CORE ---

def fetch_and_store_news(feeds):
    """Parcourt les flux RSS et ins√®re les nouveaux articles dans la DB."""
    conn = sqlite3.connect('berzerk.db')
    cursor = conn.cursor()
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    new_articles_found = 0
    for source, url in feeds.items():
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                feed = feedparser.parse(response.content)
                for entry in feed.entries:
                    # On r√©cup√®re la date et on la convertit en objet datetime
                    # feedparser a une structure pratique pour √ßa dans "published_parsed"
                    published_tuple = entry.get('published_parsed')
                    if published_tuple:
                        dt_object = datetime(*published_tuple[:6])
                    else:
                        dt_object = datetime.now() # Fallback si pas de date

                    # INSERT OR IGNORE est la cl√© : il n'ins√®re que si le lien n'existe pas d√©j√†
                    cursor.execute('''
                        INSERT OR IGNORE INTO articles (source, title, link, published_str, published_date)
                        VALUES (?, ?, ?, ?, ?)
                    ''', (source, entry.title, entry.link, entry.get('published', 'N/A'), dt_object))
                    
                    if cursor.rowcount > 0:
                        new_articles_found += 1

        except Exception as e:
            print(f"Erreur lors de la r√©cup√©ration du flux de {source}: {e}")
            
    conn.commit()
    conn.close()
    return new_articles_found

def get_articles_from_db():
    """R√©cup√®re tous les articles de la DB, tri√©s par date de publication."""
    conn = sqlite3.connect('berzerk.db')
    # On force la connexion √† retourner des dictionnaires au lieu de tuples, c'est plus pratique
    conn.row_factory = sqlite3.Row 
    cursor = conn.cursor()
    
    cursor.execute("SELECT * FROM articles ORDER BY published_date DESC")
    articles = [dict(row) for row in cursor.fetchall()]
    
    conn.close()
    return articles

def get_article_text(url):
    # (Cette fonction ne change pas)
    try:
        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        paragraphs = soup.find_all('p')
        article_text = ' '.join([p.get_text() for p in paragraphs])
        return article_text
    except Exception as e:
        print(f"Erreur de r√©cup√©ration de l'article √† l'URL {url}: {e}")
        return None

def analyze_news_with_llm(article_text: str):
    """Analyse un article en utilisant une cha√Æne LangChain."""
    if not llm or not article_text:
        return None
    
    parser = JsonOutputParser(pydantic_object=Analysis)
    prompt_template = """Tu es un analyste financier expert pour le syst√®me BERSERK. Analyse l'article de presse suivant et extrais les informations cl√©s.
    {format_instructions}
    Voici l'article :
    ---
    {article}
    ---"""
    prompt = PromptTemplate(
        template=prompt_template,
        input_variables=["article"],
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )
    chain = prompt | llm | parser

    try:
        analysis_result = chain.invoke({"article": article_text})
        return analysis_result
    except Exception as e:
        st.error(f"Erreur lors de l'ex√©cution de la cha√Æne LangChain : {e}")
        return None

# --- INTERFACE UTILISATEUR (STREAMLIT) ---

st.set_page_config(page_title="BERSERK Labo", layout="wide")
st.title("üìò BERSERK - Labo d'Analyse (Phase 2)")
st.caption("Moteur: LangChain + Gemini + Agents IA | Monitoring: LangSmith")

# NOUVEAU : On initialise la DB au d√©marrage de l'app
init_db()

if 'articles' not in st.session_state:
    # Au premier chargement, on remplit la liste depuis la DB
    st.session_state.articles = get_articles_from_db()
if 'selected_article_link' not in st.session_state:
    st.session_state.selected_article_link = None
if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = None

# NOUVEAU : Ajouter ces lignes pour g√©rer l'√©tat des agents
if 'agent_team' not in st.session_state:
    st.session_state.agent_team = None
if 'agent_analyses' not in st.session_state:
    st.session_state.agent_analyses = None

left_column, right_column = st.columns([1, 2])

with left_column:
    st.header("Flux d'actualit√©s")
    
    if st.button("üîÑ Charger les derni√®res actualit√©s", use_container_width=True):
        with st.spinner("Recherche de nouveaux articles..."):
            # 1. On cherche et stocke les nouveaux articles
            new_count = fetch_and_store_news(RSS_FEEDS)
            st.toast(f"{new_count} nouvel(s) article(s) trouv√©(s) !")
            # 2. On recharge la liste COMPL√àTE et TRI√âE depuis la DB
            st.session_state.articles = get_articles_from_db()
            st.session_state.selected_article_link = None
            st.session_state.analysis_result = None
            # NOUVEAU : R√©initialiser aussi les agents
            st.session_state.agent_team = None
            st.session_state.agent_analyses = None
        st.rerun()

    # On affiche les articles de st.session_state, qui est maintenant toujours tri√©
    if st.session_state.articles:
        for article in st.session_state.articles:
            with st.container(border=True):
                st.markdown(f"**{article['title']}**")
                
                # NOUVEAU : On affiche la source et l'heure de publication
                # On reformate l'objet datetime pour un affichage lisible
                pub_date = datetime.fromisoformat(article['published_date'])
                st.caption(f"Source: {article['source']} | Publi√© le: {pub_date.strftime('%d/%m/%Y √† %H:%M')}")
                
                if st.button("ü§ñ Analyser", key=article['link']):
                    st.session_state.selected_article_link = article['link']
                    st.session_state.analysis_result = None
                    # NOUVEAU : R√©initialiser aussi les agents
                    st.session_state.agent_team = None
                    st.session_state.agent_analyses = None
                    st.rerun()
    else:
        st.info("Aucun article en base. Cliquez sur 'Charger les derni√®res actualit√©s' pour commencer.")

with right_column:
    st.header("üî¨ Analyse de l'IA")
    
    if st.session_state.selected_article_link:
        if st.session_state.analysis_result is None:
            with st.spinner("Analyse en cours (LangChain)..."):
                link = st.session_state.selected_article_link
                text = get_article_text(link)
                if text:
                    st.session_state.analysis_result = analyze_news_with_llm(text)
                else:
                    st.session_state.analysis_result = {"error": "Contenu inaccessible"}
            st.rerun()

        analysis = st.session_state.analysis_result
        if analysis:
            if "error" in analysis:
                st.error(analysis["error"])
            else:
                st.success("Analyse termin√©e !")
                
                # MISE EN FORME COMME SUR TON SCREENSHOT
                st.subheader("üìù R√©sum√©")
                st.write(analysis.get('resume', 'N/A'))
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("√âvaluation", analysis.get('evaluation', 'N/A'))
                with col2:
                    st.metric("Impact Potentiel", f"{analysis.get('impact', 0)}/10")

                st.subheader("üìà Entit√©s Concern√©es")
                # st.write(analysis.get('entites', [])) # Moins joli
                st.json(analysis.get('entites', [])) # Plus joli

                st.divider() # Ajoute une ligne de s√©paration visuelle

                # --- NOUVELLE SECTION : ORCHESTRATION DES AGENTS ---

                # Si l'√©quipe n'a pas encore √©t√© recrut√©e, afficher le bouton
                if st.session_state.agent_team is None:
                    if st.button("üë• Recruter l'√âquipe d'Agents Sp√©cialis√©s", use_container_width=True):
                        with st.spinner("Le Chef d'Orchestre recrute l'√©quipe..."):
                            # On r√©cup√®re les entit√©s et le r√©sum√© de l'analyse initiale
                            entities = analysis.get('entites', [])
                            summary = analysis.get('resume', '')
                            # On appelle notre routeur intelligent
                            st.session_state.agent_team = route_to_agents(entities, summary)
                        st.rerun()

                # Si l'√©quipe est recrut√©e, on l'affiche et on lance les analyses
                if st.session_state.agent_team is not None:
                    st.subheader("üë• √âquipe d'Agents Recrut√©e")

                    # Afficher l'√©quipe
                    for agent in st.session_state.agent_team:
                        st.info(f"**{agent['agent_type'].replace('_', ' ').title()}** recrut√© avec le focus : *{agent['focus']}*")

                    # Si les analyses ne sont pas encore faites, afficher le bouton pour les lancer
                    if st.session_state.agent_analyses is None:
                        if st.button("üöÄ Lancer les Analyses de l'√âquipe", type="primary", use_container_width=True):
                            st.session_state.agent_analyses = []
                            
                            # On r√©cup√®re le texte complet de l'article UNE SEULE FOIS
                            full_text = get_article_text(st.session_state.selected_article_link)
                            
                            if full_text:
                                # On boucle sur chaque agent recrut√© pour lancer son analyse
                                with st.spinner("Les agents travaillent... Cette op√©ration peut prendre un certain temps."):
                                    for agent in st.session_state.agent_team:
                                        # On appelle la fonction d'ex√©cution de notre module agents.py
                                        single_analysis = run_agent_analysis(
                                            agent_type=agent['agent_type'],
                                            focus=agent['focus'],
                                            news_summary=analysis.get('resume', ''),
                                            full_article_text=full_text
                                        )
                                        st.session_state.agent_analyses.append({
                                            "agent_type": agent['agent_type'],
                                            "focus": agent['focus'],
                                            "analysis": single_analysis
                                        })
                            else:
                                st.error("Impossible de r√©cup√©rer le texte complet de l'article pour les agents.")
                                st.session_state.agent_analyses = [] # Pour √©viter de relancer
                            st.rerun()

                # Si les analyses sont termin√©es, on les affiche
                if st.session_state.agent_analyses is not None:
                    st.subheader("üìù Debriefing de l'√âquipe")
                    for result in st.session_state.agent_analyses:
                        with st.expander(f"**Analyse du {result['agent_type'].replace('_', ' ').title()}** - Focus : *{result['focus']}*"):
                            st.markdown(result['analysis'])
    else:
        st.info("Cliquez sur 'Analyser' sur une news pour commencer.")
</file>

<file path="diagnostic_db.py">
#!/usr/bin/env python3
"""
üîç DIAGNOSTIC BASE DE DONN√âES BERZERK
====================================
Script simple pour analyser les d√©cisions stock√©es
"""

import sqlite3
import json

def diagnostic_db():
    """Analyse le contenu de la base de donn√©es"""
    conn = sqlite3.connect('berzerk.db')
    cursor = conn.cursor()
    
    # Compter les articles avec d√©cisions
    cursor.execute('SELECT COUNT(*) FROM articles WHERE decision_json IS NOT NULL')
    total_analyzed = cursor.fetchone()[0]
    
    # Compter les articles avec statut "analyzed"
    cursor.execute('SELECT COUNT(*) FROM articles WHERE status = "analyzed"')
    status_analyzed = cursor.fetchone()[0]
    
    print(f"üìä Total articles avec d√©cisions: {total_analyzed}")
    print(f"üìä Articles avec statut 'analyzed': {status_analyzed}")
    
    # Examiner les d√©cisions
    cursor.execute('SELECT id, title, decision_json FROM articles WHERE decision_json IS NOT NULL LIMIT 5')
    decisions = cursor.fetchall()
    
    print(f"\nüîç √âchantillon de {len(decisions)} d√©cisions:")
    print("-" * 60)
    
    achat_count = 0
    for article_id, title, decision_json in decisions:
        print(f"\nüì∞ Article {article_id}: {title[:50]}...")
        try:
            decision = json.loads(decision_json)
            
            # V√©rifier le format de la d√©cision
            if isinstance(decision, dict):
                action = decision.get('action', 'N/A')
                ticker = decision.get('ticker', 'N/A')
                
                print(f"   üéØ Action: {action}")
                print(f"   üìà Ticker: {ticker}")
                
                if action and action.upper() == 'ACHETER':
                    achat_count += 1
                    print(f"   ‚úÖ D√âCISION D'ACHAT TROUV√âE!")
                
            else:
                print(f"   ‚ö†Ô∏è  Format inattendu: {type(decision)}")
                
        except json.JSONDecodeError as e:
            print(f"   ‚ùå Erreur JSON: {e}")
    
    print(f"\nüìà R√©sum√©: {achat_count} d√©cision(s) d'ACHAT trouv√©e(s)")
    
    conn.close()

if __name__ == "__main__":
    diagnostic_db()
</file>

<file path="env.example">
# Cl√© API pour Google Gemini
GOOGLE_API_KEY="votre_cl√©_ici"

# Cl√© API pour Tavily Search
TAVILY_API_KEY="votre_cl√©_ici"
</file>

<file path="orchestrator.py">
"""
Orchestrateur Automatis√© BERZERK - Phase 2.3
============================================

Ce module contient le pipeline automatis√© complet utilisant LangGraph pour orchestrer
l'ensemble de la cha√Æne d'analyse financi√®re : de la news brute √† la d√©cision d'investissement.

Architecture : News ‚Üí Analyse Initiale ‚Üí Routage Agents ‚Üí Analyses Sp√©cialis√©es ‚Üí D√©cision Finale

Auteur: BERZERK Team
Phase: 2.3 - Automatisation Compl√®te
"""

import json
import sys
from typing import Dict, List, Any, TypedDict
from datetime import datetime

# LangGraph Imports
from langgraph.graph import StateGraph, END
from langchain_core.output_parsers import JsonOutputParser

# Imports depuis nos modules existants
from berzerk_lab import get_article_text, analyze_news_with_llm
from agents import route_to_agents, run_agent_analysis, run_ticker_hunter, run_augmented_analysis, AGENT_PROFILES, llm

# --- D√âFINITION DE L'√âTAT DU GRAPHE ---

class GraphState(TypedDict):
    """√âtat qui circule dans le graphe et est mis √† jour √† chaque √©tape."""
    news_link: str
    news_summary: str
    full_article_text: str
    initial_analysis: Dict[str, Any]
    actionable_tickers: List[Dict[str, str]]  # Nouveau : R√©sultat du Ticker Hunter
    agent_team: List[Dict[str, str]]
    agent_debriefing: str
    final_decision: Dict[str, Any]
    capital_disponible: float
    execution_log: List[str]
    timestamp: str

# --- MOD√àLE PYDANTIC POUR LA D√âCISION FINALE ---

from pydantic import BaseModel, Field

class InvestmentDecision(BaseModel):
    """Mod√®le pour valider la d√©cision finale d'investissement."""
    decision: str = Field(description="ACHETER, VENDRE, SURVEILLER ou IGNORER")
    ticker: str = Field(description="Ticker de l'action concern√©e ou null")
    confiance: str = Field(description="√âLEV√âE, MOYENNE ou FAIBLE")
    justification_synthetique: str = Field(description="Justification en une phrase")
    allocation_capital_pourcentage: float = Field(description="Pourcentage du capital √† allouer (0.0 √† 5.0)")
    points_cles_positifs: List[str] = Field(description="Points positifs cl√©s")
    points_cles_negatifs_risques: List[str] = Field(description="Risques identifi√©s")

# --- FONCTIONS UTILITAIRES ---

def log_step(state: GraphState, message: str) -> None:
    """Ajoute un log √† l'√©tat avec timestamp."""
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_message = f"[{timestamp}] {message}"
    state["execution_log"].append(log_message)
    print(f"üîÑ {log_message}")

def format_debriefing(agent_analyses: List[Dict[str, str]]) -> str:
    """Formate les analyses des agents pour le superviseur."""
    debriefing_parts = []
    for i, analysis in enumerate(agent_analyses, 1):
        debriefing_parts.append(
            f"\n--- ANALYSE {i} : {analysis['agent_type'].upper().replace('_', ' ')} ---\n"
            f"Focus : {analysis['focus']}\n\n"
            f"{analysis['analysis']}\n"
            f"{'='*80}"
        )
    return "\n".join(debriefing_parts)

# --- N≈íUDS DU GRAPHE (chaque n≈ìud est une fonction) ---

def node_initial_analysis(state: GraphState) -> GraphState:
    """N≈ìud 1 : R√©cup√®re le texte de l'article et fait l'analyse initiale."""
    log_step(state, "D√âMARRAGE - Analyse Initiale")
    
    try:
        # R√©cup√©ration du texte complet
        full_text = get_article_text(state['news_link'])
        if not full_text:
            raise ValueError("Impossible de r√©cup√©rer le texte de l'article")
        
        # Analyse initiale avec LLM
        analysis = analyze_news_with_llm(full_text)
        if not analysis:
            raise ValueError("√âchec de l'analyse initiale")
        
        # Mise √† jour de l'√©tat
        state['full_article_text'] = full_text
        state['initial_analysis'] = analysis
        state['news_summary'] = analysis.get('resume', '')
        
        log_step(state, f"‚úÖ Analyse initiale termin√©e - Impact: {analysis.get('impact', 'N/A')}/10")
        log_step(state, f"‚úÖ Entit√©s d√©tect√©es: {', '.join(analysis.get('entites', []))}")
        
    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans l'analyse initiale: {str(e)}")
        state['initial_analysis'] = {"error": str(e)}
    
    return state

def node_find_actionable_tickers(state: GraphState) -> GraphState:
    """N≈ìud 2 : Chasse aux Tickers - Identifie les tickers actionnables."""
    log_step(state, "TICKER HUNTER - Identification des tickers actionnables")
    
    try:
        if 'error' in state['initial_analysis']:
            raise ValueError("Analyse initiale √©chou√©e, impossible d'identifier les tickers")
        
        # Ex√©cution du Ticker Hunter
        ticker_result = run_ticker_hunter(
            news_summary=state['news_summary'],
            full_article_text=state['full_article_text']
        )
        
        actionable_tickers = ticker_result.get('tickers_identifies', [])
        state['actionable_tickers'] = actionable_tickers
        
        if actionable_tickers:
            log_step(state, f"üéØ {len(actionable_tickers)} ticker(s) actionnable(s) identifi√©(s)")
            for ticker_info in actionable_tickers:
                # Gestion des objets Pydantic ET des dictionnaires
                if hasattr(ticker_info, 'ticker'):
                    ticker = ticker_info.ticker
                    company = ticker_info.nom_entreprise
                else:
                    ticker = ticker_info.get('ticker', 'N/A')
                    company = ticker_info.get('nom_entreprise', 'N/A')
                log_step(state, f"   ‚Üí {ticker} ({company})")
        else:
            log_step(state, "‚ö†Ô∏è  Aucun ticker actionnable identifi√© - Pipeline orient√© macro")
            
    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans le Ticker Hunter: {str(e)}")
        state['actionable_tickers'] = []
    
    return state

def node_route_to_agents(state: GraphState) -> GraphState:
    """N≈ìud 3 : Recrute l'√©quipe d'agents bas√©e sur les tickers identifi√©s."""
    log_step(state, "ROUTAGE - Recrutement de l'√©quipe d'agents (bas√© sur tickers)")
    
    try:
        if 'error' in state['initial_analysis']:
            raise ValueError("Analyse initiale √©chou√©e, impossible de router")
        
        actionable_tickers = state.get('actionable_tickers', [])
        
        if actionable_tickers:
            # Mode PR√âCIS : Tickers identifi√©s ‚Üí Agents cibl√©s
            team = []
            
            # Pour chaque ticker, on cr√©e un analyste d'actions d√©di√©
            for ticker_info in actionable_tickers:
                # Gestion des objets Pydantic ET des dictionnaires
                if hasattr(ticker_info, 'ticker'):
                    ticker = ticker_info.ticker
                    company = ticker_info.nom_entreprise
                else:
                    ticker = ticker_info.get('ticker', '')
                    company = ticker_info.get('nom_entreprise', '')
                
                team.append({
                    "agent_type": "analyste_actions",
                    "focus": f"{ticker} ({company})"
                })
            
            # Ajout d'un analyste sectoriel si multiple tickers
            if len(actionable_tickers) > 1:
                sectors = []
                for ticker_info in actionable_tickers:
                    # Gestion des objets Pydantic ET des dictionnaires
                    if hasattr(ticker_info, 'justification_impact'):
                        justification = ticker_info.justification_impact
                    else:
                        justification = ticker_info.get('justification_impact', '')
                    # Extraction de mots-cl√©s sectoriels basiques
                    if any(word in justification.lower() for word in ['tech', 'technologie', 'intelligence artificielle', 'ia']):
                        sectors.append('Technologie')
                    elif any(word in justification.lower() for word in ['auto', 'v√©hicule', 'transport']):
                        sectors.append('Automobile')
                    elif any(word in justification.lower() for word in ['√©nergie', 'p√©trole', 'gaz']):
                        sectors.append('√ânergie')
                    elif any(word in justification.lower() for word in ['finance', 'banque', 'cr√©dit']):
                        sectors.append('Finance')
                
                if sectors:
                    unique_sectors = list(set(sectors))
                    team.append({
                        "agent_type": "analyste_sectoriel",
                        "focus": f"Impact sectoriel sur {', '.join(unique_sectors)}"
                    })
            
            log_step(state, f"üéØ Mode PR√âCIS activ√© - {len(actionable_tickers)} ticker(s) cibl√©(s)")
            
        else:
            # Mode FALLBACK : Analyse macro classique
            entities = state['initial_analysis'].get('entites', [])
            team = route_to_agents(entities, state['news_summary'])
            log_step(state, "‚ö†Ô∏è Mode FALLBACK - Pas de tickers, analyse macro")
        
        if not team:
            raise ValueError("Aucun agent recrut√© par le routeur")
        
        state['agent_team'] = team
        
        log_step(state, f"‚úÖ √âquipe recrut√©e: {len(team)} agent(s)")
        for agent in team:
            log_step(state, f"   - {agent['agent_type']} ‚Üí Focus: {agent['focus']}")
            
    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans le routage: {str(e)}")
        state['agent_team'] = []
    
    return state

def node_run_agent_analyses(state: GraphState) -> GraphState:
    """N≈ìud 4 : Ex√©cute les analyses de chaque agent sp√©cialis√© (avec agents augment√©s)."""
    log_step(state, "EX√âCUTION - Analyses sp√©cialis√©es avec outils temps r√©el")
    
    try:
        if not state['agent_team']:
            raise ValueError("Aucun agent disponible pour l'analyse")
        
        agent_analyses = []
        actionable_tickers = state.get('actionable_tickers', [])
        
        for i, agent in enumerate(state['agent_team'], 1):
            log_step(state, f"Ex√©cution agent {i}/{len(state['agent_team'])}: {agent['agent_type']}")
            
            # D√©tecter si c'est un agent d'analyse d'actions avec ticker identifi√©
            is_ticker_analysis = (
                agent['agent_type'] == 'analyste_actions' and 
                actionable_tickers and 
                len(actionable_tickers) > 0
            )
            
            if is_ticker_analysis:
                # Extraire le ticker du focus (format: "AAPL (Apple Inc.)")
                focus_text = agent['focus']
                ticker = None
                
                # Chercher le ticker dans les actionable_tickers
                for ticker_info in actionable_tickers:
                    # Gestion des objets Pydantic ET des dictionnaires
                    if hasattr(ticker_info, 'ticker'):
                        ticker_value = ticker_info.ticker
                    else:
                        ticker_value = ticker_info.get('ticker', '')
                    
                    if ticker_value in focus_text:
                        ticker = ticker_value
                        break
                
                if ticker:
                    log_step(state, f"üöÄ Analyse AUGMENT√âE pour {ticker} (avec outils temps r√©el)")
                    
                    # Utiliser l'agent augment√© avec acc√®s aux outils
                    analysis = run_augmented_analysis(
                        ticker=ticker,
                        news_summary=state['news_summary'],
                        full_article_text=state['full_article_text']
                    )
                    
                    agent_analyses.append({
                        "agent_type": agent['agent_type'] + "_augmented",  # Marquer comme augment√©
                        "focus": agent['focus'],
                        "analysis": analysis,
                        "ticker": ticker,
                        "is_augmented": True
                    })
                    
                    log_step(state, f"‚úÖ Analyse AUGMENT√âE termin√©e pour {ticker}")
                else:
                    # Fallback vers l'analyse classique
                    log_step(state, f"‚ö†Ô∏è Ticker non trouv√©, analyse classique pour {focus_text}")
                    analysis = run_agent_analysis(
                        agent_type=agent['agent_type'],
                        focus=agent['focus'],
                        news_summary=state['news_summary'],
                        full_article_text=state['full_article_text']
                    )
                    
                    agent_analyses.append({
                        "agent_type": agent['agent_type'],
                        "focus": agent['focus'],
                        "analysis": analysis,
                        "is_augmented": False
                    })
                    
                    log_step(state, f"‚úÖ Analyse classique termin√©e: {agent['agent_type']}")
            else:
                # Agent classique (sectoriel, g√©opolitique, etc.)
                log_step(state, f"üìä Analyse classique pour {agent['agent_type']}")
                
                analysis = run_agent_analysis(
                    agent_type=agent['agent_type'],
                    focus=agent['focus'],
                    news_summary=state['news_summary'],
                    full_article_text=state['full_article_text']
                )
                
                agent_analyses.append({
                    "agent_type": agent['agent_type'],
                    "focus": agent['focus'],
                    "analysis": analysis,
                    "is_augmented": False
                })
                
                log_step(state, f"‚úÖ Analyse classique termin√©e: {agent['agent_type']}")
        
        # Formatage du debriefing pour le superviseur
        state['agent_debriefing'] = format_debriefing(agent_analyses)
        
        # Compter les analyses augment√©es
        augmented_count = sum(1 for a in agent_analyses if a.get('is_augmented', False))
        log_step(state, f"‚úÖ Debriefing consolid√© - {len(agent_analyses)} analyses ({augmented_count} augment√©e(s))")
        
    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans les analyses d'agents: {str(e)}")
        state['agent_debriefing'] = f"ERREUR: {str(e)}"
    
    return state

def node_final_investor_decision(state: GraphState) -> GraphState:
    """N≈ìud 5 : Prend la d√©cision finale d'investissement via l'Agent Superviseur."""
    log_step(state, "D√âCISION - Agent Investisseur Final")
    
    try:
        if not state['agent_debriefing'] or 'ERREUR' in state['agent_debriefing']:
            raise ValueError("Debriefing invalide, impossible de prendre une d√©cision")
        
        # Configuration du parser JSON
        parser = JsonOutputParser(pydantic_object=InvestmentDecision)
        
        # R√©cup√©ration du template de l'investisseur final
        investor_prompt = AGENT_PROFILES["investisseur_final"]
        
        # Formatage des tickers pour l'investisseur final
        actionable_tickers = state.get('actionable_tickers', [])
        tickers_summary = "Aucun ticker sp√©cifique identifi√©"
        
        if actionable_tickers:
            tickers_list = []
            for ticker_info in actionable_tickers:
                # Gestion des objets Pydantic ET des dictionnaires
                if hasattr(ticker_info, 'ticker'):
                    # Objet Pydantic
                    ticker = ticker_info.ticker
                    company = ticker_info.nom_entreprise
                    justification = ticker_info.justification_impact
                else:
                    # Dictionnaire classique (fallback)
                    ticker = ticker_info.get('ticker', 'N/A')
                    company = ticker_info.get('nom_entreprise', 'N/A')
                    justification = ticker_info.get('justification_impact', 'N/A')
                
                tickers_list.append(f"‚Ä¢ {ticker} ({company}): {justification}")
            tickers_summary = "\n".join(tickers_list)
        
        # Cr√©ation de la cha√Æne LangChain
        chain = investor_prompt | llm | parser
        
        # Ex√©cution de la d√©cision
        decision_result = chain.invoke({
            "debriefing_equipe": state['agent_debriefing'],
            "capital_disponible": state['capital_disponible'],
            "actionable_tickers": tickers_summary
        })
        
        # --- D√âBUT DE LA CORRECTION ---
        decision_obj = None
        if isinstance(decision_result, list):
            if decision_result:
                # Si le LLM retourne une liste, on prend le premier √©l√©ment
                log_step(state, "‚ö†Ô∏è  Le LLM a retourn√© une liste, prise du premier √©l√©ment.")
                decision_obj = decision_result[0]
            else:
                raise ValueError("Le LLM a retourn√© une liste vide.")
        else:
            # Comportement normal (objet Pydantic ou dict)
            decision_obj = decision_result
        
        # Maintenant, on s'assure que decision_obj est un dictionnaire
        if hasattr(decision_obj, 'decision'):
            # C'est un objet Pydantic, convertir en dict
            decision_dict = {
                'decision': decision_obj.decision,
                'ticker': decision_obj.ticker,
                'confiance': decision_obj.confiance,
                'justification_synthetique': decision_obj.justification_synthetique,
                'allocation_capital_pourcentage': decision_obj.allocation_capital_pourcentage,
                'points_cles_positifs': decision_obj.points_cles_positifs,
                'points_cles_negatifs_risques': decision_obj.points_cles_negatifs_risques
            }
        else:
            # C'est d√©j√† un dictionnaire
            decision_dict = decision_obj
        # --- FIN DE LA CORRECTION ---
        
        state['final_decision'] = decision_dict
        
        # Logs d√©taill√©s de la d√©cision
        log_step(state, f"‚úÖ D√âCISION PRISE: {decision_dict.get('decision', 'N/A')}")
        log_step(state, f"   üéØ Ticker: {decision_dict.get('ticker', 'N/A')}")
        log_step(state, f"   üìä Confiance: {decision_dict.get('confiance', 'N/A')}")
        log_step(state, f"   üí∞ Allocation: {decision_dict.get('allocation_capital_pourcentage', 0)}%")
        log_step(state, f"   üìù Justification: {decision_dict.get('justification_synthetique', 'N/A')}")
        
    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans la d√©cision finale: {str(e)}")
        state['final_decision'] = {
            "decision": "ERREUR",
            "ticker": None,
            "confiance": "AUCUNE",
            "justification_synthetique": f"Erreur syst√®me: {str(e)}",
            "allocation_capital_pourcentage": 0.0,
            "points_cles_positifs": [],
            "points_cles_negatifs_risques": ["Erreur syst√®me"]
        }
    
    return state

# --- CONSTRUCTION DU GRAPHE LANGGRAPH ---

def create_workflow() -> StateGraph:
    """Cr√©e et configure le graphe d'orchestration avec le nouveau Ticker Hunter."""
    
    workflow = StateGraph(GraphState)
    
    # Ajout des n≈ìuds (dans l'ordre d'ex√©cution)
    workflow.add_node("initial_analysis", node_initial_analysis)
    workflow.add_node("find_actionable_tickers", node_find_actionable_tickers)  # NOUVEAU
    workflow.add_node("route_to_agents", node_route_to_agents)
    workflow.add_node("run_agent_analyses", node_run_agent_analyses)
    workflow.add_node("final_investor_decision", node_final_investor_decision)
    
    # D√©finition des transitions (nouveau flux avec Ticker Hunter)
    workflow.set_entry_point("initial_analysis")
    workflow.add_edge("initial_analysis", "find_actionable_tickers")  # 1 ‚Üí 2
    workflow.add_edge("find_actionable_tickers", "route_to_agents")   # 2 ‚Üí 3
    workflow.add_edge("route_to_agents", "run_agent_analyses")        # 3 ‚Üí 4
    workflow.add_edge("run_agent_analyses", "final_investor_decision") # 4 ‚Üí 5
    workflow.add_edge("final_investor_decision", END)                 # 5 ‚Üí FIN
    
    return workflow

# --- FONCTION PRINCIPALE D'ORCHESTRATION ---

def run_berzerk_pipeline(news_link: str, capital_disponible: float = 30000.0) -> Dict[str, Any]:
    """
    Ex√©cute le pipeline complet d'analyse BERZERK.
    
    Args:
        news_link: URL de l'article √† analyser
        capital_disponible: Capital disponible pour l'investissement
    
    Returns:
        √âtat final avec la d√©cision d'investissement
    """
    
    print("\n" + "="*80)
    print("üöÄ D√âMARRAGE DU PIPELINE AUTOMATIS√â BERZERK")
    print("="*80)
    
    # √âtat initial
    initial_state = GraphState(
        news_link=news_link,
        news_summary="",
        full_article_text="",
        initial_analysis={},
        actionable_tickers=[],  # NOUVEAU : Pour stocker les tickers identifi√©s
        agent_team=[],
        agent_debriefing="",
        final_decision={},
        capital_disponible=capital_disponible,
        execution_log=[],
        timestamp=datetime.now().isoformat()
    )
    
    # Cr√©ation et compilation du graphe
    workflow = create_workflow()
    app = workflow.compile()
    
    # Ex√©cution du pipeline
    try:
        final_state = app.invoke(initial_state)
        
        print("\n" + "="*80)
        print("üéØ PIPELINE TERMIN√â - R√âSULTATS FINAUX")
        print("="*80)
        
        return final_state
        
    except Exception as e:
        print(f"\n‚ùå ERREUR CRITIQUE DANS LE PIPELINE: {str(e)}")
        return {
            "error": str(e),
            "execution_log": initial_state.get("execution_log", []),
            "final_decision": {
                "decision": "ERREUR_CRITIQUE",
                "justification_synthetique": f"Pipeline interrompu: {str(e)}"
            }
        }

# --- FONCTION D'AFFICHAGE DES R√âSULTATS ---

def display_final_results(final_state: Dict[str, Any]) -> None:
    """Affiche les r√©sultats finaux de mani√®re format√©e."""
    
    # Affichage des tickers identifi√©s
    actionable_tickers = final_state.get('actionable_tickers', [])
    if actionable_tickers:
        print(f"\nüéØ TICKERS IDENTIFI√âS PAR LE TICKER HUNTER:")
        for ticker_info in actionable_tickers:
            # Gestion des objets Pydantic ET des dictionnaires
            if hasattr(ticker_info, 'ticker'):
                ticker = ticker_info.ticker
                company = ticker_info.nom_entreprise
                justification = ticker_info.justification_impact
            else:
                ticker = ticker_info.get('ticker', 'N/A')
                company = ticker_info.get('nom_entreprise', 'N/A')
                justification = ticker_info.get('justification_impact', 'N/A')
            print(f"   üè¢ {ticker} ({company})")
            print(f"      üìù {justification}")
    else:
        print(f"\n‚ö†Ô∏è AUCUN TICKER ACTIONNABLE IDENTIFI√â")
    
    decision = final_state.get('final_decision', {})
    
    print(f"\nüìä D√âCISION FINALE BERZERK:")
    print(f"   üéØ Action: {decision.get('decision', 'N/A')}")
    print(f"   üìà Ticker: {decision.get('ticker', 'N/A')}")
    print(f"   üîí Confiance: {decision.get('confiance', 'N/A')}")
    print(f"   üí∞ Allocation: {decision.get('allocation_capital_pourcentage', 0)}%")
    print(f"   üìù Justification: {decision.get('justification_synthetique', 'N/A')}")
    
    positifs = decision.get('points_cles_positifs', [])
    if positifs:
        print(f"\n‚úÖ Points Positifs:")
        for point in positifs:
            print(f"   ‚Ä¢ {point}")
    
    risques = decision.get('points_cles_negatifs_risques', [])
    if risques:
        print(f"\n‚ö†Ô∏è Risques Identifi√©s:")
        for risque in risques:
            print(f"   ‚Ä¢ {risque}")
    
    print(f"\nüìã Logs d'ex√©cution:")
    for log in final_state.get('execution_log', []):
        print(f"   {log}")

# --- TESTS ET EX√âCUTION PRINCIPALE ---

def test_pipeline():
    """Fonction de test avec des exemples d'articles."""
    
    test_urls = [
        "https://finance.yahoo.com/news/apple-stock-rises-ai-optimism-180000123.html",
        "https://www.reuters.com/technology/artificial-intelligence/",
        "https://finance.yahoo.com/rss/"  # Fallback sur le flux RSS
    ]
    
    print("üß™ MODE TEST - S√©lection automatique d'un article r√©cent")
    
    # Pour le test, on peut utiliser un URL simple ou une simulation
    test_url = "https://finance.yahoo.com/news/"  # URL g√©n√©rique pour test
    
    return run_berzerk_pipeline(
        news_link=test_url,
        capital_disponible=25000.0
    )

if __name__ == "__main__":
    """Point d'entr√©e principal."""
    
    # V√©rification des arguments de ligne de commande
    if len(sys.argv) > 1:
        news_url = sys.argv[1]
        capital = float(sys.argv[2]) if len(sys.argv) > 2 else 30000.0
        
        print(f"üì∞ Analyse de: {news_url}")
        print(f"üí∞ Capital disponible: {capital}‚Ç¨")
        
        final_state = run_berzerk_pipeline(news_url, capital)
        display_final_results(final_state)
        
    else:
        print("üß™ MODE DEMO - Ex√©cution du pipeline de test")
        final_state = test_pipeline()
        display_final_results(final_state)
        
        print("\nüí° Usage: python orchestrator.py <URL_NEWS> [CAPITAL]")
        print("   Exemple: python orchestrator.py 'https://finance.yahoo.com/news/apple-ai-news' 25000")
</file>

<file path="real_time_rss_monitor.py">
#!/usr/bin/env python3
"""
üöÄ BERZERK Real-Time RSS Monitor - Surveillance RSS Quasi-Instantan√©e
=====================================================================

Ce syst√®me avanc√© surveille les flux RSS en temps quasi-r√©el avec :
- Polling haute fr√©quence (30-60 secondes)
- Optimisations HTTP (ETags, Last-Modified, conditional requests)
- Threading asynchrone pour √©viter les blocages
- D√©tection intelligente des changements
- Analyse automatique instantan√©e

Architecture Temps R√©el :
- Pas d'attente bloquante (utilise threading)
- R√©activit√© √©v√©nementielle
- Gestion des erreurs robuste
- Int√©gration avec le pipeline BERZERK existant

Usage: python real_time_rss_monitor.py [poll_interval_seconds]
Arr√™t: Ctrl+C
"""

import asyncio
import threading
import time
import requests
import feedparser
import hashlib
import sqlite3
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set, Any
from dataclasses import dataclass
from email.utils import parsedate_to_datetime
import sys
import traceback

# Import des modules BERZERK
from berzerk_lab import RSS_FEEDS, init_db, get_article_text, analyze_news_with_llm
from orchestrator import run_berzerk_pipeline


@dataclass
class FeedState:
    """√âtat d'un flux RSS avec optimisations HTTP"""
    url: str
    last_modified: Optional[str] = None
    etag: Optional[str] = None
    last_check: Optional[datetime] = None
    last_content_hash: Optional[str] = None
    consecutive_errors: int = 0
    # articles_cache supprim√© - causait des doublons apr√®s red√©marrage
    
    def should_check(self, min_interval: int) -> bool:
        """D√©termine si le flux doit √™tre v√©rifi√© maintenant"""
        if self.last_check is None:
            return True
        
        # Algorithme adaptatif : plus d'erreurs = moins de v√©rifications
        if self.consecutive_errors > 0:
            penalty = min(self.consecutive_errors * 30, 300)  # Max 5 minutes de penalty
            return (datetime.now() - self.last_check).total_seconds() > (min_interval + penalty)
        
        return (datetime.now() - self.last_check).total_seconds() >= min_interval


class RealTimeRSSMonitor:
    """Surveillant RSS temps r√©el avec optimisations avanc√©es"""
    
    def __init__(self, poll_interval: int = 30, capital: float = 25000.0):
        self.poll_interval = poll_interval  # En secondes
        self.capital = capital
        self.feeds_state: Dict[str, FeedState] = {}
        self.running = False
        self.processed_articles: Set[str] = set()
        self.stats = {
            'total_checks': 0,
            'new_articles_found': 0,
            'analyses_completed': 0,
            'errors': 0,
            'start_time': datetime.now()
        }
        
        # Configuration des requ√™tes HTTP optimis√©es
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'BERZERK-RSS-Monitor/1.0 (Real-Time News Analysis)',
            'Accept': 'application/rss+xml, application/xml, text/xml',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        })
        
        # Initialisation
        self.init_feeds_state()
        self.load_processed_articles()
        
        print(f"üöÄ BERZERK Real-Time RSS Monitor initialis√©")
        print(f"   ‚ö° Polling: {poll_interval} secondes (haute fr√©quence)")
        print(f"   üìà Flux RSS: {len(RSS_FEEDS)} source (Bloomberg uniquement)")
        for feed_name, feed_url in RSS_FEEDS.items():
            print(f"   üì° {feed_name}: {feed_url}")
        print(f"   üí∞ Capital: {capital:,.2f}‚Ç¨")
        print(f"   üîÑ Optimisations: ETags, Last-Modified, Threading")
        print(f"   üìä Articles d√©j√† trait√©s: {len(self.processed_articles)}")
        print("-" * 70)
    
    def init_feeds_state(self):
        """Initialise l'√©tat de chaque flux RSS"""
        for feed_name, feed_url in RSS_FEEDS.items():
            self.feeds_state[feed_url] = FeedState(url=feed_url)
    
    def load_processed_articles(self):
        """Charge les articles d√©j√† trait√©s depuis la base de donn√©es"""
        try:
            conn = sqlite3.connect('berzerk.db')
            cursor = conn.cursor()
            # Charger TOUS les articles existants (peu importe le statut)
            cursor.execute("SELECT link FROM articles")
            self.processed_articles = {row[0] for row in cursor.fetchall()}
            conn.close()
            
            self.log(f"üì• {len(self.processed_articles)} articles existants charg√©s")
            self.log("üéØ Seuls les vrais nouveaux articles RSS seront trait√©s")
        except Exception as e:
            self.log(f"‚ö†Ô∏è Erreur lors du chargement des articles trait√©s: {e}")
            self.processed_articles = set()
    
    def log(self, message: str, level: str = "INFO"):
        """Logger avec timestamp et niveau"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        level_emoji = {
            "INFO": "‚ÑπÔ∏è",
            "SUCCESS": "‚úÖ",
            "WARNING": "‚ö†Ô∏è",
            "ERROR": "‚ùå",
            "DETECTION": "üîç"
        }.get(level, "üìù")
        print(f"‚ö° [{timestamp}] {level_emoji} {message}")
    
    def calculate_content_hash(self, content: str) -> str:
        """Calcule un hash du contenu pour d√©tecter les changements"""
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def check_feed_optimized(self, feed_state: FeedState) -> List[Dict]:
        """V√©rifie un flux RSS avec optimisations HTTP"""
        try:
            headers = {}
            
            # Optimisations HTTP conditionnelles
            if feed_state.etag:
                headers['If-None-Match'] = feed_state.etag
            if feed_state.last_modified:
                headers['If-Modified-Since'] = feed_state.last_modified
            
            # Requ√™te HTTP avec timeout court
            response = self.session.get(
                feed_state.url, 
                headers=headers, 
                timeout=10
            )
            
            feed_state.last_check = datetime.now()
            self.stats['total_checks'] += 1
            
            # Gestion des codes de statut HTTP
            if response.status_code == 304:
                # Not Modified - aucun changement
                self.log(f"üîÑ Pas de changement: {feed_state.url[:50]}...")
                feed_state.consecutive_errors = 0
                return []
            
            if response.status_code != 200:
                raise Exception(f"HTTP {response.status_code}")
            
            # Mise √† jour des m√©tadonn√©es de cache
            feed_state.etag = response.headers.get('ETag')
            feed_state.last_modified = response.headers.get('Last-Modified')
            
            # V√©rification du hash du contenu
            content_hash = self.calculate_content_hash(response.text)
            if feed_state.last_content_hash == content_hash:
                self.log(f"üîÑ Contenu identique: {feed_state.url[:50]}...")
                feed_state.consecutive_errors = 0
                return []
            
            feed_state.last_content_hash = content_hash
            
            # Parsing RSS
            feed = feedparser.parse(response.text)
            
            if feed.bozo:
                self.log(f"‚ö†Ô∏è Feed mal form√©: {feed_state.url[:50]}...")
            
            # Filtrage des nouveaux articles - LOGIQUE SIMPLIFI√âE
            new_articles = []
            for entry in feed.entries:
                article_link = entry.get('link', '')
                
                # ‚úÖ CORRECTION : Ne v√©rifier que processed_articles (pas articles_cache)
                if article_link and article_link not in self.processed_articles:
                    
                    # Marquer imm√©diatement comme trait√© pour √©viter les doublons
                    self.processed_articles.add(article_link)
                    
                    # Extraction des m√©tadonn√©es
                    published_date = None
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        published_date = datetime(*entry.published_parsed[:6])
                    elif hasattr(entry, 'published'):
                        try:
                            published_date = parsedate_to_datetime(entry.published)
                        except:
                            published_date = datetime.now()
                    else:
                        published_date = datetime.now()
                    
                    article = {
                        'title': entry.get('title', 'Titre non disponible'),
                        'link': article_link,
                        'published_date': published_date,
                        'summary': entry.get('summary', ''),
                        'source': feed_state.url,
                        'discovered_at': datetime.now()
                    }
                    
                    new_articles.append(article)
            
            # Succ√®s - reset des erreurs
            feed_state.consecutive_errors = 0
            
            if new_articles:
                self.log(f"üéØ {len(new_articles)} VRAIS nouveaux articles d√©tect√©s sur {feed_state.url[:50]}...", "DETECTION")
                self.stats['new_articles_found'] += len(new_articles)
            
            return new_articles
            
        except Exception as e:
            feed_state.consecutive_errors += 1
            self.stats['errors'] += 1
            self.log(f"‚ùå Erreur sur {feed_state.url[:50]}: {e}")
            return []
    
    def store_article(self, article: Dict):
        """Stocke un article dans la base de donn√©es"""
        try:
            conn = sqlite3.connect('berzerk.db')
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR IGNORE INTO articles 
                (title, link, published_date, source, status, published_str)
                VALUES (?, ?, ?, ?, 'pending', ?)
            """, (
                article['title'],
                article['link'],
                article['published_date'].isoformat(),
                article['source'],
                article.get('summary', 'RSS Feed')  # Utilise summary comme published_str
            ))
            
            conn.commit()
            conn.close()
            
            if cursor.rowcount > 0:
                self.log(f"üíæ Article stock√©: {article['title'][:50]}...")
            
        except Exception as e:
            self.log(f"‚ùå Erreur stockage: {e}")
    
    def analyze_article_realtime(self, article: Dict) -> Optional[Dict]:
        """Analyse un article en temps r√©el avec le pipeline BERZERK"""
        try:
            self.log(f"ü§ñ Analyse TEMPS R√âEL: {article['title'][:50]}...")
            
            # Lancement du pipeline complet
            result = run_berzerk_pipeline(article['link'], self.capital)
            
            if result and 'final_decision' in result:
                # Sauvegarde de la d√©cision
                self.save_decision_to_db(article['link'], result['final_decision'])
                
                # Marquer comme trait√©
                self.processed_articles.add(article['link'])
                
                # Statistiques
                self.stats['analyses_completed'] += 1
                
                # Affichage du r√©sultat
                decision = result['final_decision']
                action = decision.get('decision', 'INCONNU')
                
                if action == 'ACHETER':
                    self.log(f"üöÄ ACHAT IDENTIFI√â: {article['title'][:50]}...", "SUCCESS")
                    ticker = decision.get('ticker_cible', 'N/A')
                    allocation = decision.get('allocation_pourcentage', 0)
                    self.log(f"   üí∞ Ticker: {ticker}, Allocation: {allocation}%")
                elif action == 'SURVEILLER':
                    self.log(f"üëÄ SURVEILLANCE: {article['title'][:50]}...")
                else:
                    self.log(f"‚úÖ Analyse termin√©e: {action}")
                
                return result
            else:
                self.log(f"‚ö†Ô∏è √âchec d'analyse: {article['title'][:50]}...")
                return None
                
        except Exception as e:
            self.log(f"‚ùå Erreur analyse temps r√©el: {e}")
            return None
    
    def save_decision_to_db(self, article_link: str, decision: Dict):
        """Sauvegarde la d√©cision dans la base de donn√©es"""
        try:
            conn = sqlite3.connect('berzerk.db')
            cursor = conn.cursor()
            
            cursor.execute("""
                UPDATE articles 
                SET decision_json = ?, 
                    status = 'analyzed', 
                    analyzed_at = ?
                WHERE link = ?
            """, (
                json.dumps(decision, ensure_ascii=False),
                datetime.now().isoformat(),
                article_link
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.log(f"‚ùå Erreur sauvegarde d√©cision: {e}")
    
    def monitoring_thread(self):
        """Thread principal de surveillance"""
        self.log("üîÑ Thread de surveillance d√©marr√©")
        
        while self.running:
            try:
                # V√©rifier chaque flux RSS
                for feed_url, feed_state in self.feeds_state.items():
                    if not self.running:
                        break
                    
                    # V√©rifier si le flux doit √™tre contr√¥l√©
                    if feed_state.should_check(self.poll_interval):
                        new_articles = self.check_feed_optimized(feed_state)
                        
                        # Traiter les nouveaux articles
                        for article in new_articles:
                            if not self.running:
                                break
                            
                            # Stockage en base
                            self.store_article(article)
                            
                            # Analyse imm√©diate en arri√®re-plan
                            threading.Thread(
                                target=self.analyze_article_realtime,
                                args=(article,),
                                daemon=True
                            ).start()
                
                # Pause courte avant le prochain cycle
                time.sleep(1)
                
            except Exception as e:
                self.log(f"‚ùå Erreur dans le thread de surveillance: {e}")
                time.sleep(5)  # Pause plus longue en cas d'erreur
        
        self.log("üõë Thread de surveillance arr√™t√©")
    
    def display_stats(self):
        """Affiche les statistiques en temps r√©el"""
        uptime = datetime.now() - self.stats['start_time']
        
        print("\n" + "="*50)
        print("üìä STATISTIQUES TEMPS R√âEL")
        print("="*50)
        print(f"‚è±Ô∏è  Uptime: {uptime}")
        print(f"üîÑ V√©rifications totales: {self.stats['total_checks']}")
        print(f"üìà Nouveaux articles: {self.stats['new_articles_found']}")
        print(f"ü§ñ Analyses compl√®tes: {self.stats['analyses_completed']}")
        print(f"‚ùå Erreurs: {self.stats['errors']}")
        print(f"üíæ Articles en cache: {len(self.processed_articles)}")
        print("="*50)
    
    def start(self):
        """D√©marre la surveillance temps r√©el"""
        self.log("üöÄ D√âMARRAGE DE LA SURVEILLANCE TEMPS R√âEL", "SUCCESS")
        self.log(f"‚ö° Polling: {self.poll_interval} secondes")
        self.log("‚èπÔ∏è  Arr√™t: Ctrl+C")
        
        # Initialiser la base de donn√©es
        init_db()
        
        # D√©marrer le thread de surveillance
        self.running = True
        monitor_thread = threading.Thread(target=self.monitoring_thread, daemon=True)
        monitor_thread.start()
        
        try:
            # Boucle principale avec affichage des stats
            while True:
                time.sleep(30)  # Afficher les stats toutes les 30 secondes
                self.display_stats()
                
        except KeyboardInterrupt:
            self.log("üõë Arr√™t demand√© par l'utilisateur", "WARNING")
        finally:
            self.running = False
            self.log("üëã Surveillance temps r√©el arr√™t√©e", "SUCCESS")
            self.display_stats()


def main():
    """Point d'entr√©e principal"""
    # Configuration par d√©faut
    poll_interval = 30  # 30 secondes par d√©faut
    capital = 25000.0
    
    # Parsing des arguments
    if len(sys.argv) > 1:
        try:
            poll_interval = int(sys.argv[1])
            if poll_interval < 10:
                raise ValueError("L'intervalle doit √™tre d'au moins 10 secondes")
        except ValueError as e:
            print(f"‚ùå Erreur: {e}")
            print("üí° Usage: python real_time_rss_monitor.py [poll_interval_seconds]")
            print("üìä Exemple: python real_time_rss_monitor.py 30")
            sys.exit(1)
    
    print(f"üöÄ BERZERK Real-Time RSS Monitor")
    print(f"‚ö° Surveillance quasi-instantan√©e avec polling optimis√©")
    print(f"üîÑ Intervalle: {poll_interval} secondes")
    print("-" * 70)
    
    # Lancement du monitor
    monitor = RealTimeRSSMonitor(poll_interval, capital)
    monitor.start()


if __name__ == "__main__":
    main()
</file>

<file path="requirements.txt">
# Core dependencies
streamlit>=1.30.0
langchain>=0.1.0
langchain-google-genai>=0.0.6
langchain-core>=0.1.0
google-generativeai>=0.3.0
python-dotenv>=1.0.0

# Web scraping and RSS
requests>=2.31.0
beautifulsoup4>=4.12.0
feedparser>=6.0.0

# Finance and data
yfinance>=0.2.0
pandas>=2.0.0

# Search and tools
tavily-python>=0.3.0

# Additional tools
langgraph>=0.0.30
langsmith>=0.0.40

# Utility
pydantic>=2.0.0
typing-extensions>=4.8.0
</file>

<file path="reset_and_analyze.py">
#!/usr/bin/env python3
"""
üßπ BERZERK RESET & ANALYZE - Nettoyage et Relance des Analyses
==============================================================

Ce script nettoie les anciennes analyses et relance les 20 derni√®res
news avec les nouveaux agents augment√©s (Phase 5).
"""

import sqlite3
import sys
import json
from datetime import datetime
from orchestrator import run_berzerk_pipeline

def reset_analyses():
    """
    Nettoie les anciennes analyses de la base de donn√©es
    """
    print("üßπ Nettoyage des anciennes analyses...")
    
    conn = sqlite3.connect('berzerk.db')
    cursor = conn.cursor()
    
    # Remettre √† z√©ro les analyses
    cursor.execute('''
        UPDATE articles 
        SET decision_json = NULL, 
            status = "pending", 
            analyzed_at = NULL 
        WHERE decision_json IS NOT NULL
    ''')
    
    updated = cursor.rowcount
    conn.commit()
    
    # Compter les articles en attente
    cursor.execute('SELECT COUNT(*) FROM articles WHERE status = "pending"')
    pending = cursor.fetchone()[0]
    
    conn.close()
    
    print(f"‚úÖ {updated} anciennes analyses supprim√©es")
    print(f"üìù {pending} articles en attente d'analyse")
    
    return pending

def get_latest_articles(limit=20):
    """
    R√©cup√®re les derniers articles en attente
    """
    print(f"üîç R√©cup√©ration des {limit} derniers articles...")
    
    conn = sqlite3.connect('berzerk.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT id, title, link, published_date 
        FROM articles 
        WHERE status = "pending" 
        ORDER BY published_date DESC 
        LIMIT ?
    ''', (limit,))
    
    articles = cursor.fetchall()
    conn.close()
    
    print(f"‚úÖ {len(articles)} articles r√©cup√©r√©s")
    return articles

def save_decision_to_db(article_id: int, decision_result: dict) -> bool:
    """
    Sauvegarde une d√©cision d'investissement dans la base de donn√©es
    """
    try:
        conn = sqlite3.connect('berzerk.db')
        cursor = conn.cursor()
        
        # Extraire les informations cl√©s de la d√©cision
        final_decision = decision_result.get('final_decision', {})
        
        # Gestion des objets Pydantic pour final_decision
        if hasattr(final_decision, 'decision'):
            # Objet Pydantic
            decision_action = final_decision.decision
            decision_ticker = final_decision.ticker
            decision_confiance = final_decision.confiance
            decision_justification = final_decision.justification_synthetique
            decision_allocation = final_decision.allocation_capital_pourcentage
            decision_positifs = final_decision.points_cles_positifs
            decision_negatifs = final_decision.points_cles_negatifs_risques
        else:
            # Dictionnaire classique
            decision_action = final_decision.get('decision', 'ERREUR')
            decision_ticker = final_decision.get('ticker', None)
            decision_confiance = final_decision.get('confiance', 'INCONNUE')
            decision_justification = final_decision.get('justification_synthetique', 'Aucune justification')
            decision_allocation = final_decision.get('allocation_capital_pourcentage', 0.0)
            decision_positifs = final_decision.get('points_cles_positifs', [])
            decision_negatifs = final_decision.get('points_cles_negatifs_risques', [])
        
        # Pr√©parer la d√©cision format√©e pour la base de donn√©es
        decision_data = {
            'action': decision_action,
            'ticker': decision_ticker,
            'confiance': decision_confiance,
            'justification': decision_justification,
            'allocation_pourcentage': decision_allocation,
            'points_positifs': decision_positifs,
            'points_negatifs': decision_negatifs,
            'tickers_identifies': decision_result.get('actionable_tickers', []),
            'timestamp': datetime.now().isoformat()
        }
        
        # Sauvegarder dans la base de donn√©es
        cursor.execute('''
            UPDATE articles 
            SET decision_json = ?, 
                status = "analyzed", 
                analyzed_at = ? 
            WHERE id = ?
        ''', (json.dumps(decision_data), datetime.now().isoformat(), article_id))
        
        conn.commit()
        conn.close()
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde: {e}")
        return False

def analyze_articles(articles):
    """
    Lance l'analyse des articles avec les nouveaux agents augment√©s
    """
    print(f"üöÄ Lancement des analyses avec les agents augment√©s...")
    print("-" * 60)
    
    successful_analyses = 0
    failed_analyses = 0
    saved_decisions = 0
    
    for i, (article_id, title, link, published_date) in enumerate(articles, 1):
        print(f"\nüî¨ [{i}/{len(articles)}] Analyse: {title[:50]}...")
        
        try:
            # Simuler un capital de test
            capital = 10000
            
            # Lancer le pipeline BERZERK complet
            result = run_berzerk_pipeline(link, capital)
            
            if result and not result.get('error'):
                successful_analyses += 1
                print(f"‚úÖ Analyse termin√©e avec succ√®s")
                
                # Sauvegarder la d√©cision dans la base de donn√©es
                if save_decision_to_db(article_id, result):
                    saved_decisions += 1
                    print(f"üíæ D√©cision sauvegard√©e dans la base de donn√©es")
                    
                    # Afficher la d√©cision si disponible
                    if result.get('final_decision'):
                        decision = result['final_decision']
                        action = decision.get('decision', 'N/A')
                        ticker = decision.get('ticker', 'N/A')
                        allocation = decision.get('allocation_capital_pourcentage', 0)
                        print(f"üéØ D√©cision: {action} {ticker} ({allocation}%)")
                else:
                    print("‚ùå √âchec de la sauvegarde")
            else:
                failed_analyses += 1
                print(f"‚ùå √âchec de l'analyse: {result.get('error', 'Erreur inconnue')}")
                
        except Exception as e:
            failed_analyses += 1
            print(f"‚ùå Erreur lors de l'analyse: {e}")
    
    print(f"\nüìä R√âSULTATS DES ANALYSES")
    print("-" * 30)
    print(f"‚úÖ Analyses r√©ussies: {successful_analyses}")
    print(f"üíæ D√©cisions sauvegard√©es: {saved_decisions}")
    print(f"‚ùå Analyses √©chou√©es: {failed_analyses}")
    print(f"üìà Taux de r√©ussite: {(successful_analyses / len(articles)) * 100:.1f}%")
    
    return successful_analyses

def main():
    """
    Fonction principale
    """
    print("üéØ BERZERK RESET & ANALYZE")
    print("=" * 50)
    
    # √âtape 1: Nettoyer les anciennes analyses
    pending_count = reset_analyses()
    
    if pending_count == 0:
        print("‚ö†Ô∏è  Aucun article en attente d'analyse")
        return
    
    # √âtape 2: R√©cup√©rer les derniers articles
    articles = get_latest_articles(20)
    
    if not articles:
        print("‚ùå Aucun article trouv√©")
        return
    
    # √âtape 3: Analyser les articles
    successful = analyze_articles(articles)
    
    print(f"\nüèÅ TERMIN√â !")
    print(f"üìä {successful} nouvelles analyses avec agents augment√©s")
    print(f"üí° Vous pouvez maintenant relancer: python backtester.py")

if __name__ == "__main__":
    main()
</file>

<file path="start_realtime_monitor.py">
#!/usr/bin/env python3
"""
üöÄ Script de Lancement BERZERK Real-Time Monitor
===============================================

Ce script simplifie le lancement du syst√®me de surveillance RSS temps r√©el.
Il peut √©galement lancer le dashboard en parall√®le pour une visualisation compl√®te.

Usage:
    python start_realtime_monitor.py                    # Surveillance seule
    python start_realtime_monitor.py --with-dashboard   # Surveillance + Dashboard
    python start_realtime_monitor.py --interval 30      # Intervalle personnalis√©
"""

import subprocess
import sys
import time
import threading
import os
from datetime import datetime

def log(message: str):
    """Logger avec timestamp"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"üöÄ [{timestamp}] {message}")

def launch_dashboard():
    """Lance le dashboard Streamlit en arri√®re-plan"""
    try:
        log("Lancement du dashboard Streamlit...")
        
        # Lancer le dashboard
        process = subprocess.Popen([
            sys.executable, "-m", "streamlit", "run", "berzerk_dashboard.py",
            "--server.headless", "true",
            "--server.port", "8501",
            "--browser.gatherUsageStats", "false"
        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        # Attendre quelques secondes pour voir si le lancement r√©ussit
        time.sleep(3)
        
        if process.poll() is None:
            log("‚úÖ Dashboard d√©marr√© sur http://localhost:8501")
            return process
        else:
            log("‚ùå √âchec du d√©marrage du dashboard")
            return None
    
    except Exception as e:
        log(f"‚ùå Erreur lors du lancement du dashboard: {e}")
        return None

def launch_realtime_monitor(interval: int = 30):
    """Lance le monitor temps r√©el"""
    try:
        log(f"Lancement du monitor temps r√©el (intervalle: {interval}s)...")
        
        # Lancer le monitor
        process = subprocess.Popen([
            sys.executable, "real_time_rss_monitor.py", str(interval)
        ])
        
        return process
        
    except Exception as e:
        log(f"‚ùå Erreur lors du lancement du monitor: {e}")
        return None

def main():
    """Fonction principale"""
    
    # Configuration par d√©faut
    interval = 30
    with_dashboard = False
    
    # Parsing des arguments
    args = sys.argv[1:]
    
    i = 0
    while i < len(args):
        arg = args[i]
        
        if arg == "--with-dashboard":
            with_dashboard = True
        elif arg == "--interval":
            if i + 1 < len(args):
                try:
                    interval = int(args[i + 1])
                    i += 1  # Skip next argument
                except ValueError:
                    print("‚ùå Erreur: L'intervalle doit √™tre un nombre entier")
                    sys.exit(1)
            else:
                print("‚ùå Erreur: --interval n√©cessite une valeur")
                sys.exit(1)
        elif arg == "--help" or arg == "-h":
            print(__doc__)
            sys.exit(0)
        else:
            print(f"‚ùå Argument inconnu: {arg}")
            print("üí° Utilisez --help pour voir les options disponibles")
            sys.exit(1)
        
        i += 1
    
    # Affichage de la configuration
    print("\n" + "="*70)
    print("üöÄ BERZERK Real-Time Monitor - Lancement")
    print("="*70)
    print(f"‚ö° Intervalle de surveillance: {interval} secondes")
    print(f"üìä Dashboard inclus: {'Oui' if with_dashboard else 'Non'}")
    print("="*70)
    
    # V√©rification des pr√©requis
    if not os.path.exists("real_time_rss_monitor.py"):
        print("‚ùå Erreur: real_time_rss_monitor.py non trouv√©")
        sys.exit(1)
    
    if with_dashboard and not os.path.exists("berzerk_dashboard.py"):
        print("‚ùå Erreur: berzerk_dashboard.py non trouv√©")
        sys.exit(1)
    
    # Lancement des composants
    dashboard_process = None
    monitor_process = None
    
    try:
        # Lancer le dashboard si demand√©
        if with_dashboard:
            dashboard_process = launch_dashboard()
            if dashboard_process:
                time.sleep(2)  # Laisser le dashboard se stabiliser
        
        # Lancer le monitor temps r√©el
        monitor_process = launch_realtime_monitor(interval)
        
        if monitor_process:
            log("‚úÖ Monitor temps r√©el d√©marr√©")
            
            if with_dashboard:
                log("üåê Acc√©dez au dashboard: http://localhost:8501")
            
            log("‚èπÔ∏è  Appuyez sur Ctrl+C pour arr√™ter")
            
            # Attendre la fin du processus principal
            monitor_process.wait()
        else:
            log("‚ùå √âchec du d√©marrage du monitor")
            
    except KeyboardInterrupt:
        log("üõë Arr√™t demand√© par l'utilisateur")
    
    except Exception as e:
        log(f"‚ùå Erreur fatale: {e}")
    
    finally:
        # Nettoyage des processus
        if monitor_process and monitor_process.poll() is None:
            log("Arr√™t du monitor temps r√©el...")
            monitor_process.terminate()
            monitor_process.wait()
        
        if dashboard_process and dashboard_process.poll() is None:
            log("Arr√™t du dashboard...")
            dashboard_process.terminate()
            dashboard_process.wait()
        
        log("üëã Tous les processus arr√™t√©s")

if __name__ == "__main__":
    main()
</file>

<file path="suivi_projet.md">
# üìã Suivi du Projet BERZERK

## üìñ Description G√©n√©rale
**Objectif :** D√©velopper un syst√®me d'analyse automatis√©e d'actualit√©s financi√®res utilisant l'IA pour √©valuer l'impact des news sur les march√©s.

**Public cible :** Analystes financiers et investisseurs cherchant une aide √† la d√©cision rapide et fiable.

**Architecture :** Application Streamlit + LangChain + Gemini AI + Base de donn√©es SQLite

## üìã Plan de T√¢ches

### Phase 1 : Fondations 
- [x] Configuration LangChain + Gemini
- [x] Interface Streamlit basique
- [x] R√©cup√©ration flux RSS
- [x] Analyse LLM des articles
- [x] Int√©gration base de donn√©es SQLite

### Phase 2 : Agents IA Sp√©cialis√©s ‚úÖ
- [x] Cr√©ation module agents.py
- [x] Int√©gration agents dans interface principale
- [x] Agent Investisseur Final (Superviseur)
- [x] Pipeline automatis√© avec LangGraph

### Phase 2.3 : Automatisation Compl√®te ‚úÖ
- [x] Cr√©ation orchestrator.py avec LangGraph
- [x] Tests du pipeline automatis√©
- [x] Transformation du labo en moniteur temps r√©el

### Phase 3 : Architecture Service 24/7 ‚úÖ
- [x] Extension base de donn√©es avec colonnes de suivi
- [x] Service daemon berzerk_service.py
- [x] Surveillance automatique 24/7
- [x] Dashboard temps r√©el berzerk_dashboard.py
- [x] S√©paration backend/frontend

### Phase 4 : Am√©liorations Avanc√©es (√† venir)
- [ ] Filtrage avanc√© des articles
- [ ] Visualisations des tendances
- [ ] Export des r√©sultats
- [ ] API REST pour int√©grations externes

### Phase 5 : Surveillance RSS Temps R√©el ‚úÖ
- [x] Syst√®me de surveillance RSS quasi-instantan√© (30 secondes)
- [x] Optimisations HTTP (ETags, Last-Modified, codes 304)
- [x] Threading asynchrone pour analyses parall√®les
- [x] D√©tection intelligente via hash de contenu
- [x] Gestion d'erreurs adaptative
- [x] **CORRECTION CRITIQUE** : Logique de d√©tection des nouveaux articles simplifi√©e

### Phase 6 : Am√©liorations Avanc√©es (√† venir)
- [ ] Filtrage avanc√© des articles
- [ ] Visualisations des tendances
- [ ] Export des r√©sultats
- [ ] API REST pour int√©grations externes

## üìù Journal des Modifications

### 2024-01-XX - Impl√©mentation Base de Donn√©es ‚úÖ
**Objectif :** Ajouter une base de donn√©es SQLite pour √©viter les doublons et am√©liorer la gestion des articles.

**Modifications effectu√©es :**
1. ‚úÖ Ajout des imports `datetime` et `sqlite3`
2. ‚úÖ Cr√©ation fonction `init_db()` pour initialiser la base avec table `articles`
3. ‚úÖ Modification `fetch_news_from_feeds()` ‚Üí `fetch_and_store_news()` avec INSERT OR IGNORE
4. ‚úÖ Cr√©ation `get_articles_from_db()` pour r√©cup√©rer les articles tri√©s par date DESC
5. ‚úÖ Am√©lioration interface Streamlit avec dates de publication format√©es
6. ‚úÖ Ajout notification toast pour nouveaux articles trouv√©s
7. ‚úÖ Am√©lioration affichage avec `st.json()` pour les entit√©s

### 2024-01-XX - Cr√©ation Module Agents IA ‚úÖ
**Objectif :** D√©velopper une √©quipe d'agents IA sp√©cialis√©s pour l'analyse approfondie des news.

**Composants impl√©ment√©s :**
1. ‚úÖ **Initialisation LLM** avec temp√©rature 0.3 pour la personnalit√©
2. ‚úÖ **3 Profils d'Agents Sp√©cialis√©s :**
   - `analyste_actions` : Analyse d'actions individuelles avec recommandations
   - `analyste_sectoriel` : Analyse de secteurs et dynamiques concurrentielles
   - `strategiste_geopolitique` : Analyse g√©opolitique et macro√©conomique
3. ‚úÖ **Routeur Intelligent** (`route_to_agents()`) avec fallback automatique
4. ‚úÖ **Ex√©cuteur d'Agent** (`run_agent_analysis()`) avec gestion d'erreurs
5. ‚úÖ **Fonctions Utilitaires** et module de test int√©gr√©
6. ‚úÖ **Type Hints** complets et documentation d√©taill√©e

### 2024-01-XX - Int√©gration Agents dans Interface Principale ‚úÖ
**Objectif :** Int√©grer le syst√®me d'agents IA dans l'interface utilisateur de BERZERK Lab.

**Modifications effectu√©es :**
1. ‚úÖ **Import du module agents** dans `berzerk_lab.py`
2. ‚úÖ **Nouvelles variables de session_state** pour g√©rer l'√©tat des agents
3. ‚úÖ **R√©initialisation des agents** lors du changement d'article
4. ‚úÖ **Interface de recrutement** avec bouton "Recruter l'√âquipe d'Agents Sp√©cialis√©s"
5. ‚úÖ **Affichage de l'√©quipe** avec focus sp√©cifique de chaque agent
6. ‚úÖ **Interface d'ex√©cution** avec bouton "Lancer les Analyses de l'√âquipe"
7. ‚úÖ **Affichage des r√©sultats** avec expanders pour chaque analyse d'agent
8. ‚úÖ **Gestion d'erreurs** et indicateurs de progression optimis√©s
9. ‚úÖ **Interface multi-perspectives** compl√®tement fonctionnelle

### 2024-01-XX - Pipeline Automatis√© avec LangGraph ‚úÖ
**Objectif :** Cr√©er un syst√®me d'orchestration automatis√© pour la cha√Æne compl√®te d'analyse.

**Composants impl√©ment√©s :**
1. ‚úÖ **Agent Investisseur Final** ajout√© dans `agents.py`
   - Prend la d√©cision finale ACHETER/VENDRE/SURVEILLER/IGNORER
   - Calcule l'allocation de capital (% du portefeuille)
   - Format JSON structur√© avec justifications et risques
2. ‚úÖ **Pipeline LangGraph** dans `orchestrator.py`
   - Graphe d'√©tats avec 4 n≈ìuds : Analyse ‚Üí Routage ‚Üí Ex√©cution ‚Üí D√©cision
   - Gestion d'erreurs robuste √† chaque √©tape
   - Logs d'ex√©cution d√©taill√©s avec timestamps
3. ‚úÖ **Fonctions d'orchestration** compl√®tes
   - `run_berzerk_pipeline()` : Point d'entr√©e principal
   - `display_final_results()` : Affichage format√© des r√©sultats
   - Mode test int√©gr√© pour validation
4. ‚úÖ **Types et validation** avec Pydantic
   - `GraphState` : √âtat typ√© circulant dans le graphe
   - `InvestmentDecision` : Validation des d√©cisions finales

### 2024-01-XX - Architecture Service 24/7 ‚úÖ
**Objectif :** Cr√©er un syst√®me de surveillance automatique 24/7 avec s√©paration backend/frontend.

**Architecture finale :**
```
üîÑ berzerk_service.py  ‚Üê  Daemon 24/7
     ‚Üì (analyse automatique)
üóÑÔ∏è berzerk.db         ‚Üê  Base de donn√©es centralis√©e  
     ‚Üë (lecture seule)
üìä berzerk_dashboard.py ‚Üê  Dashboard Streamlit
```

**Composants impl√©ment√©s :**
1. ‚úÖ **Extension Base de Donn√©es**
   - Colonnes `status`, `decision_json`, `analyzed_at` ajout√©es
   - Gestion des migrations automatiques
   - Suivi complet du cycle de vie des articles
2. ‚úÖ **Service Daemon** (`berzerk_service.py`)
   - Surveillance continue des flux RSS (intervalle configurable)
   - D√©tection automatique des nouvelles news
   - Analyse automatique via les agents IA
   - Gestion d'erreurs robuste et logs d√©taill√©s
3. ‚úÖ **Dashboard Temps R√©el** (`berzerk_dashboard.py`)
   - Interface s√©par√©e pour visualisation
   - Statistiques globales et m√©triques
   - Filtres avanc√©s (statut, action, p√©riode)
   - Auto-refresh optionnel
   - Pagination et affichage optimis√©

## üêõ Suivi des Erreurs
*Aucune erreur critique identifi√©e pour le moment*

## ‚úÖ R√©sultats des Tests
*Tests √† effectuer apr√®s impl√©mentation de la base de donn√©es*

## üìö Documentation Consult√©e
- [LangChain Documentation](https://python.langchain.com/docs/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [SQLite Documentation](https://docs.python.org/3/library/sqlite3.html)
- [Feedparser Documentation](https://feedparser.readthedocs.io/)

## üèóÔ∏è Structure du Projet
```
Berzerk/
‚îú‚îÄ‚îÄ berzerk_lab.py          # Interface Streamlit originale (Phases 1-2)
‚îú‚îÄ‚îÄ berzerk_service.py      # Service daemon surveillance 24/7 (Phase 3)
‚îú‚îÄ‚îÄ berzerk_dashboard.py    # Dashboard temps r√©el (Phase 3)
‚îú‚îÄ‚îÄ agents.py               # Agents IA sp√©cialis√©s + Investisseur Final
‚îú‚îÄ‚îÄ orchestrator.py         # Pipeline automatis√© LangGraph (Phase 2.3)
‚îú‚îÄ‚îÄ test_feeds.py           # Tests des flux RSS
‚îú‚îÄ‚îÄ suivi_projet.md         # Documentation du projet
‚îú‚îÄ‚îÄ berzerk.db              # Base de donn√©es SQLite (cr√©√© automatiquement)
‚îú‚îÄ‚îÄ venv/                   # Environnement virtuel
‚îî‚îÄ‚îÄ .env                    # Variables d'environnement
```

### üìã Modes d'Utilisation
1. **Mode Interactif** : `streamlit run berzerk_lab.py` (Phases 1-2)
2. **Mode Service** : `python berzerk_service.py [interval]` (Phase 3)
3. **Mode Dashboard** : `streamlit run berzerk_dashboard.py` (Phase 3)
4. **Mode Pipeline** : `python orchestrator.py <URL> <CAPITAL>` (Phase 2.3)

## ü§î R√©flexions & D√©cisions

### D√©cision Architecture Base de Donn√©es
**Probl√®me :** Articles dupliqu√©s et pas de tri chronologique
**Solution choisie :** SQLite avec contrainte UNIQUE sur les liens
**Justification :** Simple, l√©ger, int√©gr√© Python, parfait pour ce volume de donn√©es

### Contraintes Techniques
- **Gemini API :** Limitation de tokens par requ√™te
- **RSS Feeds :** Certains flux peuvent √™tre instables
- **Parsing HTML :** Variabilit√© des structures selon les sources

## üìä M√©triques de Succ√®s

### Phase 1-2 : Analyse Interactive ‚úÖ
- [x] Z√©ro doublon d'article (contrainte UNIQUE sur les liens)
- [x] Tri chronologique fonctionnel (ORDER BY published_date DESC)
- [x] Persistence des donn√©es entre sessions (SQLite + init_db())
- [x] Temps de r√©ponse < 5 secondes pour l'analyse (LangChain optimis√©)

### Phase 3 : Architecture Service 24/7 ‚úÖ
- [x] Surveillance automatique continue (daemon stable)
- [x] D√©tection temps r√©el des nouvelles news
- [x] Analyse automatique sans intervention humaine
- [x] S√©paration backend/frontend fonctionnelle
- [x] Dashboard temps r√©el avec filtres avanc√©s
- [x] Gestion d'erreurs robuste et logs d√©taill√©s

### Phase 4 : Agent "Ticker Hunter" ‚úÖ
- [x] Transformation r√©volutionnaire du pipeline vers le trading cibl√©
- [x] Identification automatique de 1-5 tickers actionnables par news
- [x] Routage intelligent bas√© sur les tickers identifi√©s
- [x] Service daemon optimis√© avec prise de d√©cision orient√©e tickers
- [x] Passage de "SURVEILLER" syst√©matique √† d√©cisions d'achat cibl√©es

### Phase 5 : Surveillance RSS Temps R√©el ‚úÖ
- [x] Syst√®me de surveillance RSS quasi-instantan√© (30 secondes)
- [x] Optimisations HTTP (ETags, Last-Modified, codes 304)
- [x] Threading asynchrone pour analyses parall√®les
- [x] D√©tection intelligente via hash de contenu
- [x] Gestion d'erreurs adaptative
- [x] **CORRECTION CRITIQUE** : Logique de d√©tection des nouveaux articles simplifi√©e

## üéØ Phase 4 : Agent "Ticker Hunter" - R√©volution Strat√©gique

### Objectif R√©volutionnaire üöÄ
Transformer BERZERK d'un analyseur de news g√©n√©raliste en **machine de trading cibl√©e** via l'identification automatique de tickers actionnables.

### Nouveau Pipeline R√©volutionnaire ‚úÖ
```
Analyse Initiale ‚Üí **[TICKER HUNTER]** ‚Üí Routage des Agents ‚Üí Analyses Sp√©cialis√©es ‚Üí D√©cision Finale
```

### Impl√©mentation Compl√®te ‚úÖ

#### 1. Agent "Ticker Hunter" Ultra-Sp√©cialis√© ‚úÖ
- **Profil expert** : Focus exclusif sur les entreprises cot√©es
- **Prompt directif** : Identification 1-5 tickers maximum par news
- **Validation Pydantic** : Structure JSON stricte avec justifications
- **R√®gles critiques** : Seules les entreprises publiques avec impact direct

#### 2. Orchestrateur LangGraph Enrichi ‚úÖ
- **Nouveau n≈ìud** : `node_find_actionable_tickers()` (√âtape 2)
- **√âtat √©tendu** : `actionable_tickers` dans `GraphState`
- **Flux optimis√©** : 1 (Analyse) ‚Üí 2 (Ticker Hunter) ‚Üí 3 (Routage) ‚Üí 4 (Agents) ‚Üí 5 (D√©cision)
- **Gestion d'erreurs** : Logs d√©taill√©s et fallback automatique

#### 3. Routage Intelligent R√©volutionnaire ‚úÖ
- **Mode PR√âCIS** : 1 analyste actions par ticker identifi√©
- **Mode FALLBACK** : Analyse macro si aucun ticker trouv√©
- **Optimisation sectoriels** : Ajout analyste sectoriel si multiples tickers
- **Limite intelligente** : Maximum 2 agents pour le service automatique

#### 4. Service Daemon 2.0 ‚úÖ
- **Priorisation tickers** : Focus sur le premier ticker identifi√©
- **Allocation cibl√©e** : Maximum 3% pour s√©curit√© (service automatique)
- **Justification enrichie** : Int√©gration ticker + signaux + impact
- **Prise de d√©cision** : Orient√©e trading d'actions sp√©cifiques

#### 5. Affichage R√©sultats Enrichi ‚úÖ
- **Section d√©di√©e** : Affichage des tickers identifi√©s
- **D√©tails complets** : Ticker, entreprise, justification d'impact
- **Logs am√©lior√©s** : Tra√ßabilit√© compl√®te du Ticker Hunter

### R√©volution Strat√©gique üéØ

#### Avant (Phase 3) vs Apr√®s (Phase 4)
| Aspect | Phase 3 | Phase 4 |
|--------|---------|---------|
| **Focus** | Analyse macro g√©n√©rale | Tickers sp√©cifiques |
| **D√©cisions** | 100% "SURVEILLER" | D√©cisions d'achat cibl√©es |
| **Pr√©cision** | Entit√©s vagues | 1-5 tickers maximum |
| **Agents** | Routage bas√© entit√©s | 1 agent par ticker |
| **Efficacit√©** | Analyses redondantes | Analyses hyper-cibl√©es |

#### B√©n√©fices R√©volutionnaires üìà
1. **Hyper-Focus** : Concentration sur actions sp√©cifiques au lieu d'analyses macro vagues
2. **Qualit√© d√©cisionnelle** : Analyses pr√©cises sur tickers identifi√©s
3. **R√©duction du bruit** : √âlimination des analyses g√©n√©rales improductives
4. **Alignement mission** : 100% orient√© trading d'actions
5. **Efficacit√© computationnelle** : Moins d'analyses, plus de qualit√©
6. **Performance attendue** : Passage de "intelligent" √† "redoutable"

### Impact Transformationnel üéØ
- **Fin du "SURVEILLER" syst√©matique** : D√©cisions d'achat/vente cibl√©es
- **Pr√©cision analytique** : Focus sur 1-2 actions maximum par news
- **Pipeline orient√© trading** : Chaque √©tape optimis√©e pour l'investissement
- **Machine de guerre financi√®re** : BERZERK devient un syst√®me d'investissement professionnel

**Cette am√©lioration repr√©sente la transformation la plus importante de BERZERK : d'un analyseur de news √† un syst√®me d'investissement automatis√© de niveau professionnel.**

## üåê Phase 5 : Agents Augment√©s avec Acc√®s Internet ‚úÖ

### Objectif R√©volutionnaire üöÄ
Connecter BERZERK au monde ext√©rieur en donnant aux agents l'acc√®s √† des **outils temps r√©el** pour des analyses ancr√©es dans la r√©alit√© du march√©.

### Probl√®me R√©solu üéØ
**Avant :** Agents "aveugles" travaillant uniquement avec :
- Connaissances pr√©-entra√Æn√©es (potentiellement obsol√®tes)  
- Contenu de l'article analys√©

**Apr√®s :** Agents "conscients du contexte" avec acc√®s √† :
- üîç **Recherche web temps r√©el** (Tavily AI)
- üìä **Donn√©es financi√®res actuelles** (yfinance)
- üí∞ **Prix et variations en direct**
- üìà **Sentiment du march√©** (capitalisation, P/E, volume)

### Impl√©mentation Compl√®te ‚úÖ

#### 1. Outils Externes Int√©gr√©s ‚úÖ
- **TavilySearchResults** : Recherche web intelligente avec 3 r√©sultats max
- **get_stock_price()** : Prix actuel et variation quotidienne  
- **get_market_sentiment()** : Capitalisation, P/E ratio, volume moyen
- **Gestion d'erreurs robuste** : Fallback automatique en cas d'√©chec

#### 2. Agent Augment√© Ultra-Intelligent ‚úÖ
- **create_augmented_analyst()** : Agent avec outils disponibles
- **Prompt syst√®me optimis√©** : Instructions pour usage strat√©gique des outils
- **AgentExecutor configur√©** : Max 5 it√©rations, arr√™t anticip√© intelligent
- **Mode verbose** : Visibilit√© compl√®te du processus de r√©flexion

#### 3. Processus d'Analyse R√©volutionnaire ‚úÖ
```
1. Analyse de la news fournie
2. V√©rification prix actuel et variation (get_stock_price)
3. Recherche informations compl√©mentaires (web_search)
4. Analyse sentiment march√© (get_market_sentiment)
5. Synth√®se avec contexte temps r√©el
```

#### 4. Int√©gration Pipeline Principal ‚úÖ
- **Orchestrateur enrichi** : D√©tection automatique des analyses de tickers
- **Mode hybride** : Agents augment√©s pour tickers + agents classiques pour macro
- **Service daemon optimis√©** : Analyses augment√©es en mode automatique
- **Tra√ßabilit√© compl√®te** : Logs sp√©ciaux pour analyses augment√©es

### Exemple de Processus d'Analyse Augment√©e ü§ñ

**Sc√©nario :** News sur Apple + iPhone sales

**Agent classique (Phase 4) :**
```
"Analyse l'impact sur AAPL. L'article semble positif..."
‚Üí Recommandation bas√©e uniquement sur l'article
```

**Agent augment√© (Phase 5) :**
```
"Analyse l'impact sur AAPL. L'article semble positif..."
üîß Utilise get_stock_price("AAPL")
üí∞ AAPL: 195.20 USD üìà +5.20% vs hier
"Le march√© a d√©j√† fortement r√©agi (+5.2%)..."

üîß Utilise web_search("Apple concurrents smartphone")  
üì∞ "Samsung annonce Galaxy S25 avec IA..."
"La concurrence s'intensifie avec Samsung..."

üîß Utilise get_market_sentiment("AAPL")
üìä AAPL - Cap: 3.0T USD | P/E: 28.5 | Volume moy: 58,000,000
"Valorisation √©lev√©e mais volume normal..."

‚Üí Recommandation nuanc√©e avec contexte march√© complet
```

### Transformation Cognitive üß†

#### Impact sur la Qualit√© D√©cisionnelle
| Aspect | Agents Classiques | Agents Augment√©s |
|--------|------------------|------------------|
| **Contexte temporel** | Fig√© | Temps r√©el |
| **R√©action march√©** | Inconnue | V√©rifi√©e |
| **Informations compl√©mentaires** | Limit√©es √† l'article | Web entier accessible |
| **Valorisation** | Estimation | Donn√©es r√©elles |
| **Timing** | Th√©orique | Pratique |

#### B√©n√©fices Transformationnels üìà
1. **Contextualisation parfaite** : D√©cisions ancr√©es dans la r√©alit√©
2. **D√©tection de sur-r√©action** : √âviter les achats apr√®s forte hausse  
3. **Informations concurrentielles** : Vision √©largie du secteur
4. **Timing optimal** : Prise en compte des mouvements r√©cents
5. **Risque r√©duit** : Analyses plus compl√®tes et nuanc√©es

### Architecture Finale BERZERK 2.0 üèóÔ∏è

```
üì∞ News ‚Üí ü§ñ Ticker Hunter ‚Üí üåê Agents Augment√©s ‚Üí üí∞ D√©cision Finale
              ‚Üì                    ‚Üì
         Tickers cibl√©s      Donn√©es temps r√©el
                                   ‚Üì
                            üîç Web + üìä Finance
```

**BERZERK est d√©sormais un syst√®me d'investissement connect√© au monde r√©el, capable de prendre des d√©cisions inform√©es par le contexte actuel du march√© ! üöÄ** 

## üêõ Correction Critique : Probl√®me de Retraitement des Articles

### Probl√®me Identifi√©
**Sympt√¥me :** Le syst√®me `real_time_rss_monitor.py` retraitait des articles d√©j√† analys√©s, causant une perte de tokens inutile √† chaque red√©marrage.

**Cause Racine :** Double logique de cache probl√©matique :
- `processed_articles` : charg√© depuis la base de donn√©es au d√©marrage ‚úÖ
- `articles_cache` : r√©initialis√© √† vide √† chaque red√©marrage ‚ùå

**Impact :** 
- Perte de tokens API
- Analyses redondantes
- Pollution des logs
- Performance d√©grad√©e

### Solution Impl√©ment√©e ‚úÖ
**Strat√©gie :** Simplification de la logique de d√©tection des nouveaux articles

**Modifications dans `real_time_rss_monitor.py` :**
1. **Suppression de `articles_cache`** dans la classe `FeedState`
2. **Logique simplifi√©e** : `if article_link and article_link not in self.processed_articles:`
3. **Marquage imm√©diat** : `self.processed_articles.add(article_link)` d√®s la d√©tection
4. **Nettoyage des imports** : suppression de `field` non utilis√©

**R√©sultat :** 
- ‚úÖ Seuls les VRAIS nouveaux articles sont trait√©s
- ‚úÖ Pas de retraitement apr√®s red√©marrage
- ‚úÖ √âconomie de tokens API
- ‚úÖ Logs plus propres 

## üéØ Mise √† Jour Majeure : Focus Bloomberg et Nettoyage Projet

### Phase 6 : Simplification et Fiabilit√© ‚úÖ
**Objectif :** Concentrer les analyses uniquement sur le flux RSS de Bloomberg (plus fiable) et nettoyer le projet.

**Modifications appliqu√©es :**
1. **Flux RSS simplifi√©** : Seul Bloomberg conserv√© dans `RSS_FEEDS`
   - ‚úÖ `berzerk_lab.py` : Bloomberg uniquement
   - ‚úÖ `test_feeds.py` : Bloomberg uniquement  
   - ‚úÖ `real_time_rss_monitor.py` : Messages mis √† jour
2. **Nettoyage des fichiers obsol√®tes** :
   - ‚úÖ Suppression de `auto_monitor.py` (redondant)
   - ‚úÖ Suppression de `berzerk_service.py` (redondant)
3. **Fichiers de configuration ajout√©s** :
   - ‚úÖ `requirements.txt` : Toutes les d√©pendances Python
   - ‚úÖ `env.example` : Variables d'environnement document√©es

**Justification :** Bloomberg est plus fiable et coh√©rent que Yahoo Finance. Cette simplification am√©liore la qualit√© des analyses et la reproductibilit√© du projet.
</file>

<file path="test_feeds.py">
import feedparser
import requests

# D√©finition des flux RSS √† tester
RSS_FEEDS = {
    "Bloomberg": "https://feeds.bloomberg.com/markets/news.rss"
}

print("--- Lancement du diagnostic des flux RSS ---")

# On boucle sur chaque flux pour le tester individuellement
for source, url in RSS_FEEDS.items():
    print(f"\n[TEST] Source : {source}")
    print(f"       URL    : {url}")
    
    try:
        # On simule un navigateur en ajoutant un User-Agent
        # C'est la correction la plus probable
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # On t√©l√©charge d'abord le contenu avec requests, qui permet de passer les headers
        response = requests.get(url, headers=headers, timeout=10)
        
        # On v√©rifie le code de statut HTTP. 200 = OK. 403 = Interdit. 404 = Non trouv√©.
        print(f"       Statut HTTP : {response.status_code}")

        if response.status_code == 200:
            # Si la requ√™te a r√©ussi, on donne le contenu √† feedparser
            feed = feedparser.parse(response.content)
            
            # On v√©rifie si feedparser a bien trouv√© des articles
            if feed.entries:
                print(f"       ‚úÖ SUCC√àS : {len(feed.entries)} article(s) trouv√©(s).")
            elif feed.bozo:
                # feed.bozo = 1 signifie que le flux est mal form√©
                print(f"       ‚ö†Ô∏è AVERTISSEMENT : Le flux est mal form√©. Erreur : {feed.bozo_exception}")
            else:
                print("       ‚ö†Ô∏è AVERTISSEMENT : Le flux est valide mais ne contient aucun article.")
        else:
            print(f"       ‚ùå √âCHEC : Le serveur a refus√© la connexion (Code {response.status_code}). Le flux est probablement prot√©g√© ou mort.")

    except Exception as e:
        print(f"       ‚ùå ERREUR : Impossible de se connecter au flux. Erreur : {e}")

print("\n--- Diagnostic termin√© ---")
</file>

<file path=".gitignore">
# YoYo AI version control directory
.yoyo/
</file>

</files>
