This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/workflows/ci.yml
.gitignore
agents.py
audit_decisions.csv
backtester.py
berzerk_dashboard_old.py
berzerk_dashboard.py
berzerk_lab.py
deployment/berzerk-monitor.service
deployment/CRON_INSTRUCTIONS.md
deployment/README.md
diagnostic_db.py
env.example
export_decisions_audit.py
orchestrator.py
pyproject.toml
pytest.ini
README.md
real_time_rss_monitor.py
requirements.txt
reset_and_analyze.py
send_portfolio_update.py
start_realtime_monitor.py
suivi_projet.md
test_feeds.py
tests/__init__.py
tests/integration/__init__.py
tests/unit/__init__.py
tests/unit/test_agents.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="audit_decisions.csv">
analyzed_at,ticker,prix_a_la_decision,decision
2025-07-25T14:19:49.825054,,0.0,IGNORER
2025-07-25T14:19:46.208343,,0.0,IGNORER
2025-07-25T14:19:39.100034,,0.0,IGNORER
2025-07-25T14:19:33.036310,,0.0,SURVEILLER
2025-07-25T14:19:25.941694,,0.0,SURVEILLER
2025-07-25T14:19:18.133785,,0.0,IGNORER
2025-07-25T14:19:12.923407,,0.0,SURVEILLER
2025-07-25T14:19:06.089540,AIR.PA,180.94000244140625,SHORT
2025-07-25T14:19:02.261968,,0.0,IGNORER
2025-07-25T14:18:58.245848,,0.0,IGNORER
2025-07-25T14:18:50.000577,MC.PA,481.29998779296875,SHORT
2025-07-25T14:18:46.512355,,0.0,IGNORER
2025-07-25T14:18:40.164546,,0.0,IGNORER
2025-07-25T14:18:34.622052,SRPT,12.869000434875488,SHORT
2025-07-25T14:18:25.888214,,0.0,IGNORER
2025-07-25T14:18:21.133638,,0.0,SURVEILLER
2025-07-25T14:18:15.654307,,0.0,IGNORER
2025-07-25T14:18:07.009782,TTE,60.59000015258789,LONG
2025-07-25T14:17:47.004497,,0.0,IGNORER
2025-07-25T14:17:39.087361,,0.0,IGNORER
</file>

<file path="deployment/berzerk-monitor.service">
[Unit]
Description=BERZERK Real-Time RSS Monitor Service
After=network.target

[Service]
# Utilisateur qui ex√©cutera le service
User=berzerk 
# Groupe qui ex√©cutera le service
Group=berzerk 

# R√©pertoire de travail de l'application
WorkingDirectory=/home/berzerk/app 

# Commande pour d√©marrer le service
# Utilise le python de l'environnement virtuel
ExecStart=/home/berzerk/app/venv/bin/python real_time_rss_monitor.py

# Politique de red√©marrage : toujours red√©marrer en cas de crash
Restart=always 
# D√©lai avant de red√©marrer
RestartSec=10 

# Configuration des logs
StandardOutput=journal
StandardError=journal
SyslogIdentifier=berzerk-monitor

[Install]
WantedBy=multi-user.target
</file>

<file path="deployment/CRON_INSTRUCTIONS.md">
# ‚öôÔ∏è Configuration du Rapport de Portefeuille P√©riodique

Ce guide explique comment configurer une t√¢che planifi√©e (`cron job`) sur votre VPS pour recevoir un r√©sum√© de votre portefeuille BERZERK toutes les 6 heures sur Telegram.

## 1. Se Connecter au VPS

Connectez-vous √† votre VPS avec votre utilisateur habituel (celui qui a les droits `sudo`).

## 2. Ouvrir l'√âditeur Crontab

Nous allons √©diter les t√¢ches planifi√©es pour l'utilisateur `berzerk` afin que le script s'ex√©cute dans le bon environnement.

```bash
sudo crontab -u berzerk -e
```

Si c'est la premi√®re fois, il vous demandera de choisir un √©diteur. Choisissez `nano` (g√©n√©ralement l'option 1), c'est le plus simple.

## 3. Ajouter la T√¢che Planifi√©e

Allez tout √† la fin du fichier et ajoutez la ligne suivante. Copiez-la exactement.

```
0 */6 * * * /home/berzerk/app/venv/bin/python /home/berzerk/app/send_portfolio_update.py
```

### Explication de la commande :

- `0 */6 * * *` : C'est la planification. Elle signifie "Ex√©cute √† la minute 0, toutes les 6 heures, tous les jours". Le script tournera donc √† 00:00, 06:00, 12:00, et 18:00.
- `/home/berzerk/app/venv/bin/python` : C'est le chemin **absolu** vers l'interpr√©teur Python de votre environnement virtuel. C'est crucial pour que le script utilise les bonnes d√©pendances.
- `/home/berzerk/app/send_portfolio_update.py` : C'est le chemin **absolu** vers le script que nous voulons ex√©cuter.

## 4. Sauvegarder et Quitter

- Appuyez sur `Ctrl+X`.
- Appuyez sur `Y` pour confirmer la sauvegarde.
- Appuyez sur `Entr√©e` pour valider le nom du fichier.

Vous devriez voir un message comme `crontab: installing new crontab`.

C'est tout ! Votre rapporteur de portefeuille est maintenant configur√© et s'ex√©cutera automatiquement.
</file>

<file path="deployment/README.md">
# üöÄ Guide de D√©ploiement BERZERK

## Configuration du Serveur de Production

### 1. Pr√©paration du serveur

#### G√©n√©rer une paire de cl√©s SSH
```bash
ssh-keygen -t ed25519 -C "berzerk-deploy-key"
```

#### Cloner le projet sur le serveur
```bash
git clone https://github.com/votre-nom/berzerk.git /home/berzerk/app
```

#### Cr√©er l'environnement virtuel
```bash
cd /home/berzerk/app
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

#### Cr√©er le fichier .env sur le serveur
```bash
nano /home/berzerk/app/.env
# Ajoutez vos cl√©s :
# GOOGLE_API_KEY=votre_cl√©_google
# TAVILY_API_KEY=votre_cl√©_tavily
```

### 2. Configuration du service systemd

#### Copier le fichier de service
```bash
sudo cp deployment/berzerk-monitor.service /etc/systemd/system/
```

#### Activer et d√©marrer le service
```bash
sudo systemctl daemon-reload
sudo systemctl enable berzerk-monitor.service
sudo systemctl start berzerk-monitor.service
```

#### V√©rifier le statut
```bash
sudo systemctl status berzerk-monitor
journalctl -u berzerk-monitor -f
```

### 3. Configuration GitHub

#### Variables (Settings > Secrets and variables > Actions > Variables)
- `GOOGLE_API_KEY`: Votre cl√© API Google Gemini
- `TAVILY_API_KEY`: Votre cl√© API Tavily

#### Secrets (Settings > Secrets and variables > Actions > Secrets)
- `PROD_HOST`: Adresse IP ou domaine du serveur
- `PROD_USERNAME`: Nom d'utilisateur SSH (ex: ubuntu, berzerk)
- `PROD_SSH_KEY`: Cl√© SSH priv√©e pour l'authentification

### 4. Workflow de D√©ploiement

Le syst√®me CI/CD fonctionne ainsi :

1. **Push vers main** ‚Üí D√©clenche le workflow CI
2. **Tests & Linting** ‚Üí Validation automatique de la qualit√©
3. **D√©ploiement** ‚Üí Si CI r√©ussie, d√©ploiement automatique
4. **Red√©marrage services** ‚Üí Application des changements
</file>

<file path="export_decisions_audit.py">
import sqlite3
import json
import csv
from pathlib import Path

DB_PATH = "berzerk.db"
EXPORT_CSV = True  # Passe √† False si tu ne veux pas de CSV
CSV_PATH = "audit_decisions.csv"


def extract_decisions(limit=50):
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute(
        """
        SELECT analyzed_at, decision_json
        FROM articles
        WHERE decision_json IS NOT NULL
        ORDER BY analyzed_at DESC
        LIMIT ?
        """,
        (limit,)
    )
    rows = cursor.fetchall()
    conn.close()
    results = []
    for analyzed_at, decision_json in rows:
        try:
            data = json.loads(decision_json)
            prix = data.get("prix_a_la_decision", None)
            ticker = data.get("ticker", None)
            decision = data.get("decision", None)
            results.append({
                "analyzed_at": analyzed_at,
                "ticker": ticker,
                "prix_a_la_decision": prix,
                "decision": decision,
            })
        except Exception as e:
            print(f"[WARN] Erreur parsing JSON: {e}")
    return results


def print_decisions(decisions):
    print(f"{'Date/Heure':<22} | {'Ticker':<8} | {'Prix √† la d√©cision':<18} | {'D√©cision':<10}")
    print("-" * 65)
    for d in decisions:
        print(f"{d['analyzed_at']:<22} | {d['ticker'] or 'N/A':<8} | {d['prix_a_la_decision'] or 'N/A':<18} | {d['decision'] or 'N/A':<10}")


def export_csv(decisions, path):
    with open(path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["analyzed_at", "ticker", "prix_a_la_decision", "decision"])
        writer.writeheader()
        for d in decisions:
            writer.writerow(d)
    print(f"Export CSV termin√© : {path}")


if __name__ == "__main__":
    decisions = extract_decisions()
    print_decisions(decisions)
    if EXPORT_CSV:
        export_csv(decisions, CSV_PATH)
</file>

<file path="pytest.ini">
[pytest]
minversion = 6.0
addopts = -ra -q
testpaths =
    tests
</file>

<file path="send_portfolio_update.py">
from dotenv import load_dotenv
import sqlite3
import json
import os
from datetime import datetime
import yfinance as yf

load_dotenv()

# --- Fonction utilitaire : prix actuel ---
def get_current_price(ticker: str) -> float:
    ticker = ticker.strip().replace("$", "")
    if not ticker:
        return 0.0
    try:
        stock = yf.Ticker(ticker)
        data = stock.history(period="1d", interval="1m")
        if not data.empty:
            return float(data["Close"].iloc[-1])
        info = stock.info
        price = info.get("regularMarketPrice") or info.get("currentPrice")
        if price:
            return float(price)
        hist = stock.history(period="5d")
        if not hist.empty:
            return float(hist["Close"].iloc[-1])
        return 0.0
    except Exception:
        return 0.0

# --- Fonction utilitaire : notification Telegram ---
def send_telegram_notification(message: str):
    bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
    chat_id = os.getenv("TELEGRAM_CHAT_ID")
    if not bot_token or not chat_id:
        print("[WARN] Variables Telegram manquantes : TELEGRAM_BOT_TOKEN ou TELEGRAM_CHAT_ID non d√©finies. Notification ignor√©e.")
        return
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": message,
        "parse_mode": "Markdown"
    }
    try:
        import requests
        response = requests.post(url, data=payload, timeout=10)
        if response.status_code != 200:
            print(f"[ERROR] Notification Telegram √©chou√©e : {response.status_code} - {response.text}")
        else:
            print("[INFO] Notification Telegram envoy√©e avec succ√®s.")
    except Exception as e:
        print(f"[ERROR] Exception lors de l'envoi Telegram : {e}")

# --- Extraction des positions actives ---
def fetch_active_positions():
    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()
    cursor.execute("""
        SELECT decision_json FROM articles
        WHERE decision_json IS NOT NULL
        AND (json_extract(decision_json, '$.decision') = 'LONG' OR json_extract(decision_json, '$.decision') = 'SHORT'
             OR json_extract(decision_json, '$.action') = 'LONG' OR json_extract(decision_json, '$.action') = 'SHORT')
    """)
    rows = cursor.fetchall()
    conn.close()
    positions = []
    for (decision_json,) in rows:
        try:
            data = json.loads(decision_json)
            action = data.get("decision", data.get("action", "")).upper()
            if action not in ["LONG", "SHORT"]:
                continue
            ticker = data.get("ticker", None)
            if not ticker:
                continue
            prix_decision = float(data.get("prix_a_la_decision", 0.0))
            positions.append({
                "ticker": ticker,
                "action": action,
                "prix_decision": prix_decision,
                "justification": data.get("justification_synthetique", data.get("justification", "")),
                "analyzed_at": data.get("analyzed_at", ""),
            })
        except Exception as e:
            print(f"[WARN] Erreur parsing JSON: {e}")
    return positions

# --- G√©n√©ration du r√©sum√© Telegram ---
def generate_portfolio_summary(positions):
    if not positions:
        return "‚ö™Ô∏è *Rapport de Portefeuille BERZERK* ‚ö™Ô∏è\n\nAucune position active pour le moment."
    header = "üìä *Rapport de Portefeuille BERZERK*\n\n"
    table_header = "`Ticker   | Dir.  | Entr√©e | Actuel | P&L`\n"
    table_rows = []
    total_trades = len(positions)
    win_trades = 0
    total_pnl = 0
    for pos in positions:
        ticker = pos["ticker"]
        action = pos["action"]
        prix_decision = pos["prix_decision"]
        prix_actuel = get_current_price(ticker)
        pnl_pct = 0
        if prix_decision > 0 and prix_actuel > 0:
            if action == "LONG":
                pnl_pct = ((prix_actuel - prix_decision) / prix_decision) * 100
            elif action == "SHORT":
                pnl_pct = ((prix_decision - prix_actuel) / prix_decision) * 100
        total_pnl += pnl_pct
        if pnl_pct >= 0:
            win_trades += 1
        pnl_emoji = "‚úÖ" if pnl_pct >= 0 else "üîª"
        row = f"`{ticker:<8} | {action:<5} | {prix_decision:<6.2f} | {prix_actuel:<6.2f} | {pnl_pct:+.2f}% {pnl_emoji}`"
        table_rows.append(row)
    win_rate = (win_trades / total_trades) * 100 if total_trades else 0
    avg_pnl = total_pnl / total_trades if total_trades else 0
    summary = f"\n*Positions: {total_trades} | Taux de r√©ussite: {win_rate:.1f}% | Perf. moyenne: {avg_pnl:+.2f}%*"
    message = header + table_header + "\n".join(table_rows) + summary
    return message

if __name__ == "__main__":
    positions = fetch_active_positions()
    message = generate_portfolio_summary(positions)
    print(message)
    send_telegram_notification(message)
</file>

<file path="tests/__init__.py">
# Fichier marker pour le package de tests BERZERK
</file>

<file path="tests/integration/__init__.py">
# Tests d'int√©gration pour le projet BERZERK
</file>

<file path="tests/unit/__init__.py">
# Tests unitaires pour le projet BERZERK
</file>

<file path="tests/unit/test_agents.py">
from agents import get_agent_description, get_available_agents


def test_route_to_agents_fallback_logic():
    """
    Teste la logique de fallback du routeur quand le LLM √©choue.
    Ce test est plus simple et ne d√©pend pas du LLM.
    """
    # 1. Test avec un ticker en majuscules (devrait d√©clencher analyste_actions)
    entities = ["AAPL", "technologie", "innovation"]

    # Test direct de la logique de fallback (extraite de la fonction)
    fallback_agents = []

    # Recherche de tickers (g√©n√©ralement en majuscules, 2-5 caract√®res)
    tickers = [
        entity for entity in entities if entity.isupper() and 2 <= len(entity) <= 5
    ]
    if tickers:
        fallback_agents.append({"agent_type": "analyste_actions", "focus": tickers[0]})

    # Recherche de secteurs (mots-cl√©s courants)
    secteurs = [
        "tech",
        "technologie",
        "√©nergie",
        "finance",
        "sant√©",
        "pharma",
        "automobile",
    ]
    for entity in entities:
        if any(secteur in entity.lower() for secteur in secteurs):
            fallback_agents.append(
                {"agent_type": "analyste_sectoriel", "focus": entity}
            )
            break

    # 2. V√©rifications
    assert len(fallback_agents) == 2
    assert fallback_agents[0]["agent_type"] == "analyste_actions"
    assert fallback_agents[0]["focus"] == "AAPL"
    assert fallback_agents[1]["agent_type"] == "analyste_sectoriel"
    assert fallback_agents[1]["focus"] == "technologie"


def test_get_available_agents():
    """
    Teste que la fonction get_available_agents retourne les bons types d'agents.
    """
    agents = get_available_agents()

    # V√©rification que les agents de base sont pr√©sents
    expected_agents = [
        "analyste_actions",
        "analyste_sectoriel",
        "strategiste_geopolitique",
        "ticker_hunter",
    ]

    for agent in expected_agents:
        assert agent in agents


def test_get_agent_description():
    """
    Teste que get_agent_description retourne une description pour les agents connus.
    """
    # Test avec un agent connu
    description = get_agent_description("analyste_actions")
    assert description != "Agent non reconnu"
    assert len(description) > 10  # Une description doit avoir du contenu

    # Test avec un agent inconnu
    description_unknown = get_agent_description("agent_inexistant")
    assert description_unknown == "Agent non reconnu"
</file>

<file path=".github/workflows/ci.yml">
name: BERZERK - CI & CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  # --- JOB 1: Validation du code ---
  validate-code:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11"]

    steps:
    - name: 1. Checkout du code
      uses: actions/checkout@v4

    - name: 2. Mise en place de Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: 3. Installation des d√©pendances
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-mock black ruff

    - name: 4. Cr√©ation du fichier .env pour la CI
      run: |
        echo "GOOGLE_API_KEY=${{ vars.GOOGLE_API_KEY }}" >> .env
        echo "TAVILY_API_KEY=${{ vars.TAVILY_API_KEY }}" >> .env
        echo "CI_ENV=true" >> .env

    - name: 5. V√©rification du formatage avec Black
      run: black --check .

    - name: 6. Linting avec Ruff
      run: ruff check .

    - name: 7. Ex√©cution des tests avec Pytest
      run: pytest

  # --- JOB 2: D√©ploiement (uniquement si la validation r√©ussit) ---
  deploy-to-prod:
    # 'needs' garantit que ce job ne se lance que si 'validate-code' a r√©ussi
    needs: validate-code
    runs-on: ubuntu-latest
    
    # 'if' garantit que ce job ne se lance que pour un push sur main,
    # et pas pour une pull request.
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: 1. Checkout du code
      uses: actions/checkout@v4

    - name: 2. D√©ploiement sur le serveur de production via SSH
      uses: appleboy/ssh-action@v1.0.3
      with:
        host: ${{ secrets.PROD_HOST }}
        username: ${{ secrets.PROD_USERNAME }}
        key: ${{ secrets.PROD_SSH_KEY }}
        port: 22
        script: |
          cd /home/berzerk/app 
          echo ">>> Mise √† jour du code depuis Git..."
          git pull origin main
          echo ">>> Activation de l'environnement virtuel..."
          source venv/bin/activate
          echo ">>> Installation des d√©pendances..."
          pip install -r requirements.txt
          echo ">>> Red√©marrage du service de monitoring..."
          sudo systemctl restart berzerk-monitor
          echo ">>> D√©ploiement termin√© avec succ√®s !"
</file>

<file path=".gitignore">
# YoYo AI version control directory
.yoyo/

# Base de donn√©es SQLite
*.db
berzerk.db

# Variables d'environnement
.env
.env.local

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
.venv/
pip-log.txt
pip-delete-this-directory.txt

# Virtual Environment
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Temporary files
*.tmp
*.temp" > .gitignore
</file>

<file path="env.example">
# Cl√© API pour Google Gemini
GOOGLE_API_KEY="votre_cl√©_ici"

# Cl√© API pour Tavily Search
TAVILY_API_KEY="votre_cl√©_ici" 
# Token pour le bot Telegram
TELEGRAM_BOT_TOKEN="votre_token_ici"
# ID du chat Telegram o√π envoyer les notifications
TELEGRAM_CHAT_ID="votre_chat_id_ici"
</file>

<file path="pyproject.toml">
[tool.black]
line-length = 88
target-version = ['py311']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | venv
  | _build
  | buck-out
  | build
  | dist
)/
'''

[tool.ruff]
# M√™me longueur de ligne que Black
line-length = 88
target-version = "py311"

# Fichiers √† exclure
exclude = [
    ".bzr",
    ".direnv",
    ".eggs",
    ".git",
    ".hg",
    ".mypy_cache",
    ".nox",
    ".pants.d",
    ".pytype",
    ".ruff_cache",
    ".svn",
    ".tox",
    ".venv",
    "__pypackages__",
    "_build",
    "buck-out",
    "build",
    "dist",
    "node_modules",
    "venv",
]

[tool.ruff.lint]
# R√®gles √† activer
select = [
    "E",  # pycodestyle errors
    "W",  # pycodestyle warnings
    "F",  # pyflakes
    "I",  # isort
    "B",  # flake8-bugbear
    "C4", # flake8-comprehensions
    "UP", # pyupgrade
]

# R√®gles √† ignorer
ignore = [
    "E501", # line too long, g√©r√© par Black
    "B008", # do not perform function calls in argument defaults
    "C901", # too complex
]

[tool.ruff.lint.mccabe]
max-complexity = 10
</file>

<file path="README.md">
# ‚ö° BERZERK

Un moteur d'analyse d'actualit√©s financi√®res bas√© sur l'IA, con√ßu pour g√©n√©rer des d√©cisions d'investissement "tac-au-tac".

BERZERK est un syst√®me automatis√© qui surveille en temps r√©el les actualit√©s financi√®res, d√©ploie une √©quipe d'agents IA sp√©cialis√©s pour analyser leur impact potentiel, et g√©n√®re des d√©cisions d'investissement claires et exploitables. Le projet est construit sur une philosophie de "Pure Pr√©diction", visant √† agir sur le potentiel futur d'une information avant que le march√© ne l'ait pleinement int√©gr√©e.

![alt text](https://img.shields.io/badge/License-MIT-yellow.svg)
![alt text](https://img.shields.io/badge/python-3.9+-blue.svg)
![alt text](https://img.shields.io/badge/Framework-Streamlit-ff69b4.svg)

## üéØ Core Features

- **Real-Time News Monitoring**: Surveillance quasi-instantan√©e (cycles de 30s) du flux RSS de Bloomberg avec des optimisations HTTP avanc√©es (ETags, Last-Modified) pour une efficacit√© maximale.
- **AI Agent Team**: Une √©quipe d'agents IA, orchestr√©e par LangGraph, collabore pour analyser les news sous diff√©rents angles :
  - **Ticker Hunter**: Identifie les entreprises cot√©es les plus impact√©es par une news.
  - **Pure Prediction Analyst**: √âvalue l'impact futur d'une nouvelle sur une action sp√©cifique, en ignorant d√©lib√©r√©ment la r√©action pass√©e du march√©.
  - **Final Investor**: Synth√©tise toutes les analyses, s√©lectionne la meilleure opportunit√© et prend la d√©cision finale (LONG, SHORT, SURVEILLER).
- **Automated Analysis Pipeline**: Un graphe d'√©tats (LangGraph) g√®re l'ensemble du processus, de la r√©cup√©ration de la news √† la d√©cision finale, de mani√®re robuste, tra√ßable et avec une validation syst√©matique des tickers.
- **Real-Time Trade Alerts**: Notifications instantan√©es via Telegram pour chaque d√©cision LONG ou SHORT, permettant une action imm√©diate.
- **Automated Portfolio Reporting**: Des r√©sum√©s p√©riodiques (via cron) de toutes les positions actives et de leur performance actuelle sont envoy√©s directement sur Telegram.
- **"Clart√© Radicale" Decision Dashboard**: Une interface utilisateur Streamlit √©pur√©e qui pr√©sente les d√©cisions, le portefeuille actif et la performance de chaque trade en temps r√©el.
- **Centralized Database**: Utilise SQLite pour stocker les articles, les analyses et les d√©cisions, assurant la persistance et la tra√ßabilit√© de chaque action.

## üèóÔ∏è Architecture

Le syst√®me est con√ßu avec une s√©paration claire entre le backend (surveillance/analyse/notification) et le frontend (visualisation).

```mermaid
graph TD
    subgraph "Backend (Service 24/7)"
        A[RSS Feed - Bloomberg] -- News --> B(real_time_rss_monitor.py);
        B -- D√©tecte nouvelle --> C{orchestrator.py};
        C -- Lance pipeline LangGraph --> D[AI Agent Team];
        D -- Analyse & D√©cide --> E[D√©cision Finale];
        E -- Sauvegarde --> F[(berzerk.db)];
        E -- Si LONG/SHORT --> G{{Telegram API}};
        G -- Alerte Signal --> H[Utilisateur];
    end

    subgraph "Frontend (Visualisation)"
        F -- Lit les d√©cisions --> I[berzerk_dashboard.py];
        I -- Affiche --> H;
    end
    
    subgraph "Outils de Validation & Reporting"
        F -- Lit les d√©cisions d'achat --> J(backtester.py);
        J -- Simule les trades --> K[Rapport de Performance];
        F -- Lit les positions actives --> L(send_portfolio_update.py);
        L -- "cron" (toutes les 6h) --> M{{Telegram API}};
        M -- Rapport Portefeuille --> H;
    end
```

## üõ†Ô∏è Tech Stack
- **Backend**: Python 3.9+
- **AI & Orchestration**: LangChain, LangGraph, Google Gemini
- **Frontend**: Streamlit
- **Database**: SQLite
- **Data & Web**: yfinance (donn√©es financi√®res), Tavily (recherche web), requests, BeautifulSoup4, feedparser
- **Notifications**: API Telegram

## üöÄ Setup and Installation

### 1. Clone the Repository
```bash
git clone https://github.com/votre-nom-utilisateur/berzerk.git
cd berzerk
```

### 2. Create a Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate
# Sur Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Set Up Environment Variables
Le syst√®me a besoin de cl√©s API pour fonctionner. Copiez le fichier d'exemple et remplissez-le avec vos cl√©s.
```bash
cp env.example .env
```
Ouvrez le fichier .env avec un √©diteur et ajoutez vos cl√©s :
```dotenv
# Cl√© API pour Google Gemini
GOOGLE_API_KEY="votre_cl√©_ici"

# Cl√© API pour Tavily Search
TAVILY_API_KEY="votre_cl√©_ici"

# --- Notifications (Optionnel) ---
# Token pour le bot Telegram
TELEGRAM_BOT_TOKEN="votre_token_ici"
# ID du chat Telegram o√π envoyer les notifications
TELEGRAM_CHAT_ID="votre_chat_id_ici"
```

## üìñ How to Use

### 1. Lancement Principal (Recommand√©)
Le script start_realtime_monitor.py lance le moniteur en arri√®re-plan et, optionnellement, le tableau de bord.
Pour lancer la surveillance seule (mode serveur) :
```bash
python start_realtime_monitor.py
```
Pour lancer la surveillance ET le tableau de bord en parall√®le (mode local) :
```bash
python start_realtime_monitor.py --with-dashboard
```
Acc√©dez au tableau de bord sur http://localhost:8501.

### 2. Lancer le Tableau de Bord Manuellement
Si vous voulez seulement visualiser les d√©cisions d√©j√† pr√©sentes dans la base de donn√©es.
```bash
streamlit run berzerk_dashboard.py
```

### 3. Analyser une URL Unique (Mode Test)
Pour tester le pipeline sur un article sp√©cifique sans lancer la surveillance.
```bash
python orchestrator.py "https://url-de-votre-article.com"
```

### 4. R√©initialiser et R√©-analyser
Pour nettoyer toutes les analyses et relancer le processus sur les articles les plus r√©cents (utile apr√®s une mise √† jour des agents).
```bash
python reset_and_analyze.py
```

### 5. Obtenir un Rapport de Portefeuille Manuellement
Pour tester l'envoi du rapport de portefeuille sans attendre la t√¢che planifi√©e.
```bash
python send_portfolio_update.py
```

## üß† The BERZERK Philosophy: "Tac au Tac" Pure Prediction

BERZERK a √©volu√© pour adopter une philosophie radicale : la pr√©diction pure. Contrairement √† une approche prudente qui v√©rifierait si le march√© a d√©j√† r√©agi, BERZERK agit comme un visionnaire.

- **Il Ignore D√©lib√©r√©ment les Donn√©es de March√© Pass√©es** : Le syst√®me ne regarde pas le prix de la veille. Il √©vite ainsi d'√™tre "pollu√©" par la volatilit√© et les r√©actions irrationnelles √† court terme.
- **Il se Fonde sur le Potentiel de l'Information** : La d√©cision est bas√©e sur l'impact fondamental que la news est susceptible d'avoir sur le business d'une entreprise.
- **Il Vise √† Agir AVANT la Foule** : L'objectif est de capturer la valeur cr√©√©e par l'information elle-m√™me, pas de suivre une tendance d√©j√† en cours.

Cette approche fait de BERZERK non pas un simple co-pilote d'analyse, mais une v√©ritable machine de guerre pr√©dictive, con√ßue pour √™tre offensive et d√©cisive.

## üìÇ Project Modules Explained

- **orchestrator.py**: Le c≈ìur du syst√®me. Contient le pipeline LangGraph qui orchestre la collaboration des agents IA et g√®re la logique de d√©cision.
- **agents.py**: D√©finit les profils et les capacit√©s de chaque agent IA sp√©cialis√© (Ticker Hunter, Pure Prediction Analyst, etc.).
- **real_time_rss_monitor.py**: Le service de surveillance 24/7 qui scanne les flux RSS, d√©tecte les nouvelles, d√©clenche le pipeline d'analyse et envoie les alertes de trade.
- **berzerk_dashboard.py**: L'interface utilisateur Streamlit con√ßue selon le principe de "Clart√© Radicale", affichant les signaux et le portefeuille actif.
- **send_portfolio_update.py**: Script autonome, lanc√© par cron, qui envoie un r√©sum√© des positions actives et de leur performance sur Telegram.
- **start_realtime_monitor.py**: Script de lancement simplifi√© pour une prise en main facile.
- **reset_and_analyze.py**: Script de maintenance pour r√©initialiser et relancer les analyses.
- **berzerk.db**: La base de donn√©es SQLite o√π toutes les donn√©es sont stock√©es.

## üìÑ License

This project is licensed under the MIT License.
</file>

<file path="test_feeds.py">
import feedparser
import requests

# D√©finition des flux RSS √† tester
RSS_FEEDS = {"Bloomberg": "https://feeds.bloomberg.com/markets/news.rss"}

print("--- Lancement du diagnostic des flux RSS ---")

# On boucle sur chaque flux pour le tester individuellement
for source, url in RSS_FEEDS.items():
    print(f"\n[TEST] Source : {source}")
    print(f"       URL    : {url}")

    try:
        # On simule un navigateur en ajoutant un User-Agent
        # C'est la correction la plus probable
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

        # On t√©l√©charge d'abord le contenu avec requests, qui permet de passer les headers
        response = requests.get(url, headers=headers, timeout=10)

        # On v√©rifie le code de statut HTTP. 200 = OK. 403 = Interdit. 404 = Non trouv√©.
        print(f"       Statut HTTP : {response.status_code}")

        if response.status_code == 200:
            # Si la requ√™te a r√©ussi, on donne le contenu √† feedparser
            feed = feedparser.parse(response.content)

            # On v√©rifie si feedparser a bien trouv√© des articles
            if feed.entries:
                print(f"       ‚úÖ SUCC√àS : {len(feed.entries)} article(s) trouv√©(s).")
            elif feed.bozo:
                # feed.bozo = 1 signifie que le flux est mal form√©
                print(
                    f"       ‚ö†Ô∏è AVERTISSEMENT : Le flux est mal form√©. Erreur : {feed.bozo_exception}"
                )
            else:
                print(
                    "       ‚ö†Ô∏è AVERTISSEMENT : Le flux est valide mais ne contient aucun article."
                )
        else:
            print(
                f"       ‚ùå √âCHEC : Le serveur a refus√© la connexion (Code {response.status_code}). Le flux est probablement prot√©g√© ou mort."
            )

    except Exception as e:
        print(f"       ‚ùå ERREUR : Impossible de se connecter au flux. Erreur : {e}")

print("\n--- Diagnostic termin√© ---")
</file>

<file path="berzerk_dashboard_old.py">
#!/usr/bin/env python3
"""
üéØ BERZERK COMMAND CENTER - Dashboard Professionnel
===================================================

Interface Streamlit avanc√©e pour visualiser et analyser les performances
du syst√®me BERZERK avec tableaux de bord interactifs et analytics.

Fonctionnalit√©s:
- üìà Live Feed: Analyses en temps r√©el avec cartes interactives
- üèÜ Performance & Backtest: M√©triques de performance et backtesting
- üìä Graphiques interactifs avec Plotly
- üé® Interface moderne avec couleurs et ic√¥nes
- ‚ö° Cache optimis√© pour performances

Usage: streamlit run berzerk_dashboard.py
"""

import json
import sqlite3
import time
from datetime import datetime, timedelta

import pandas as pd
import plotly.graph_objects as go
import streamlit as st
import yfinance as yf

# Configuration de la page simplifi√©e
st.set_page_config(
    page_title="BERZERK - Centre de Contr√¥le",
    page_icon="‚ö°",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# En-t√™te principal SIMPLE et CLAIR
st.markdown(
    """
<div class="main-header">
    <h1 style="color: white; font-size: 2.5rem; margin: 0; font-weight: 700;">
        ‚ö° BERZERK Command Center
    </h1>
    <p style="color: rgba(255,255,255,0.9); font-size: 1.2rem; margin: 0.5rem 0 0 0;">
        Intelligence Artificielle ‚Ä¢ Analyse d'Actualit√©s Financi√®res ‚Ä¢ D√©cisions d'Investissement
    </p>
</div>
""",
    unsafe_allow_html=True,
)

# Styles CSS ULTRA SIMPLES - Fond blanc, texte lisible
st.markdown(
    """
<style>
    /* Fond g√©n√©ral blanc */
    .main {
        background-color: #ffffff !important;
        color: #333333 !important;
    }

    /* Supprimer le fond sombre de Streamlit */
    .stApp {
        background-color: #ffffff !important;
    }

    /* En-t√™te avec couleurs douces */
    .main-header {
        background: linear-gradient(135deg, #4285f4, #34a853);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
        color: white !important;
    }

    /* Cartes avec bordures color√©es et fond blanc */
    .metric-card {
        background: #ffffff !important;
        border: 2px solid #e8f0fe;
        border-left: 5px solid #4285f4;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        color: #333333 !important;
    }

    .metric-card h3 {
        color: #1a73e8 !important;
        font-size: 1.1rem !important;
        margin-bottom: 0.5rem !important;
    }

    /* Cartes d'articles avec fond blanc */
    .article-card {
        background: #ffffff !important;
        border: 1px solid #dadce0;
        border-radius: 8px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        color: #333333 !important;
    }

    /* Titre d'article en noir */
    .article-title {
        color: #202124 !important;
        font-size: 1.2rem !important;
        font-weight: 600 !important;
        margin-bottom: 0.8rem !important;
        line-height: 1.4 !important;
    }

    /* M√©ta infos en gris */
    .article-meta {
        color: #5f6368 !important;
        font-size: 0.9rem !important;
        margin-bottom: 1rem !important;
    }

    /* Badges d'action plus simples */
    .badge-acheter {
        background: #34a853 !important;
        color: white !important;
        padding: 0.7rem 1.5rem !important;
        border-radius: 6px !important;
        font-weight: bold !important;
        font-size: 1rem !important;
        display: inline-block !important;
        margin-bottom: 1rem !important;
    }

    .badge-surveiller {
        background: #fbbc04 !important;
        color: #333333 !important;
        padding: 0.7rem 1.5rem !important;
        border-radius: 6px !important;
        font-weight: bold !important;
        font-size: 1rem !important;
        display: inline-block !important;
        margin-bottom: 1rem !important;
    }

    .badge-vendre {
        background: #ea4335 !important;
        color: white !important;
        padding: 0.7rem 1.5rem !important;
        border-radius: 6px !important;
        font-weight: bold !important;
        font-size: 1rem !important;
        display: inline-block !important;
        margin-bottom: 1rem !important;
    }

    .badge-ignorer {
        background: #9aa0a6 !important;
        color: white !important;
        padding: 0.7rem 1.5rem !important;
        border-radius: 6px !important;
        font-weight: bold !important;
        font-size: 1rem !important;
        display: inline-block !important;
        margin-bottom: 1rem !important;
    }

    /* M√©triques en ligne plus visibles */
    .inline-metric {
        background: #f8f9fa !important;
        border: 1px solid #e0e0e0 !important;
        padding: 0.8rem !important;
        border-radius: 6px !important;
        margin: 0.3rem !important;
        color: #333333 !important;
        font-size: 0.9rem !important;
    }

    .inline-metric strong {
        color: #1a73e8 !important;
    }

    /* Section headers plus clairs */
    .section-header {
        background: #f8f9fa !important;
        border: 1px solid #e0e0e0 !important;
        border-left: 4px solid #4285f4 !important;
        padding: 1rem 1.5rem !important;
        border-radius: 6px !important;
        margin: 1.5rem 0 1rem 0 !important;
        color: #333333 !important;
    }

    .section-header h3 {
        color: #1a73e8 !important;
        margin: 0 !important;
    }

    /* Am√©liorer les selectbox */
    .stSelectbox > div > div {
        background-color: #ffffff !important;
        border: 2px solid #dadce0 !important;
        border-radius: 6px !important;
        color: #333333 !important;
    }

    /* Forcer le texte en noir partout */
    .stMarkdown, .stText, p, span, div {
        color: #333333 !important;
    }

    /* Onglets plus visibles */
    .stTabs [data-baseweb="tab-list"] {
        background-color: #f8f9fa !important;
        border-radius: 6px !important;
        padding: 0.5rem !important;
    }

    .stTabs [data-baseweb="tab"] {
        background-color: transparent !important;
        color: #5f6368 !important;
        font-weight: 500 !important;
    }

    .stTabs [data-baseweb="tab"][aria-selected="true"] {
        background-color: #ffffff !important;
        color: #1a73e8 !important;
        font-weight: 600 !important;
    }
</style>
""",
    unsafe_allow_html=True,
)

# =============================================================================
# FONCTIONS DE CACHE ET DONN√âES
# =============================================================================


@st.cache_data(ttl=30)  # Cache pendant 30 secondes pour live feed
def get_articles_with_decisions():
    """R√©cup√®re tous les articles avec leurs d√©cisions"""
    conn = sqlite3.connect("berzerk.db")
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    cursor.execute(
        """
        SELECT * FROM articles
        ORDER BY published_date DESC
    """
    )

    articles = [dict(row) for row in cursor.fetchall()]
    conn.close()
    return articles


@st.cache_data(ttl=30)
def get_dashboard_stats():
    """R√©cup√®re les statistiques pour le tableau de bord - VERSION SIMPLIFI√âE"""
    try:
        conn = sqlite3.connect("berzerk.db")
        cursor = conn.cursor()

        # M√©triques principales
        cursor.execute("SELECT COUNT(*) FROM articles")
        total_articles = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM articles WHERE status = 'analyzed'")
        analyzed_articles = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM articles WHERE status = 'pending'")
        pending_articles = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM articles WHERE status = 'error'")
        error_count = cursor.fetchone()[0]

        # D√©cisions d'achat (recherche dans decision_json)
        cursor.execute(
            """
            SELECT COUNT(*) FROM articles
            WHERE status = 'analyzed'
            AND (decision_json LIKE '%"action": "ACHETER"%' OR decision_json LIKE '%"decision": "ACHETER"%')
        """
        )
        buy_decisions = cursor.fetchone()[0]

        # Derni√®re analyse
        cursor.execute(
            """
            SELECT analyzed_at FROM articles
            WHERE status = 'analyzed' AND analyzed_at IS NOT NULL
            ORDER BY analyzed_at DESC LIMIT 1
        """
        )
        last_analysis = cursor.fetchone()

        # Calculer les minutes depuis la derni√®re analyse
        last_analysis_minutes = 999
        if last_analysis and last_analysis[0]:
            try:
                last_time = datetime.fromisoformat(last_analysis[0])
                time_diff = datetime.now() - last_time
                last_analysis_minutes = int(time_diff.total_seconds() // 60)
            except Exception:
                last_analysis_minutes = 999

        conn.close()

        return {
            "total_articles": total_articles,
            "analyzed_articles": analyzed_articles,
            "pending_articles": pending_articles,
            "error_count": error_count,
            "buy_decisions": buy_decisions,
            "last_analysis_minutes": last_analysis_minutes,
        }

    except Exception as e:
        st.error(f"Erreur lors de la r√©cup√©ration des statistiques: {e}")
        return {
            "total_articles": 0,
            "analyzed_articles": 0,
            "pending_articles": 0,
            "error_count": 0,
            "buy_decisions": 0,
            "last_analysis_minutes": 999,
        }


@st.cache_data(ttl=300)  # Cache pendant 5 minutes
def get_backtest_data():
    """R√©cup√®re et traite les donn√©es de backtest"""
    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()

    # R√©cup√©rer les d√©cisions d'achat
    cursor.execute(
        """
        SELECT id, title, published_date, decision_json
        FROM articles
        WHERE decision_json IS NOT NULL
        AND status = "analyzed"
        ORDER BY published_date DESC
    """
    )

    rows = cursor.fetchall()
    conn.close()

    buy_decisions = []

    for row in rows:
        article_id, title, published_date, decision_json = row

        try:
            decision = json.loads(decision_json)
            action = decision.get("action", decision.get("decision", "")).upper()

            if action in ["ACHETER", "ACHAT", "BUY"]:
                ticker = decision.get("ticker")

                if ticker:
                    buy_decisions.append(
                        {
                            "article_id": article_id,
                            "title": title,
                            "ticker": ticker,
                            "decision_date": datetime.fromisoformat(published_date),
                            "action": action,
                            "justification": decision.get(
                                "justification", "Aucune justification"
                            ),
                            "allocation": decision.get(
                                "allocation_pourcentage",
                                decision.get("allocation_percent", 0.0),
                            ),
                            "confiance": decision.get(
                                "confiance", decision.get("confidence", "INCONNUE")
                            ),
                        }
                    )
        except Exception:
            continue

    return buy_decisions


def simulate_trade_performance(
    ticker: str, decision_date: datetime, holding_days: int = 7
) -> dict | None:
    """Simule la performance d'un trade"""
    try:
        # Calculer les dates
        buy_date = decision_date + timedelta(days=1)
        sell_date = buy_date + timedelta(days=holding_days)

        # T√©l√©charger les donn√©es
        stock = yf.Ticker(ticker)
        start_date = buy_date - timedelta(days=10)
        end_date = datetime.now() + timedelta(days=2)

        hist = stock.history(start=start_date, end=end_date)

        if hist.empty:
            return None

        # Trouver les prix
        buy_price = None
        sell_price = None

        # Prix d'achat
        for date, row in hist.iterrows():
            if date.date() >= buy_date.date():
                buy_price = row["Open"]
                break

        if buy_price is None:
            buy_price = hist.iloc[-1]["Close"]

        # Prix de vente
        if datetime.now().date() < sell_date.date():
            sell_price = hist.iloc[-1]["Close"]
        else:
            for date, row in hist.iterrows():
                if date.date() >= sell_date.date():
                    sell_price = row["Open"]
                    break

            if sell_price is None:
                sell_price = hist.iloc[-1]["Close"]

        # Calculer la performance
        roi_percent = ((sell_price - buy_price) / buy_price) * 100

        return {
            "ticker": ticker,
            "buy_price": round(buy_price, 2),
            "sell_price": round(sell_price, 2),
            "roi_percent": round(roi_percent, 2),
            "is_profitable": roi_percent > 0,
            "decision_date": decision_date,
            "buy_date": buy_date,
            "sell_date": sell_date,
        }

    except Exception:
        return None


# =============================================================================
# FONCTIONS D'AFFICHAGE
# =============================================================================


def parse_decision_json(decision_json: str) -> dict:
    """Parse le JSON de d√©cision de mani√®re s√©curis√©e"""
    if not decision_json:
        return {}
    try:
        return json.loads(decision_json)
    except Exception:
        return {}


def get_decision_color(action: str) -> str:
    """Retourne la couleur associ√©e √† une action"""
    colors = {
        "ACHETER": "#28a745",
        "VENDRE": "#dc3545",
        "SURVEILLER": "#ffc107",
        "IGNORER": "#6c757d",
    }
    return colors.get(action, "#6c757d")


def display_simple_article_card(article: dict):
    """Affiche une carte d'article ULTRA SIMPLE et LISIBLE"""
    decision = parse_decision_json(article.get("decision_json", "{}"))

    # Container principal
    st.markdown('<div class="article-card">', unsafe_allow_html=True)

    # TITRE de l'article (gros et lisible)
    title = article["title"]
    if len(title) > 80:
        title = title[:80] + "..."

    st.markdown(f'<div class="article-title">{title}</div>', unsafe_allow_html=True)

    # INFOS RAPIDES
    source = article.get("source", "Bloomberg")
    date_str = article.get("published_date", "")
    if date_str:
        try:
            date_obj = datetime.fromisoformat(date_str)
            date_display = date_obj.strftime("%d/%m √† %H:%M")
        except Exception:
            date_display = "Date inconnue"
    else:
        date_display = "Date inconnue"

    st.markdown(
        f'<div class="article-meta">üì∞ {source} ‚Ä¢ üìÖ {date_display}</div>',
        unsafe_allow_html=True,
    )

    # CONTENU PRINCIPAL selon le statut
    if article["status"] == "analyzed" and decision:
        # === ARTICLE ANALYS√â ===

        # Action principale (gros badge visible)
        action = decision.get("action", decision.get("decision", "INCONNUE")).upper()
        ticker = decision.get("ticker", "N/A")

        if action == "ACHETER":
            badge_class = "badge-acheter"
            message = "‚úÖ ACHETER"
            if ticker != "N/A":
                message += f" ‚Ä¢ {ticker}"
        elif action == "SURVEILLER":
            badge_class = "badge-surveiller"
            message = "üëÄ SURVEILLER"
            if ticker != "N/A":
                message += f" ‚Ä¢ {ticker}"
        elif action == "VENDRE":
            badge_class = "badge-vendre"
            message = "‚ùå VENDRE"
            if ticker != "N/A":
                message += f" ‚Ä¢ {ticker}"
        else:
            badge_class = "badge-ignorer"
            message = "‚ö™ IGNORER"

        st.markdown(
            f'<div class="{badge_class}">{message}</div>', unsafe_allow_html=True
        )

        # D√©tails importants (3 colonnes)
        col1, col2, col3 = st.columns(3)

        with col1:
            confidence = decision.get("confidence", decision.get("confiance", "N/A"))
            st.markdown(
                f'<div class="inline-metric"><strong>Confiance:</strong><br/>{confidence}</div>',
                unsafe_allow_html=True,
            )

        with col2:
            allocation = decision.get(
                "allocation_pourcentage", decision.get("allocation_percent", 0.0)
            )
            st.markdown(
                f'<div class="inline-metric"><strong>Allocation:</strong><br/>{allocation}%</div>',
                unsafe_allow_html=True,
            )

        with col3:
            if ticker != "N/A":
                st.markdown(
                    f'<div class="inline-metric"><strong>Titre:</strong><br/>{ticker}</div>',
                    unsafe_allow_html=True,
                )
            else:
                st.markdown(
                    '<div class="inline-metric"><strong>Statut:</strong><br/>Pas de titre</div>',
                    unsafe_allow_html=True,
                )

        # Justification (simple)
        justification = decision.get("justification", "")
        if len(justification) > 20:
            with st.expander("üìã Voir le raisonnement complet"):
                st.write(justification)

    else:
        # === ARTICLE NON ANALYS√â ===
        if article["status"] == "pending":
            st.markdown("**üïí EN ATTENTE D'ANALYSE**")
            st.info("Cet article sera analys√© bient√¥t.")
        elif article["status"] == "in_progress":
            st.markdown("**‚ö° ANALYSE EN COURS**")
            st.info("L'IA analyse cet article maintenant.")
        elif article["status"] == "error":
            st.markdown("**‚ùå ERREUR**")
            st.error("Probl√®me lors de l'analyse.")
        else:
            st.markdown(f'**‚ùì STATUT: {article["status"].upper()}**')

    st.markdown("</div>", unsafe_allow_html=True)
    st.markdown("---")  # S√©parateur visible


def display_live_feed_tab():
    """Affiche l'onglet Live Feed ultra-simplifi√©"""

    # R√©cup√©ration des statistiques
    stats = get_dashboard_stats()

    # EN-T√äTE SIMPLE
    st.markdown("# üìà Analyses en Temps R√©el")
    st.markdown("Surveillance automatique des actualit√©s financi√®res Bloomberg")
    st.markdown("---")

    # Controls rapides
    col1, col2 = st.columns([1, 3])

    with col1:
        if st.button("üîÑ Actualiser", type="primary"):
            st.cache_data.clear()
            st.rerun()

    with col2:
        auto_refresh = st.checkbox(
            "üîÅ Auto-actualisation",
            value=False,
            help="Actualise automatiquement toutes les 30 secondes",
        )
        if auto_refresh:
            time.sleep(30)
            st.rerun()

    # TABLEAU DE BORD SIMPLE
    st.markdown("## üìä Situation Actuelle")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(
            "üì∞ Articles Total",
            stats["total_articles"],
            help="Nombre total d'articles dans la base",
        )

    with col2:
        analyzed_count = stats["analyzed_articles"]
        st.metric("‚úÖ Analys√©s", analyzed_count, help="Articles analys√©s par l'IA")

    with col3:
        buy_count = stats.get("buy_decisions", 0)
        st.metric(
            "üéØ Opportunit√©s", buy_count, help="Recommandations d'achat d√©tect√©es"
        )

    # FILTRES SIMPLES
    st.markdown("---")
    st.markdown("## üîç Filtres")

    col1, col2 = st.columns(2)

    with col1:
        show_filter = st.selectbox(
            "Afficher:",
            [
                "Tous les articles",
                "Seulement les analys√©s",
                "Seulement les recommandations d'achat",
            ],
        )

    with col2:
        period_filter = st.selectbox(
            "P√©riode:", ["Toutes", "Derni√®res 24h", "Cette semaine"]
        )

    # R√âCUP√âRATION ET FILTRAGE DES ARTICLES
    articles = get_articles_with_decisions()

    # Application des filtres
    if show_filter == "Seulement les analys√©s":
        articles = [a for a in articles if a["status"] == "analyzed"]
    elif show_filter == "Seulement les recommandations d'achat":
        articles = [
            a
            for a in articles
            if a["status"] == "analyzed"
            and "ACHETER" in str(a.get("decision_json", ""))
        ]

    if period_filter != "Toutes":
        days_map = {"Derni√®res 24h": 1, "Cette semaine": 7}
        days = days_map[period_filter]
        cutoff_date = datetime.now() - timedelta(days=days)
        articles = [
            a
            for a in articles
            if datetime.fromisoformat(a.get("published_date", "1970-01-01"))
            > cutoff_date
        ]

    # AFFICHAGE DES ARTICLES
    st.markdown("---")
    st.markdown(f"## üìã Articles ({len(articles)} r√©sultats)")

    if len(articles) == 0:
        st.info("üîç Aucun article trouv√© avec ces filtres.")
    else:
        for article in articles:
            display_simple_article_card(article)


def display_performance_tab():
    """Affiche l'onglet Performance & Backtest"""
    st.markdown(
        '<div class="main-header"><h1>üèÜ Performance & Backtest</h1></div>',
        unsafe_allow_html=True,
    )

    # Boutons de contr√¥le
    col1, col2 = st.columns([1, 5])

    with col1:
        if st.button("üîÑ Actualiser Performance", type="primary"):
            st.cache_data.clear()
            st.rerun()

    # R√©cup√©ration des donn√©es de backtest
    buy_decisions = get_backtest_data()

    if not buy_decisions:
        st.warning("Aucune d√©cision d'achat trouv√©e pour effectuer le backtest.")
        return

    st.info(f"üìä {len(buy_decisions)} d√©cisions d'achat trouv√©es pour le backtest")

    # Simulation des trades
    with st.spinner("üîÑ Simulation des trades en cours..."):
        trade_results = []

        progress_bar = st.progress(0)

        for i, decision in enumerate(buy_decisions):
            result = simulate_trade_performance(
                decision["ticker"], decision["decision_date"]
            )

            if result:
                result.update(
                    {
                        "title": decision["title"],
                        "allocation": decision["allocation"],
                        "confidence": decision["confiance"],
                    }
                )
                trade_results.append(result)

            progress_bar.progress((i + 1) / len(buy_decisions))

        progress_bar.empty()

    if not trade_results:
        st.error("Aucun trade n'a pu √™tre simul√©.")
        return

    # Calcul des KPIs
    total_trades = len(trade_results)
    winning_trades = len([t for t in trade_results if t["is_profitable"]])
    losing_trades = total_trades - winning_trades
    win_rate = (winning_trades / total_trades) * 100 if total_trades > 0 else 0

    total_roi = sum(t["roi_percent"] for t in trade_results)
    avg_roi = total_roi / total_trades if total_trades > 0 else 0

    best_trade = max(trade_results, key=lambda x: x["roi_percent"])
    worst_trade = min(trade_results, key=lambda x: x["roi_percent"])

    # A. KPIs de Performance
    st.markdown("### üìà KPIs de Performance")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "üéØ Taux de R√©ussite",
            f"{win_rate:.1f}%",
            delta=f"{winning_trades}/{total_trades}",
            help="Pourcentage de trades rentables",
        )

    with col2:
        st.metric(
            "üìä ROI Moyen",
            f"{avg_roi:+.2f}%",
            help="Retour sur investissement moyen par trade",
        )

    with col3:
        st.metric(
            "‚úÖ Trades Gagnants", winning_trades, help="Nombre de trades profitables"
        )

    with col4:
        st.metric("‚ùå Trades Perdants", losing_trades, help="Nombre de trades en perte")

    # B. Graphique de Performance Cumul√©e
    st.markdown("### üìà Performance Cumul√©e")

    # Calcul de la performance cumul√©e
    cumulative_performance = []
    capital = 100  # Capital initial de 100‚Ç¨

    for i, trade in enumerate(trade_results):
        capital = capital * (1 + trade["roi_percent"] / 100)
        cumulative_performance.append(
            {
                "Trade": i + 1,
                "Capital": capital,
                "Date": trade["decision_date"],
                "Ticker": trade["ticker"],
                "ROI": trade["roi_percent"],
            }
        )

    df_perf = pd.DataFrame(cumulative_performance)

    # Graphique Plotly
    fig = go.Figure()

    fig.add_trace(
        go.Scatter(
            x=df_perf["Trade"],
            y=df_perf["Capital"],
            mode="lines+markers",
            name="Capital Cumul√©",
            line={"color": "#2a5298", "width": 3},
            marker={"size": 6},
            hovertemplate="<b>Trade %{x}</b><br>"
            + "Capital: %{y:.2f}‚Ç¨<br>"
            + "ROI: %{customdata:.2f}%<extra></extra>",
            customdata=df_perf["ROI"],
        )
    )

    fig.add_hline(
        y=100,
        line_dash="dash",
        line_color="gray",
        annotation_text="Capital Initial (100‚Ç¨)",
    )

    fig.update_layout(
        title="üöÄ √âvolution du Capital (100‚Ç¨ initial)",
        xaxis_title="Num√©ro de Trade",
        yaxis_title="Capital (‚Ç¨)",
        height=500,
        showlegend=True,
        hovermode="x unified",
    )

    st.plotly_chart(fig, use_container_width=True)

    # M√©triques finales
    final_capital = df_perf["Capital"].iloc[-1]
    total_return = ((final_capital - 100) / 100) * 100

    col1, col2 = st.columns(2)
    with col1:
        st.metric(
            "üí∞ Capital Final", f"{final_capital:.2f}‚Ç¨", delta=f"{total_return:+.2f}%"
        )

    with col2:
        st.metric(
            "üéØ Performance Totale",
            f"{total_return:+.2f}%",
            help="Performance totale depuis le d√©but",
        )

    # C. Tableau des Trades D√©taill√©s
    st.markdown("### üìã Tableau des Trades D√©taill√©s")

    # Pr√©paration du DataFrame
    df_trades = pd.DataFrame(trade_results)

    # Formatage des colonnes
    df_trades["decision_date"] = pd.to_datetime(df_trades["decision_date"]).dt.strftime(
        "%Y-%m-%d"
    )
    df_trades["buy_date"] = pd.to_datetime(df_trades["buy_date"]).dt.strftime(
        "%Y-%m-%d"
    )
    df_trades["Performance"] = df_trades["roi_percent"].apply(lambda x: f"{x:+.2f}%")

    # S√©lection des colonnes √† afficher
    display_columns = [
        "ticker",
        "title",
        "decision_date",
        "buy_price",
        "sell_price",
        "Performance",
        "confidence",
    ]
    df_display = df_trades[display_columns].copy()

    # Renommage des colonnes
    df_display.columns = [
        "Ticker",
        "Titre",
        "Date D√©cision",
        "Prix Achat",
        "Prix Vente",
        "Performance",
        "Confiance",
    ]

    # Style conditionnel
    def highlight_performance(row):
        if "Performance" in row:
            if "+" in str(row["Performance"]):
                return ["background-color: #d4edda"] * len(row)
            else:
                return ["background-color: #f8d7da"] * len(row)
        return [""] * len(row)

    # Affichage du tableau styl√©
    styled_df = df_display.style.apply(highlight_performance, axis=1)
    st.dataframe(styled_df, use_container_width=True, height=400)

    # D. Meilleurs et Pires Trades
    st.markdown("### üèÜ Meilleurs et Pires Trades")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### ü•á Meilleur Trade")
        st.success(f"**{best_trade['ticker']}** - {best_trade['roi_percent']:+.2f}%")
        st.write(f"üìÖ {best_trade['decision_date'].strftime('%Y-%m-%d')}")
        st.write(f"üí∞ {best_trade['buy_price']} ‚Üí {best_trade['sell_price']}")
        st.write(f"üì∞ {best_trade['title'][:50]}...")

    with col2:
        st.markdown("#### üìâ Pire Trade")
        st.error(f"**{worst_trade['ticker']}** - {worst_trade['roi_percent']:+.2f}%")
        st.write(f"üìÖ {worst_trade['decision_date'].strftime('%Y-%m-%d')}")
        st.write(f"üí∞ {worst_trade['buy_price']} ‚Üí {worst_trade['sell_price']}")
        st.write(f"üì∞ {worst_trade['title'][:50]}...")


# =============================================================================
# INTERFACE PRINCIPALE
# =============================================================================


def main():
    """Interface principale du BERZERK Command Center"""

    # Navigation par onglets
    tab1, tab2 = st.tabs(["üìà Live Feed", "üèÜ Performance & Backtest"])

    with tab1:
        display_live_feed_tab()

    with tab2:
        display_performance_tab()


if __name__ == "__main__":
    main()
</file>

<file path="berzerk_lab.py">
import sqlite3
from datetime import datetime

import feedparser
import requests
import streamlit as st
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field

# LangChain Imports
from langchain_google_genai import ChatGoogleGenerativeAI

# NOUVEAU : Import depuis notre module d'agents
from agents import route_to_agents, run_agent_analysis

# --- CONFIGURATION & SETUP ---
load_dotenv()


def init_db():
    """Initialise la base de donn√©es SQLite et cr√©e la table articles."""
    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()
    # On cr√©e une table pour stocker les articles.
    # Le lien (link) est UNIQUE pour √©viter les doublons.
    cursor.execute(
        """
        CREATE TABLE IF NOT EXISTS articles (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            source TEXT NOT NULL,
            title TEXT NOT NULL,
            link TEXT NOT NULL UNIQUE,
            published_str TEXT,
            published_date DATETIME NOT NULL,
            fetched_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            status TEXT DEFAULT 'pending',
            decision_json TEXT,
            analyzed_at DATETIME
        )
    """
    )

    # Ajouter les nouvelles colonnes si elles n'existent pas (pour les anciennes bases)
    try:
        cursor.execute("ALTER TABLE articles ADD COLUMN status TEXT DEFAULT 'pending'")
    except sqlite3.OperationalError:
        pass  # La colonne existe d√©j√†

    try:
        cursor.execute("ALTER TABLE articles ADD COLUMN decision_json TEXT")
    except sqlite3.OperationalError:
        pass  # La colonne existe d√©j√†

    try:
        cursor.execute("ALTER TABLE articles ADD COLUMN analyzed_at DATETIME")
    except sqlite3.OperationalError:
        pass  # La colonne existe d√©j√†

    conn.commit()
    conn.close()


# D√©finition de la structure de sortie attendue
class Analysis(BaseModel):
    resume: str = Field(description="R√©sum√© de la news en 3 phrases maximum.")
    impact: int = Field(
        description="Note d'impact de 1 (faible) √† 10 (tr√®s fort) sur les march√©s."
    )
    evaluation: str = Field(
        description="Une cha√Æne de caract√®res: 'Positif', 'N√©gatif' ou 'Neutre'."
    )
    entites: list[str] = Field(
        description="Liste de tickers d'actions (ex: ['AAPL', 'TSLA']), de noms de soci√©t√©s et de secteurs concern√©s."
    )


# Initialisation du mod√®le LLM via LangChain
try:
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-lite-preview-06-17", temperature=0
    )
except Exception as e:
    st.error(
        f"Erreur d'initialisation du mod√®le LangChain. V√©rifiez votre GOOGLE_API_KEY. Erreur: {e}"
    )
    llm = None

# Liste des flux RSS fonctionnels (apr√®s notre diagnostic)
RSS_FEEDS = {"Bloomberg": "https://feeds.bloomberg.com/markets/news.rss"}

# --- FONCTIONS CORE ---


def fetch_and_store_news(feeds):
    """Parcourt les flux RSS et ins√®re les nouveaux articles dans la DB."""
    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    new_articles_found = 0
    for source, url in feeds.items():
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                feed = feedparser.parse(response.content)
                for entry in feed.entries:
                    # On r√©cup√®re la date et on la convertit en objet datetime
                    # feedparser a une structure pratique pour √ßa dans "published_parsed"
                    published_tuple = entry.get("published_parsed")
                    if published_tuple:
                        dt_object = datetime(*published_tuple[:6])
                    else:
                        dt_object = datetime.now()  # Fallback si pas de date

                    # INSERT OR IGNORE est la cl√© : il n'ins√®re que si le lien n'existe pas d√©j√†
                    cursor.execute(
                        """
                        INSERT OR IGNORE INTO articles (source, title, link, published_str, published_date)
                        VALUES (?, ?, ?, ?, ?)
                    """,
                        (
                            source,
                            entry.title,
                            entry.link,
                            entry.get("published", "N/A"),
                            dt_object,
                        ),
                    )

                    if cursor.rowcount > 0:
                        new_articles_found += 1

        except Exception as e:
            print(f"Erreur lors de la r√©cup√©ration du flux de {source}: {e}")

    conn.commit()
    conn.close()
    return new_articles_found


def get_articles_from_db():
    """R√©cup√®re tous les articles de la DB, tri√©s par date de publication."""
    conn = sqlite3.connect("berzerk.db")
    # On force la connexion √† retourner des dictionnaires au lieu de tuples, c'est plus pratique
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    cursor.execute("SELECT * FROM articles ORDER BY published_date DESC")
    articles = [dict(row) for row in cursor.fetchall()]

    conn.close()
    return articles


def get_article_text(url):
    # (Cette fonction ne change pas)
    try:
        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        soup = BeautifulSoup(response.content, "html.parser")
        paragraphs = soup.find_all("p")
        article_text = " ".join([p.get_text() for p in paragraphs])
        return article_text
    except Exception as e:
        print(f"Erreur de r√©cup√©ration de l'article √† l'URL {url}: {e}")
        return None


def analyze_news_with_llm(article_text: str):
    """Analyse un article en utilisant une cha√Æne LangChain."""
    if not llm or not article_text:
        return None

    parser = JsonOutputParser(pydantic_object=Analysis)
    prompt_template = """Tu es un analyste financier expert pour le syst√®me BERSERK. Analyse l'article de presse suivant et extrais les informations cl√©s.
    {format_instructions}
    Voici l'article :
    ---
    {article}
    ---"""
    prompt = PromptTemplate(
        template=prompt_template,
        input_variables=["article"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
    )
    chain = prompt | llm | parser

    try:
        analysis_result = chain.invoke({"article": article_text})
        return analysis_result
    except Exception as e:
        st.error(f"Erreur lors de l'ex√©cution de la cha√Æne LangChain : {e}")
        return None


# --- INTERFACE UTILISATEUR (STREAMLIT) ---

st.set_page_config(page_title="BERSERK Labo", layout="wide")
st.title("üìò BERSERK - Labo d'Analyse (Phase 2)")
st.caption("Moteur: LangChain + Gemini + Agents IA | Monitoring: LangSmith")

# NOUVEAU : On initialise la DB au d√©marrage de l'app
init_db()

if "articles" not in st.session_state:
    # Au premier chargement, on remplit la liste depuis la DB
    st.session_state.articles = get_articles_from_db()
if "selected_article_link" not in st.session_state:
    st.session_state.selected_article_link = None
if "analysis_result" not in st.session_state:
    st.session_state.analysis_result = None

# NOUVEAU : Ajouter ces lignes pour g√©rer l'√©tat des agents
if "agent_team" not in st.session_state:
    st.session_state.agent_team = None
if "agent_analyses" not in st.session_state:
    st.session_state.agent_analyses = None

left_column, right_column = st.columns([1, 2])

with left_column:
    st.header("Flux d'actualit√©s")

    if st.button("üîÑ Charger les derni√®res actualit√©s", use_container_width=True):
        with st.spinner("Recherche de nouveaux articles..."):
            # 1. On cherche et stocke les nouveaux articles
            new_count = fetch_and_store_news(RSS_FEEDS)
            st.toast(f"{new_count} nouvel(s) article(s) trouv√©(s) !")
            # 2. On recharge la liste COMPL√àTE et TRI√âE depuis la DB
            st.session_state.articles = get_articles_from_db()
            st.session_state.selected_article_link = None
            st.session_state.analysis_result = None
            # NOUVEAU : R√©initialiser aussi les agents
            st.session_state.agent_team = None
            st.session_state.agent_analyses = None
        st.rerun()

    # On affiche les articles de st.session_state, qui est maintenant toujours tri√©
    if st.session_state.articles:
        for article in st.session_state.articles:
            with st.container(border=True):
                st.markdown(f"**{article['title']}**")

                # NOUVEAU : On affiche la source et l'heure de publication
                # On reformate l'objet datetime pour un affichage lisible
                pub_date = datetime.fromisoformat(article["published_date"])
                st.caption(
                    f"Source: {article['source']} | Publi√© le: {pub_date.strftime('%d/%m/%Y √† %H:%M')}"
                )

                if st.button("ü§ñ Analyser", key=article["link"]):
                    st.session_state.selected_article_link = article["link"]
                    st.session_state.analysis_result = None
                    # NOUVEAU : R√©initialiser aussi les agents
                    st.session_state.agent_team = None
                    st.session_state.agent_analyses = None
                    st.rerun()
    else:
        st.info(
            "Aucun article en base. Cliquez sur 'Charger les derni√®res actualit√©s' pour commencer."
        )

with right_column:
    st.header("üî¨ Analyse de l'IA")

    if st.session_state.selected_article_link:
        if st.session_state.analysis_result is None:
            with st.spinner("Analyse en cours (LangChain)..."):
                link = st.session_state.selected_article_link
                text = get_article_text(link)
                if text:
                    st.session_state.analysis_result = analyze_news_with_llm(text)
                else:
                    st.session_state.analysis_result = {"error": "Contenu inaccessible"}
            st.rerun()

        analysis = st.session_state.analysis_result
        if analysis:
            if "error" in analysis:
                st.error(analysis["error"])
            else:
                st.success("Analyse termin√©e !")

                # MISE EN FORME COMME SUR TON SCREENSHOT
                st.subheader("üìù R√©sum√©")
                st.write(analysis.get("resume", "N/A"))

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("√âvaluation", analysis.get("evaluation", "N/A"))
                with col2:
                    st.metric("Impact Potentiel", f"{analysis.get('impact', 0)}/10")

                st.subheader("üìà Entit√©s Concern√©es")
                # st.write(analysis.get('entites', [])) # Moins joli
                st.json(analysis.get("entites", []))  # Plus joli

                st.divider()  # Ajoute une ligne de s√©paration visuelle

                # --- NOUVELLE SECTION : ORCHESTRATION DES AGENTS ---

                # Si l'√©quipe n'a pas encore √©t√© recrut√©e, afficher le bouton
                if st.session_state.agent_team is None:
                    if st.button(
                        "üë• Recruter l'√âquipe d'Agents Sp√©cialis√©s",
                        use_container_width=True,
                    ):
                        with st.spinner("Le Chef d'Orchestre recrute l'√©quipe..."):
                            # On r√©cup√®re les entit√©s et le r√©sum√© de l'analyse initiale
                            entities = analysis.get("entites", [])
                            summary = analysis.get("resume", "")
                            # On appelle notre routeur intelligent
                            st.session_state.agent_team = route_to_agents(
                                entities, summary
                            )
                        st.rerun()

                # Si l'√©quipe est recrut√©e, on l'affiche et on lance les analyses
                if st.session_state.agent_team is not None:
                    st.subheader("üë• √âquipe d'Agents Recrut√©e")

                    # Afficher l'√©quipe
                    for agent in st.session_state.agent_team:
                        st.info(
                            f"**{agent['agent_type'].replace('_', ' ').title()}** recrut√© avec le focus : *{agent['focus']}*"
                        )

                    # Si les analyses ne sont pas encore faites, afficher le bouton pour les lancer
                    if st.session_state.agent_analyses is None:
                        if st.button(
                            "üöÄ Lancer les Analyses de l'√âquipe",
                            type="primary",
                            use_container_width=True,
                        ):
                            st.session_state.agent_analyses = []

                            # On r√©cup√®re le texte complet de l'article UNE SEULE FOIS
                            full_text = get_article_text(
                                st.session_state.selected_article_link
                            )

                            if full_text:
                                # On boucle sur chaque agent recrut√© pour lancer son analyse
                                with st.spinner(
                                    "Les agents travaillent... Cette op√©ration peut prendre un certain temps."
                                ):
                                    for agent in st.session_state.agent_team:
                                        # On appelle la fonction d'ex√©cution de notre module agents.py
                                        single_analysis = run_agent_analysis(
                                            agent_type=agent["agent_type"],
                                            focus=agent["focus"],
                                            news_summary=analysis.get("resume", ""),
                                            full_article_text=full_text,
                                        )
                                        st.session_state.agent_analyses.append(
                                            {
                                                "agent_type": agent["agent_type"],
                                                "focus": agent["focus"],
                                                "analysis": single_analysis,
                                            }
                                        )
                            else:
                                st.error(
                                    "Impossible de r√©cup√©rer le texte complet de l'article pour les agents."
                                )
                                st.session_state.agent_analyses = (
                                    []
                                )  # Pour √©viter de relancer
                            st.rerun()

                # Si les analyses sont termin√©es, on les affiche
                if st.session_state.agent_analyses is not None:
                    st.subheader("üìù Debriefing de l'√âquipe")
                    for result in st.session_state.agent_analyses:
                        with st.expander(
                            f"**Analyse du {result['agent_type'].replace('_', ' ').title()}** - Focus : *{result['focus']}*"
                        ):
                            st.markdown(result["analysis"])
    else:
        st.info("Cliquez sur 'Analyser' sur une news pour commencer.")
</file>

<file path="start_realtime_monitor.py">
#!/usr/bin/env python3
"""
üöÄ Script de Lancement BERZERK Real-Time Monitor
===============================================

Ce script simplifie le lancement du syst√®me de surveillance RSS temps r√©el.
Il peut √©galement lancer le dashboard en parall√®le pour une visualisation compl√®te.

Usage:
    python start_realtime_monitor.py                    # Surveillance seule
    python start_realtime_monitor.py --with-dashboard   # Surveillance + Dashboard
    python start_realtime_monitor.py --interval 30      # Intervalle personnalis√©
"""

import os
import subprocess
import sys
import time
from datetime import datetime


def log(message: str):
    """Logger avec timestamp"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"üöÄ [{timestamp}] {message}")


def launch_dashboard():
    """Lance le dashboard Streamlit en arri√®re-plan"""
    try:
        log("Lancement du dashboard Streamlit...")

        # Lancer le dashboard
        process = subprocess.Popen(
            [
                sys.executable,
                "-m",
                "streamlit",
                "run",
                "berzerk_dashboard.py",
                "--server.headless",
                "true",
                "--server.port",
                "8501",
                "--browser.gatherUsageStats",
                "false",
            ],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
        )

        # Attendre quelques secondes pour voir si le lancement r√©ussit
        time.sleep(3)

        if process.poll() is None:
            log("‚úÖ Dashboard d√©marr√© sur http://localhost:8501")
            return process
        else:
            log("‚ùå √âchec du d√©marrage du dashboard")
            return None

    except Exception as e:
        log(f"‚ùå Erreur lors du lancement du dashboard: {e}")
        return None


def launch_realtime_monitor(interval: int = 30):
    """Lance le monitor temps r√©el"""
    try:
        log(f"Lancement du monitor temps r√©el (intervalle: {interval}s)...")

        # Lancer le monitor
        process = subprocess.Popen(
            [sys.executable, "real_time_rss_monitor.py", str(interval)]
        )

        return process

    except Exception as e:
        log(f"‚ùå Erreur lors du lancement du monitor: {e}")
        return None


def main():
    """Fonction principale"""

    # Configuration par d√©faut
    interval = 30
    with_dashboard = False

    # Parsing des arguments
    args = sys.argv[1:]

    i = 0
    while i < len(args):
        arg = args[i]

        if arg == "--with-dashboard":
            with_dashboard = True
        elif arg == "--interval":
            if i + 1 < len(args):
                try:
                    interval = int(args[i + 1])
                    i += 1  # Skip next argument
                except ValueError:
                    print("‚ùå Erreur: L'intervalle doit √™tre un nombre entier")
                    sys.exit(1)
            else:
                print("‚ùå Erreur: --interval n√©cessite une valeur")
                sys.exit(1)
        elif arg == "--help" or arg == "-h":
            print(__doc__)
            sys.exit(0)
        else:
            print(f"‚ùå Argument inconnu: {arg}")
            print("üí° Utilisez --help pour voir les options disponibles")
            sys.exit(1)

        i += 1

    # Affichage de la configuration
    print("\n" + "=" * 70)
    print("üöÄ BERZERK Real-Time Monitor - Lancement")
    print("=" * 70)
    print(f"‚ö° Intervalle de surveillance: {interval} secondes")
    print(f"üìä Dashboard inclus: {'Oui' if with_dashboard else 'Non'}")
    print("=" * 70)

    # V√©rification des pr√©requis
    if not os.path.exists("real_time_rss_monitor.py"):
        print("‚ùå Erreur: real_time_rss_monitor.py non trouv√©")
        sys.exit(1)

    if with_dashboard and not os.path.exists("berzerk_dashboard.py"):
        print("‚ùå Erreur: berzerk_dashboard.py non trouv√©")
        sys.exit(1)

    # Lancement des composants
    dashboard_process = None
    monitor_process = None

    try:
        # Lancer le dashboard si demand√©
        if with_dashboard:
            dashboard_process = launch_dashboard()
            if dashboard_process:
                time.sleep(2)  # Laisser le dashboard se stabiliser

        # Lancer le monitor temps r√©el
        monitor_process = launch_realtime_monitor(interval)

        if monitor_process:
            log("‚úÖ Monitor temps r√©el d√©marr√©")

            if with_dashboard:
                log("üåê Acc√©dez au dashboard: http://localhost:8501")

            log("‚èπÔ∏è  Appuyez sur Ctrl+C pour arr√™ter")

            # Attendre la fin du processus principal
            monitor_process.wait()
        else:
            log("‚ùå √âchec du d√©marrage du monitor")

    except KeyboardInterrupt:
        log("üõë Arr√™t demand√© par l'utilisateur")

    except Exception as e:
        log(f"‚ùå Erreur fatale: {e}")

    finally:
        # Nettoyage des processus
        if monitor_process and monitor_process.poll() is None:
            log("Arr√™t du monitor temps r√©el...")
            monitor_process.terminate()
            monitor_process.wait()

        if dashboard_process and dashboard_process.poll() is None:
            log("Arr√™t du dashboard...")
            dashboard_process.terminate()
            dashboard_process.wait()

        log("üëã Tous les processus arr√™t√©s")


if __name__ == "__main__":
    main()
</file>

<file path="backtester.py">
#!/usr/bin/env python3
"""
üéØ BERZERK BACKTESTER - Module de Validation de Performance
=====================================================

Ce module analyse les d√©cisions d'ACHAT stock√©es dans la base de donn√©es
et simule leur rentabilit√© pour valider la performance du syst√®me BERZERK.

Strat√©gie de test :
- P√©riode de d√©tention : 7 jours calendaires
- Prix d'achat : Ouverture du jour de bourse suivant la d√©cision
- Prix de vente : Ouverture du jour de bourse apr√®s 7 jours
- M√©triques calcul√©es : ROI, taux de r√©ussite, performance cumul√©e

Auteur : BERZERK System
Date : 2024-01-XX
"""

import json
import sqlite3
import sys
from datetime import datetime, timedelta

import yfinance as yf

# Configuration
HOLDING_PERIOD_DAYS = 7
DATABASE_PATH = "berzerk.db"


class BerzerkBacktester:
    """
    Classe principale pour le backtesting des d√©cisions BERZERK
    """

    def __init__(self, db_path: str = DATABASE_PATH):
        self.db_path = db_path
        self.results = []

    def get_buy_decisions(self) -> list[dict]:
        """
        R√©cup√®re toutes les d√©cisions d'ACHAT de la base de donn√©es
        """
        print("üîç Recherche des d√©cisions d'ACHAT dans la base de donn√©es...")

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # R√©cup√©rer tous les articles avec d√©cisions
        cursor.execute(
            """
            SELECT id, title, link, published_date, decision_json
            FROM articles
            WHERE decision_json IS NOT NULL
            AND status = "analyzed"
            ORDER BY published_date DESC
        """
        )

        rows = cursor.fetchall()
        conn.close()

        buy_decisions = []

        for row in rows:
            article_id, title, link, published_date, decision_json = row

            try:
                decision = json.loads(decision_json)

                # Nouveau format : chercher dans 'action'
                action = decision.get("action", "").upper()

                # V√©rifier si c'est une d√©cision d'ACHAT/LONG
                if action in ["LONG", "ACHETER", "ACHAT", "BUY"]:
                    ticker = decision.get("ticker")

                    if ticker:  # Seulement si on a un ticker valide
                        buy_decisions.append(
                            {
                                "article_id": article_id,
                                "title": title,
                                "link": link,
                                "ticker": ticker,
                                "decision_date": datetime.fromisoformat(published_date),
                                "action": action,
                                "justification": decision.get(
                                    "justification", "Aucune justification"
                                ),
                                "allocation": decision.get(
                                    "allocation_pourcentage", 0.0
                                ),
                                "confiance": decision.get("confiance", "INCONNUE"),
                            }
                        )
                        print(
                            f"‚úÖ D√©cision LONG/ACHAT trouv√©e: {ticker} ({title[:30]}...)"
                        )
                    else:
                        print(f"‚ö†Ô∏è  D√©cision LONG/ACHAT sans ticker: {title[:30]}...")
                else:
                    print(f"üìä D√©cision {action}: {title[:30]}...")

            except json.JSONDecodeError as e:
                print(f"‚ùå Erreur JSON pour l'article {article_id}: {e}")
            except Exception as e:
                print(f"‚ùå Erreur lors du traitement de l'article {article_id}: {e}")

        print(f"\nüìà {len(buy_decisions)} d√©cision(s) LONG/ACHAT trouv√©e(s)")
        return buy_decisions

    def get_next_trading_day(self, date: datetime) -> datetime:
        """
        Trouve le prochain jour de bourse apr√®s une date donn√©e

        Args:
            date: Date de d√©part

        Returns:
            datetime: Prochain jour de bourse
        """
        # Commencer par le jour suivant
        next_day = date + timedelta(days=1)

        # √âviter les weekends (lundi = 0, dimanche = 6)
        while next_day.weekday() >= 5:  # 5 = samedi, 6 = dimanche
            next_day += timedelta(days=1)

        return next_day

    def simulate_trade(self, trade: dict) -> dict | None:
        """
        Simule un trade individuel avec la strat√©gie de d√©tention de 7 jours

        Args:
            trade: Dictionnaire contenant les infos du trade

        Returns:
            Dict: R√©sultat de la simulation ou None si erreur
        """
        ticker = trade["ticker"]
        decision_date = trade["decision_date"]

        print(
            f"üìä Simulation du trade {ticker} (d√©cision du {decision_date.strftime('%Y-%m-%d')})"
        )

        try:
            # Dates de trading avec ajustement pour les dates tr√®s r√©centes
            buy_date = self.get_next_trading_day(decision_date)
            sell_date = self.get_next_trading_day(
                buy_date + timedelta(days=HOLDING_PERIOD_DAYS)
            )

            # P√©riode de t√©l√©chargement des donn√©es avec marge √©tendue
            start_date = buy_date - timedelta(
                days=10
            )  # Plus de marge pour les dates r√©centes
            end_date = datetime.now() + timedelta(
                days=2
            )  # Utiliser date actuelle + marge

            print(
                f"   üìÖ P√©riode de donn√©es: {start_date.strftime('%Y-%m-%d')} ‚Üí {end_date.strftime('%Y-%m-%d')}"
            )

            # T√©l√©charger les donn√©es historiques
            stock = yf.Ticker(ticker)
            hist = stock.history(start=start_date, end=end_date)

            if hist.empty:
                print(f"‚ùå Pas de donn√©es historiques pour {ticker}")
                return None

            print(f"   üìä {len(hist)} jours de donn√©es r√©cup√©r√©s")

            # Trouver les prix d'achat et de vente
            buy_price = None
            sell_price = None
            actual_buy_date = None
            actual_sell_date = None

            # Prix d'achat : premier prix d'ouverture disponible >= buy_date
            for date, row in hist.iterrows():
                if date.date() >= buy_date.date():
                    buy_price = row["Open"]
                    actual_buy_date = date
                    print(
                        f"   üí∞ Prix d'achat trouv√©: {buy_price:.2f} USD le {date.strftime('%Y-%m-%d')}"
                    )
                    break

            # Si pas de prix d'achat exact, prendre le dernier prix disponible
            if buy_price is None:
                if not hist.empty:
                    last_row = hist.iloc[-1]
                    buy_price = last_row["Close"]  # Utiliser le prix de cl√¥ture
                    actual_buy_date = hist.index[-1]
                    print(
                        f"   üí∞ Prix d'achat (dernier disponible): {buy_price:.2f} USD le {actual_buy_date.strftime('%Y-%m-%d')}"
                    )
                else:
                    print(f"‚ùå Impossible de trouver un prix d'achat pour {ticker}")
                    return None

            # Prix de vente : chercher le prix apr√®s la p√©riode de d√©tention
            if datetime.now().date() < sell_date.date():
                # Si la date de vente est dans le futur, utiliser le prix actuel
                try:
                    current_info = stock.info
                    sell_price = current_info.get("regularMarketPrice", buy_price)
                    actual_sell_date = datetime.now()
                    print(
                        f"   üìà Prix de vente (actuel): {sell_price:.2f} USD le {actual_sell_date.strftime('%Y-%m-%d')}"
                    )
                except Exception:
                    # Si pas d'info actuelle, utiliser le dernier prix historique
                    sell_price = hist.iloc[-1]["Close"]
                    actual_sell_date = hist.index[-1]
                    print(
                        f"   üìà Prix de vente (dernier historique): {sell_price:.2f} USD le {actual_sell_date.strftime('%Y-%m-%d')}"
                    )
            else:
                # Prix de vente normal : chercher dans l'historique
                for date, row in hist.iterrows():
                    if date.date() >= sell_date.date():
                        sell_price = row["Open"]
                        actual_sell_date = date
                        print(
                            f"   üìà Prix de vente trouv√©: {sell_price:.2f} USD le {date.strftime('%Y-%m-%d')}"
                        )
                        break

                # Si pas trouv√©, utiliser le dernier prix disponible
                if sell_price is None:
                    sell_price = hist.iloc[-1]["Close"]
                    actual_sell_date = hist.index[-1]
                    print(
                        f"   üìà Prix de vente (dernier disponible): {sell_price:.2f} USD le {actual_sell_date.strftime('%Y-%m-%d')}"
                    )

            if buy_price is None or sell_price is None:
                print(f"‚ùå Impossible de trouver les prix pour {ticker}")
                return None

            # Calculer la performance
            roi_percent = ((sell_price - buy_price) / buy_price) * 100

            result = {
                "ticker": ticker,
                "title": (
                    trade["title"][:50] + "..."
                    if len(trade["title"]) > 50
                    else trade["title"]
                ),
                "decision_date": decision_date,
                "buy_date": actual_buy_date,
                "sell_date": actual_sell_date,
                "buy_price": round(buy_price, 2),
                "sell_price": round(sell_price, 2),
                "roi_percent": round(roi_percent, 2),
                "allocation": trade["allocation"],
                "is_profitable": roi_percent > 0,
                "is_partial_simulation": datetime.now().date()
                < sell_date.date(),  # Indicateur si simulation partielle
            }

            status = "‚úÖ PROFIT" if roi_percent > 0 else "‚ùå PERTE"
            partial_note = (
                " (‚ö†Ô∏è Simulation partielle)" if result["is_partial_simulation"] else ""
            )
            print(f"üíπ {ticker}: {roi_percent:+.2f}% {status}{partial_note}")

            return result

        except Exception as e:
            print(f"‚ùå Erreur simulation {ticker}: {e}")
            return None

    def run_backtest(self) -> dict:
        """
        Ex√©cute le backtest complet et g√©n√®re le rapport de performance

        Returns:
            Dict: R√©sultats complets du backtest
        """
        print("üöÄ D√âMARRAGE DU BACKTEST BERZERK")
        print("=" * 60)

        # √âtape 1 : Extraire les d√©cisions d'ACHAT
        buy_decisions = self.get_buy_decisions()

        if not buy_decisions:
            print("‚ùå Aucune d√©cision d'ACHAT trouv√©e dans la base de donn√©es")
            return {"error": "No buy decisions found"}

        # √âtape 2 : Simuler chaque trade
        print(f"\nüéØ Simulation de {len(buy_decisions)} trades...")
        print("-" * 60)

        successful_trades = []
        failed_trades = []

        for trade in buy_decisions:
            result = self.simulate_trade(trade)
            if result:
                successful_trades.append(result)
            else:
                failed_trades.append(trade)

        # √âtape 3 : Calculer les m√©triques
        if not successful_trades:
            print("‚ùå Aucun trade n'a pu √™tre simul√©")
            return {"error": "No successful simulations"}

        # M√©triques de performance
        total_trades = len(successful_trades)
        winning_trades = [t for t in successful_trades if t["is_profitable"]]
        losing_trades = [t for t in successful_trades if not t["is_profitable"]]

        win_rate = (len(winning_trades) / total_trades) * 100
        avg_roi = sum(t["roi_percent"] for t in successful_trades) / total_trades
        total_roi = sum(t["roi_percent"] for t in successful_trades)

        best_trade = max(successful_trades, key=lambda x: x["roi_percent"])
        worst_trade = min(successful_trades, key=lambda x: x["roi_percent"])

        # Stocker les r√©sultats
        self.results = successful_trades

        return {
            "total_trades": total_trades,
            "successful_simulations": len(successful_trades),
            "failed_simulations": len(failed_trades),
            "winning_trades": len(winning_trades),
            "losing_trades": len(losing_trades),
            "win_rate": round(win_rate, 2),
            "avg_roi": round(avg_roi, 2),
            "total_roi": round(total_roi, 2),
            "best_trade": best_trade,
            "worst_trade": worst_trade,
            "trades": successful_trades,
        }

    def display_results(self, results: dict):
        """
        Affiche le rapport de performance format√©

        Args:
            results: R√©sultats du backtest
        """
        if "error" in results:
            print(f"‚ùå Erreur : {results['error']}")
            return

        print("\n" + "=" * 60)
        print("üìà RAPPORT DE PERFORMANCE BERZERK")
        print("=" * 60)

        # Statistiques globales
        print("\nüìä STATISTIQUES GLOBALES")
        print("-" * 30)
        print(f"Total des trades simul√©s    : {results['total_trades']}")
        print(f"Simulations r√©ussies       : {results['successful_simulations']}")
        print(f"Simulations √©chou√©es       : {results['failed_simulations']}")
        print(f"Trades gagnants            : {results['winning_trades']}")
        print(f"Trades perdants            : {results['losing_trades']}")
        print(f"Taux de r√©ussite           : {results['win_rate']:.2f}%")
        print(f"ROI moyen par trade        : {results['avg_roi']:+.2f}%")
        print(f"ROI total cumul√©           : {results['total_roi']:+.2f}%")

        # Meilleurs et pires trades
        print("\nüèÜ MEILLEUR TRADE")
        print("-" * 20)
        best = results["best_trade"]
        print(f"Ticker  : {best['ticker']}")
        print(f"ROI     : {best['roi_percent']:+.2f}%")
        print(
            f"Achat   : {best['buy_price']:.2f} USD le {best['buy_date'].strftime('%Y-%m-%d')}"
        )
        print(
            f"Vente   : {best['sell_price']:.2f} USD le {best['sell_date'].strftime('%Y-%m-%d')}"
        )

        print("\nüìâ PIRE TRADE")
        print("-" * 15)
        worst = results["worst_trade"]
        print(f"Ticker  : {worst['ticker']}")
        print(f"ROI     : {worst['roi_percent']:+.2f}%")
        print(
            f"Achat   : {worst['buy_price']:.2f} USD le {worst['buy_date'].strftime('%Y-%m-%d')}"
        )
        print(
            f"Vente   : {worst['sell_price']:.2f} USD le {worst['sell_date'].strftime('%Y-%m-%d')}"
        )

        # D√©tail de tous les trades
        print("\nüìã D√âTAIL DE TOUS LES TRADES")
        print("-" * 40)
        for trade in results["trades"]:
            status = "‚úÖ" if trade["is_profitable"] else "‚ùå"
            print(
                f"{status} {trade['ticker']:<6} | {trade['roi_percent']:+6.2f}% | "
                f"{trade['buy_date'].strftime('%Y-%m-%d')} ‚Üí {trade['sell_date'].strftime('%Y-%m-%d')} | "
                f"{trade['title']}"
            )

        # Conclusions
        print("\nüéØ CONCLUSIONS")
        print("-" * 15)
        if results["win_rate"] > 60:
            print(
                "üî• Performance EXCELLENTE ! Le syst√®me montre une tr√®s bonne capacit√© pr√©dictive."
            )
        elif results["win_rate"] > 50:
            print("üëç Performance POSITIVE. Le syst√®me bat le hasard.")
        else:
            print("‚ö†Ô∏è  Performance √Ä AM√âLIORER. Revoir les strat√©gies d'analyse.")

        if results["avg_roi"] > 2:
            print("üí∞ ROI moyen tr√®s attractif pour une strat√©gie √† 7 jours.")
        elif results["avg_roi"] > 0:
            print("üìà ROI moyen positif, strat√©gie rentable.")
        else:
            print("üìâ ROI moyen n√©gatif, n√©cessite des ajustements.")


def main():
    """
    Fonction principale du backtester
    """
    print("üéØ BERZERK BACKTESTER - Validation de Performance")
    print("=" * 60)

    # V√©rifier les pr√©requis
    import importlib.util

    missing_modules = []
    for module in ["pandas", "yfinance"]:
        if importlib.util.find_spec(module) is None:
            missing_modules.append(module)

    if missing_modules:
        print(f"‚ùå Erreur : Modules manquants {missing_modules}")
        print("üí° Installez les d√©pendances : pip install yfinance pandas")
        sys.exit(1)

    # Lancer le backtester
    backtester = BerzerkBacktester()
    results = backtester.run_backtest()
    backtester.display_results(results)

    print(f"\nüîÑ Backtest termin√© ! P√©riode test√©e : {HOLDING_PERIOD_DAYS} jours")
    print("üìä Utilisez ces r√©sultats pour am√©liorer les strat√©gies BERZERK.")


if __name__ == "__main__":
    main()
</file>

<file path="diagnostic_db.py">
#!/usr/bin/env python3
"""
üîç DIAGNOSTIC BASE DE DONN√âES BERZERK
====================================
Script simple pour analyser les d√©cisions stock√©es
"""

import json
import sqlite3


def diagnostic_db():
    """Analyse le contenu de la base de donn√©es"""
    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()

    # Compter les articles avec d√©cisions
    cursor.execute("SELECT COUNT(*) FROM articles WHERE decision_json IS NOT NULL")
    total_analyzed = cursor.fetchone()[0]

    # Compter les articles avec statut "analyzed"
    cursor.execute('SELECT COUNT(*) FROM articles WHERE status = "analyzed"')
    status_analyzed = cursor.fetchone()[0]

    print(f"üìä Total articles avec d√©cisions: {total_analyzed}")
    print(f"üìä Articles avec statut 'analyzed': {status_analyzed}")

    # Examiner les d√©cisions
    cursor.execute(
        "SELECT id, title, decision_json FROM articles WHERE decision_json IS NOT NULL LIMIT 5"
    )
    decisions = cursor.fetchall()

    print(f"\nüîç √âchantillon de {len(decisions)} d√©cisions:")
    print("-" * 60)

    long_count = 0
    for article_id, title, decision_json in decisions:
        print(f"\nüì∞ Article {article_id}: {title[:50]}...")
        try:
            decision = json.loads(decision_json)

            # V√©rifier le format de la d√©cision
            if isinstance(decision, dict):
                action = decision.get("action", "N/A")
                ticker = decision.get("ticker", "N/A")

                print(f"   üéØ Action: {action}")
                print(f"   üìà Ticker: {ticker}")

                if action and action.upper() in ["LONG", "ACHETER"]:  # Compatibilit√© avec anciennes donn√©es
                    long_count += 1
                    print("   ‚úÖ D√âCISION LONG/ACHAT TROUV√âE!")

            else:
                print(f"   ‚ö†Ô∏è  Format inattendu: {type(decision)}")

        except json.JSONDecodeError as e:
            print(f"   ‚ùå Erreur JSON: {e}")

    print(f"\nüìà R√©sum√©: {long_count} d√©cision(s) LONG/ACHAT trouv√©e(s)")

    conn.close()


if __name__ == "__main__":
    diagnostic_db()
</file>

<file path="requirements.txt">
# Core dependencies
streamlit>=1.30.0
streamlit-autorefresh>=1.0.1
langchain>=0.1.0
langchain-google-genai>=0.0.6
langchain-core>=0.1.0
google-generativeai>=0.3.0
python-dotenv>=1.0.0

# Web scraping and RSS
requests>=2.31.0
beautifulsoup4>=4.12.0
feedparser>=6.0.0

# Finance and data
yfinance>=0.2.0
pandas>=2.0.0

# Search and tools
tavily-python>=0.3.0

# Additional tools
langgraph>=0.0.30
langsmith>=0.0.40

# Utility
pydantic>=2.0.0
typing-extensions>=4.8.0

# Development dependencies (for CI/CD)
pytest>=7.0.0
pytest-mock>=3.12.0
black>=23.0.0
ruff>=0.1.0 
langchain_community
</file>

<file path="real_time_rss_monitor.py">
#!/usr/bin/env python3
"""
üöÄ BERZERK Real-Time RSS Monitor - Surveillance RSS Quasi-Instantan√©e
=====================================================================

Ce syst√®me avanc√© surveille les flux RSS en temps quasi-r√©el avec :
- Polling haute fr√©quence (30-60 secondes)
- Optimisations HTTP (ETags, Last-Modified, conditional requests)
- Threading asynchrone pour √©viter les blocages
- D√©tection intelligente des changements
- Analyse automatique instantan√©e

Architecture Temps R√©el :
- Pas d'attente bloquante (utilise threading)
- R√©activit√© √©v√©nementielle
- Gestion des erreurs robuste
- Int√©gration avec le pipeline BERZERK existant

Usage: python real_time_rss_monitor.py [poll_interval_seconds]
Arr√™t: Ctrl+C
"""

import hashlib
import json
import sqlite3
import sys
import threading
import time
from dataclasses import dataclass
from datetime import datetime
from email.utils import parsedate_to_datetime

import feedparser
import requests

# Import des modules BERZERK
from berzerk_lab import RSS_FEEDS, init_db
from orchestrator import run_berzerk_pipeline, send_telegram_notification


@dataclass
class FeedState:
    """√âtat d'un flux RSS avec optimisations HTTP"""

    url: str
    last_modified: str | None = None
    etag: str | None = None
    last_check: datetime | None = None
    last_content_hash: str | None = None
    consecutive_errors: int = 0
    # articles_cache supprim√© - causait des doublons apr√®s red√©marrage

    def should_check(self, min_interval: int) -> bool:
        """D√©termine si le flux doit √™tre v√©rifi√© maintenant"""
        if self.last_check is None:
            return True

        # Algorithme adaptatif : plus d'erreurs = moins de v√©rifications
        if self.consecutive_errors > 0:
            penalty = min(self.consecutive_errors * 30, 300)  # Max 5 minutes de penalty
            return (datetime.now() - self.last_check).total_seconds() > (
                min_interval + penalty
            )

        return (datetime.now() - self.last_check).total_seconds() >= min_interval


class RealTimeRSSMonitor:
    """Surveillant RSS temps r√©el avec optimisations avanc√©es"""

    def __init__(self, poll_interval: int = 30, capital: float = 25000.0):
        self.poll_interval = poll_interval  # En secondes
        self.capital = capital
        self.feeds_state: dict[str, FeedState] = {}
        self.running = False
        self.processed_articles: set[str] = set()
        self.stats = {
            "total_checks": 0,
            "new_articles_found": 0,
            "analyses_completed": 0,
            "errors": 0,
            "start_time": datetime.now(),
        }

        # Configuration des requ√™tes HTTP optimis√©es
        self.session = requests.Session()
        self.session.headers.update(
            {
                "User-Agent": "BERZERK-RSS-Monitor/1.0 (Real-Time News Analysis)",
                "Accept": "application/rss+xml, application/xml, text/xml",
                "Accept-Encoding": "gzip, deflate",
                "Connection": "keep-alive",
            }
        )

        # Initialisation
        self.init_feeds_state()
        self.load_processed_articles()

        print("üöÄ BERZERK Real-Time RSS Monitor initialis√©")
        print(f"   ‚ö° Polling: {poll_interval} secondes (haute fr√©quence)")
        print(f"   üìà Flux RSS: {len(RSS_FEEDS)} source (Bloomberg uniquement)")
        for feed_name, feed_url in RSS_FEEDS.items():
            print(f"   üì° {feed_name}: {feed_url}")
        print(f"   üí∞ Capital: {capital:,.2f}‚Ç¨")
        print("   üîÑ Optimisations: ETags, Last-Modified, Threading")
        print(f"   üìä Articles d√©j√† trait√©s: {len(self.processed_articles)}")
        print("-" * 70)

    def init_feeds_state(self):
        """Initialise l'√©tat de chaque flux RSS"""
        for _feed_name, feed_url in RSS_FEEDS.items():
            self.feeds_state[feed_url] = FeedState(url=feed_url)

    def load_processed_articles(self):
        """Charge les articles d√©j√† trait√©s depuis la base de donn√©es"""
        try:
            conn = sqlite3.connect("berzerk.db")
            cursor = conn.cursor()
            # Charger TOUS les articles existants (peu importe le statut)
            cursor.execute("SELECT link FROM articles")
            self.processed_articles = {row[0] for row in cursor.fetchall()}
            conn.close()

            self.log(f"üì• {len(self.processed_articles)} articles existants charg√©s")
            self.log("üéØ Seuls les vrais nouveaux articles RSS seront trait√©s")
        except Exception as e:
            self.log(f"‚ö†Ô∏è Erreur lors du chargement des articles trait√©s: {e}")
            self.processed_articles = set()

    def log(self, message: str, level: str = "INFO"):
        """Logger avec timestamp et niveau"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        level_emoji = {
            "INFO": "‚ÑπÔ∏è",
            "SUCCESS": "‚úÖ",
            "WARNING": "‚ö†Ô∏è",
            "ERROR": "‚ùå",
            "DETECTION": "üîç",
        }.get(level, "üìù")
        print(f"‚ö° [{timestamp}] {level_emoji} {message}")

    def calculate_content_hash(self, content: str) -> str:
        """Calcule un hash du contenu pour d√©tecter les changements"""
        return hashlib.md5(content.encode("utf-8")).hexdigest()

    def check_feed_optimized(self, feed_state: FeedState) -> list[dict]:
        """V√©rifie un flux RSS avec optimisations HTTP"""
        try:
            headers = {}

            # Optimisations HTTP conditionnelles
            if feed_state.etag:
                headers["If-None-Match"] = feed_state.etag
            if feed_state.last_modified:
                headers["If-Modified-Since"] = feed_state.last_modified

            # Requ√™te HTTP avec timeout court
            response = self.session.get(feed_state.url, headers=headers, timeout=10)

            feed_state.last_check = datetime.now()
            self.stats["total_checks"] += 1

            # Gestion des codes de statut HTTP
            if response.status_code == 304:
                # Not Modified - aucun changement
                self.log(f"üîÑ Pas de changement: {feed_state.url[:50]}...")
                feed_state.consecutive_errors = 0
                return []

            if response.status_code != 200:
                raise Exception(f"HTTP {response.status_code}")

            # Mise √† jour des m√©tadonn√©es de cache
            feed_state.etag = response.headers.get("ETag")
            feed_state.last_modified = response.headers.get("Last-Modified")

            # V√©rification du hash du contenu
            content_hash = self.calculate_content_hash(response.text)
            if feed_state.last_content_hash == content_hash:
                self.log(f"üîÑ Contenu identique: {feed_state.url[:50]}...")
                feed_state.consecutive_errors = 0
                return []

            feed_state.last_content_hash = content_hash

            # Parsing RSS
            feed = feedparser.parse(response.text)

            if feed.bozo:
                self.log(f"‚ö†Ô∏è Feed mal form√©: {feed_state.url[:50]}...")

            # Filtrage des nouveaux articles - LOGIQUE SIMPLIFI√âE
            new_articles = []
            for entry in feed.entries:
                article_link = entry.get("link", "")

                # ‚úÖ CORRECTION : Ne v√©rifier que processed_articles (pas articles_cache)
                if article_link and article_link not in self.processed_articles:

                    # Marquer imm√©diatement comme trait√© pour √©viter les doublons
                    self.processed_articles.add(article_link)

                    # Extraction des m√©tadonn√©es
                    published_date = None
                    if hasattr(entry, "published_parsed") and entry.published_parsed:
                        published_date = datetime(*entry.published_parsed[:6])
                    elif hasattr(entry, "published"):
                        try:
                            published_date = parsedate_to_datetime(entry.published)
                        except Exception:
                            published_date = datetime.now()
                    else:
                        published_date = datetime.now()

                    article = {
                        "title": entry.get("title", "Titre non disponible"),
                        "link": article_link,
                        "published_date": published_date,
                        "summary": entry.get("summary", ""),
                        "source": feed_state.url,
                        "discovered_at": datetime.now(),
                    }

                    new_articles.append(article)

            # Succ√®s - reset des erreurs
            feed_state.consecutive_errors = 0

            if new_articles:
                self.log(
                    f"üéØ {len(new_articles)} VRAIS nouveaux articles d√©tect√©s sur {feed_state.url[:50]}...",
                    "DETECTION",
                )
                self.stats["new_articles_found"] += len(new_articles)

            return new_articles

        except Exception as e:
            feed_state.consecutive_errors += 1
            self.stats["errors"] += 1
            self.log(f"‚ùå Erreur sur {feed_state.url[:50]}: {e}")
            return []

    def store_article(self, article: dict):
        """Stocke un article dans la base de donn√©es"""
        try:
            conn = sqlite3.connect("berzerk.db")
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT OR IGNORE INTO articles
                (title, link, published_date, source, status, published_str)
                VALUES (?, ?, ?, ?, 'pending', ?)
            """,
                (
                    article["title"],
                    article["link"],
                    article["published_date"].isoformat(),
                    article["source"],
                    article.get(
                        "summary", "RSS Feed"
                    ),  # Utilise summary comme published_str
                ),
            )

            conn.commit()
            conn.close()

            if cursor.rowcount > 0:
                self.log(f"üíæ Article stock√©: {article['title'][:50]}...")

        except Exception as e:
            self.log(f"‚ùå Erreur stockage: {e}")

    def analyze_article_realtime(self, article: dict) -> dict | None:
        """Analyse un article en temps r√©el avec le pipeline BERZERK"""
        try:
            self.log(f"ü§ñ Analyse TEMPS R√âEL: {article['title'][:50]}...")

            # Lancement du pipeline complet
            result = run_berzerk_pipeline(article["link"], self.capital)

            if result and "final_decision" in result:
                # Sauvegarde de la d√©cision
                self.save_decision_to_db(article["link"], result["final_decision"])

                # Marquer comme trait√©
                self.processed_articles.add(article["link"])

                # Statistiques
                self.stats["analyses_completed"] += 1

                # Affichage du r√©sultat
                decision = result["final_decision"]
                action = decision.get("decision", "INCONNU")

                # --- D√âBUT DU TEMPLATE FINAL ---
                if action in ["LONG", "SHORT"]:
                    ticker = decision.get("ticker", "N/A")
                    prix_decision = decision.get("prix_a_la_decision", 0.0)
                    confiance = decision.get("confiance", "INCONNUE")
                    justification = decision.get("justification_synthetique", "N/A")
                    article_link = article["link"]

                    if action == "LONG":
                        signal_color = "üü¢"
                        action_label = "ACHAT (LONG)"
                    else: # SHORT
                        signal_color = "üî¥"
                        action_label = "VENTE (SHORT)"
                    
                    message = (
                        f"{signal_color} *NOUVEAU SIGNAL BERZERK*\n\n"
                        f"*{action_label}:* `{ticker}`\n"
                        f"-----------------------------------\n"
                        f"üí∞ *Prix d'Entr√©e:* `{prix_decision:.2f} $`\n"
                        f"üí™ *Confiance:* **{confiance.upper()}**\n\n"
                        f"> {justification}\n\n"
                        f"üì∞ [Lire l'article source]({article_link})"
                    )
                    send_telegram_notification(message)
                # --- FIN DU TEMPLATE FINAL ---

                if action in ["LONG", "ACHETER"]:  # Compatibilit√© avec anciennes donn√©es
                    self.log(
                        f"üöÄ SIGNAL LONG IDENTIFI√â: {article['title'][:50]}...", "SUCCESS"
                    )
                    ticker = decision.get("ticker_cible", "N/A")
                    allocation = decision.get("allocation_pourcentage", 0)
                    self.log(f"   üí∞ Ticker: {ticker}, Allocation: {allocation}%")
                elif action == "SURVEILLER":
                    self.log(f"üëÄ SURVEILLANCE: {article['title'][:50]}...")
                else:
                    self.log(f"‚úÖ Analyse termin√©e: {action}")

                return result
            else:
                self.log(f"‚ö†Ô∏è √âchec d'analyse: {article['title'][:50]}...")
                return None

        except Exception as e:
            self.log(f"‚ùå Erreur analyse temps r√©el: {e}")
            return None

    def save_decision_to_db(self, article_link: str, decision: dict):
        """Sauvegarde la d√©cision dans la base de donn√©es"""
        try:
            conn = sqlite3.connect("berzerk.db")
            cursor = conn.cursor()

            cursor.execute(
                """
                UPDATE articles
                SET decision_json = ?,
                    status = 'analyzed',
                    analyzed_at = ?
                WHERE link = ?
            """,
                (
                    json.dumps(decision, ensure_ascii=False),
                    datetime.now().isoformat(),
                    article_link,
                ),
            )

            conn.commit()
            conn.close()

        except Exception as e:
            self.log(f"‚ùå Erreur sauvegarde d√©cision: {e}")

    def monitoring_thread(self):
        """Thread principal de surveillance"""
        self.log("üîÑ Thread de surveillance d√©marr√©")

        while self.running:
            try:
                # V√©rifier chaque flux RSS
                for _feed_url, feed_state in self.feeds_state.items():
                    if not self.running:
                        break

                    # V√©rifier si le flux doit √™tre contr√¥l√©
                    if feed_state.should_check(self.poll_interval):
                        new_articles = self.check_feed_optimized(feed_state)

                        # Traiter les nouveaux articles
                        for article in new_articles:
                            if not self.running:
                                break

                            # Stockage en base
                            self.store_article(article)

                            # Analyse imm√©diate en arri√®re-plan
                            threading.Thread(
                                target=self.analyze_article_realtime,
                                args=(article,),
                                daemon=True,
                            ).start()

                # Pause courte avant le prochain cycle
                time.sleep(1)

            except Exception as e:
                self.log(f"‚ùå Erreur dans le thread de surveillance: {e}")
                time.sleep(5)  # Pause plus longue en cas d'erreur

        self.log("üõë Thread de surveillance arr√™t√©")

    def display_stats(self):
        """Affiche les statistiques en temps r√©el"""
        uptime = datetime.now() - self.stats["start_time"]

        print("\n" + "=" * 50)
        print("üìä STATISTIQUES TEMPS R√âEL")
        print("=" * 50)
        print(f"‚è±Ô∏è  Uptime: {uptime}")
        print(f"üîÑ V√©rifications totales: {self.stats['total_checks']}")
        print(f"üìà Nouveaux articles: {self.stats['new_articles_found']}")
        print(f"ü§ñ Analyses compl√®tes: {self.stats['analyses_completed']}")
        print(f"‚ùå Erreurs: {self.stats['errors']}")
        print(f"üíæ Articles en cache: {len(self.processed_articles)}")
        print("=" * 50)

    def start(self):
        """D√©marre la surveillance temps r√©el"""
        self.log("üöÄ D√âMARRAGE DE LA SURVEILLANCE TEMPS R√âEL", "SUCCESS")
        self.log(f"‚ö° Polling: {self.poll_interval} secondes")
        self.log("‚èπÔ∏è  Arr√™t: Ctrl+C")

        # Initialiser la base de donn√©es
        init_db()

        # D√©marrer le thread de surveillance
        self.running = True
        monitor_thread = threading.Thread(target=self.monitoring_thread, daemon=True)
        monitor_thread.start()

        try:
            # Boucle principale avec affichage des stats
            while True:
                time.sleep(30)  # Afficher les stats toutes les 30 secondes
                self.display_stats()

        except KeyboardInterrupt:
            self.log("üõë Arr√™t demand√© par l'utilisateur", "WARNING")
        finally:
            self.running = False
            self.log("üëã Surveillance temps r√©el arr√™t√©e", "SUCCESS")
            self.display_stats()


def main():
    """Point d'entr√©e principal"""
    # Configuration par d√©faut
    poll_interval = 30  # 30 secondes par d√©faut
    capital = 25000.0

    # Parsing des arguments
    if len(sys.argv) > 1:
        try:
            poll_interval = int(sys.argv[1])
            if poll_interval < 10:
                raise ValueError("L'intervalle doit √™tre d'au moins 10 secondes")
        except ValueError as e:
            print(f"‚ùå Erreur: {e}")
            print("üí° Usage: python real_time_rss_monitor.py [poll_interval_seconds]")
            print("üìä Exemple: python real_time_rss_monitor.py 30")
            sys.exit(1)

    print("üöÄ BERZERK Real-Time RSS Monitor")
    print("‚ö° Surveillance quasi-instantan√©e avec polling optimis√©")
    print(f"üîÑ Intervalle: {poll_interval} secondes")
    print("-" * 70)

    # Lancement du monitor
    monitor = RealTimeRSSMonitor(poll_interval, capital)
    monitor.start()


if __name__ == "__main__":
    main()
</file>

<file path="reset_and_analyze.py">
#!/usr/bin/env python3
"""
üßπ BERZERK RESET & ANALYZE - Nettoyage et Relance des Analyses
==============================================================

Ce script nettoie les anciennes analyses et relance les 20 derni√®res
news avec les nouveaux agents augment√©s (Phase 5).
"""

import json
import sqlite3
from datetime import datetime

from orchestrator import run_berzerk_pipeline, send_telegram_notification


def reset_analyses():
    """
    Nettoie les anciennes analyses de la base de donn√©es
    """
    print("üßπ Nettoyage des anciennes analyses...")

    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()

    # Remettre √† z√©ro les analyses
    cursor.execute(
        """
        UPDATE articles
        SET decision_json = NULL,
            status = "pending",
            analyzed_at = NULL
        WHERE decision_json IS NOT NULL
    """
    )

    updated = cursor.rowcount
    conn.commit()

    # Compter les articles en attente
    cursor.execute('SELECT COUNT(*) FROM articles WHERE status = "pending"')
    pending = cursor.fetchone()[0]

    conn.close()

    print(f"‚úÖ {updated} anciennes analyses supprim√©es")
    print(f"üìù {pending} articles en attente d'analyse")

    return pending


def get_latest_articles(limit=10):
    """
    R√©cup√®re les derniers articles en attente
    """
    print(f"üîç R√©cup√©ration des {limit} derniers articles...")

    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()

    cursor.execute(
        """
        SELECT id, title, link, published_date
        FROM articles
        WHERE status = "pending"
        ORDER BY published_date DESC
        LIMIT ?
    """,
        (limit,),
    )

    articles = cursor.fetchall()
    conn.close()

    print(f"‚úÖ {len(articles)} articles r√©cup√©r√©s")
    return articles


def save_decision_to_db(article_id: int, decision_result: dict) -> bool:
    """
    Sauvegarde une d√©cision d'investissement dans la base de donn√©es.
    """
    try:
        conn = sqlite3.connect("berzerk.db")
        cursor = conn.cursor()

        # On r√©cup√®re l'objet de d√©cision final, qui contient d√©j√† tout (y compris le prix)
        final_decision = decision_result.get("final_decision", {})

        if not final_decision:
            print("‚ùå Aucune d√©cision finale trouv√©e √† sauvegarder.")
            return False

        # On sauvegarde directement l'objet complet sans le reconstruire
        cursor.execute(
            """
            UPDATE articles
            SET decision_json = ?,
                status = "analyzed",
                analyzed_at = ?
            WHERE id = ?
            """,
            (json.dumps(final_decision), datetime.now().isoformat(), article_id),
        )

        conn.commit()
        conn.close()
        return True

    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde: {e}")
        return False


def analyze_articles(articles):
    """
    Lance l'analyse des articles avec les nouveaux agents augment√©s
    """
    print("üöÄ Lancement des analyses avec les agents augment√©s...")
    print("-" * 60)

    successful_analyses = 0
    failed_analyses = 0
    saved_decisions = 0

    for i, (article_id, title, link, _published_date) in enumerate(articles, 1):
        print(f"\nüî¨ [{i}/{len(articles)}] Analyse: {title[:50]}...")

        try:
            # Simuler un capital de test
            capital = 10000

            # Lancer le pipeline BERZERK complet
            result = run_berzerk_pipeline(link, capital)

            if result and not result.get("error"):
                successful_analyses += 1
                print("‚úÖ Analyse termin√©e avec succ√®s")

                # Sauvegarder la d√©cision dans la base de donn√©es
                if save_decision_to_db(article_id, result):
                    saved_decisions += 1
                    print("üíæ D√©cision sauvegard√©e dans la base de donn√©es")

                    # Afficher la d√©cision si disponible
                    if result.get("final_decision"):
                        decision = result["final_decision"]
                        action = decision.get("decision", "N/A")
                        ticker = decision.get("ticker", "N/A")
                        allocation = decision.get("allocation_capital_pourcentage", 0)
                        print(f"üéØ D√©cision: {action} {ticker} ({allocation}%)")

                        # --- D√âBUT DU TEMPLATE FINAL ---
                        if action in ["LONG", "SHORT"]:
                            ticker = decision.get("ticker", "N/A")
                            prix_decision = decision.get("prix_a_la_decision", 0.0)
                            confiance = decision.get("confiance", "INCONNUE")
                            justification = decision.get("justification_synthetique", "N/A")
                            article_link = link

                            if action == "LONG":
                                signal_color = "üü¢"
                                action_label = "ACHAT (LONG)"
                            else: # SHORT
                                signal_color = "üî¥"
                                action_label = "VENTE (SHORT)"
                            
                            message = (
                                f"{signal_color} *SIGNAL DE TEST (RESET) BERZERK*\n\n"
                                f"*{action_label}:* `{ticker}`\n"
                                f"-----------------------------------\n"
                                f"üí∞ *Prix d'Entr√©e:* `{prix_decision:.2f} $`\n"
                                f"üí™ *Confiance:* **{confiance.upper()}**\n\n"
                                f"> {justification}\n\n"
                                f"üì∞ [Lire l'article source]({article_link})"
                            )
                            send_telegram_notification(message)
                        # --- FIN DU TEMPLATE FINAL ---
                else:
                    print("‚ùå √âchec de la sauvegarde")
            else:
                failed_analyses += 1
                print(
                    f"‚ùå √âchec de l'analyse: {result.get('error', 'Erreur inconnue')}"
                )

        except Exception as e:
            failed_analyses += 1
            print(f"‚ùå Erreur lors de l'analyse: {e}")

    print("\nüìä R√âSULTATS DES ANALYSES")
    print("-" * 30)
    print(f"‚úÖ Analyses r√©ussies: {successful_analyses}")
    print(f"üíæ D√©cisions sauvegard√©es: {saved_decisions}")
    print(f"‚ùå Analyses √©chou√©es: {failed_analyses}")
    print(f"üìà Taux de r√©ussite: {(successful_analyses / len(articles)) * 100:.1f}%")

    return successful_analyses


def main():
    """
    Fonction principale
    """
    print("üéØ BERZERK RESET & ANALYZE")
    print("=" * 50)

    # √âtape 1: Nettoyer les anciennes analyses
    pending_count = reset_analyses()

    if pending_count == 0:
        print("‚ö†Ô∏è  Aucun article en attente d'analyse")
        return

    # √âtape 2: R√©cup√©rer les derniers articles
    articles = get_latest_articles(20)

    if not articles:
        print("‚ùå Aucun article trouv√©")
        return

    # √âtape 3: Analyser les articles
    successful = analyze_articles(articles)

    print("\nüèÅ TERMIN√â !")
    print(f"üìä {successful} nouvelles analyses avec agents augment√©s")
    print("üí° Vous pouvez maintenant relancer: python backtester.py")


if __name__ == "__main__":
    main()
</file>

<file path="suivi_projet.md">
# Suivi Projet BERZERK

## 1. Description G√©n√©rale
Objectif : Orchestration automatis√©e de d√©cisions d'investissement IA avec tra√ßabilit√© et suivi de performance. Capture robuste du prix √† la d√©cision, stockage, et affichage comparatif dans le dashboard.

## 2. Plan de T√¢ches
- [x] Fonction robuste de capture de prix en temps r√©el (`get_live_price`) avec fallback multi-niveaux et logs WARN.
- [x] Int√©gration de la capture du prix exact dans `node_final_investor_decision` (orchestrator.py).
- [x] Ajout de la cl√© `prix_a_la_decision` dans la structure de d√©cision.
- [x] Lecture et affichage du prix √† la d√©cision dans le dashboard (`berzerk_dashboard.py`).
- [x] Affichage conditionnel de la performance et gestion des cas N/A.

## 3. Journal des Modifications
- 2024-05-07 : Ajout de `get_live_price` robuste (fallback intraday, info, historique, gestion exceptions).
- 2024-05-07 : Enrichissement de la d√©cision avec le prix captur√© dans `node_final_investor_decision`.
- 2024-05-07 : Lecture de la cl√© `prix_a_la_decision` dans `load_decisions_from_db` et affichage dans `display_decision_card` et `display_active_portfolio`.
- 2024-05-07 : Affichage conditionnel et aide utilisateur pour les cas o√π le prix n'est pas disponible.

## 4. Suivi des Erreurs
- Si le prix n'est pas captur√© (0.0), affichage WARN dans la console et "N/A" dans le dashboard avec explication.
- Robustesse assur√©e par gestion d'exceptions √† chaque √©tape de r√©cup√©ration de prix.

## 5. R√©sultats des Tests
- Test manuel sur tickers valides et invalides : prix captur√© ou fallback, logs WARN visibles.
- Dashboard affiche correctement prix √† la d√©cision, prix actuel, performance ou "N/A".

## 6. Documentation Consult√©e
- [yfinance - Doc officielle](https://github.com/ranaroussi/yfinance)
- [Streamlit st.metric](https://docs.streamlit.io/library/api-reference/data/st.metric)

## 7. Structure du Projet (extrait)
- orchestrator.py : logique de d√©cision, capture prix
- berzerk_dashboard.py : affichage, calculs de performance
- suivi_projet.md : documentation centrale

## 8. R√©flexions & D√©cisions
- Approche multi-fallback pour la robustesse de la capture de prix.
- Ajout syst√©matique de logs pour la tra√ßabilit√©.
- Affichage UX-friendly pour les cas d'indisponibilit√© de prix.
- Compatibilit√© ascendante assur√©e (cl√© absente = 0.0, affichage N/A).
</file>

<file path="agents.py">
"""
Module d'Agents IA Sp√©cialis√©s pour le Projet BERZERK
====================================================

Ce module contient une √©quipe d'agents IA sp√©cialis√©s pour analyser les news financi√®res
sous diff√©rents angles. Chaque agent a une expertise unique et apporte sa perspective
√† l'analyse globale.

Auteur: BERZERK Team
Phase: 2 - Agents IA Sp√©cialis√©s
"""

import yfinance as yf
from dotenv import load_dotenv
from langchain.agents import AgentExecutor, create_tool_calling_agent

# Imports pour les outils
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.tools import tool

# LangChain Imports
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import BaseModel, Field

# --- CONFIGURATION & SETUP ---
load_dotenv()

# Initialisation du LLM avec temp√©rature plus √©lev√©e pour la personnalit√© des agents
try:
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-lite-preview-06-17",
        temperature=0.3,
        # Le param√®tre convert_system_message_to_human est maintenant g√©r√© automatiquement
    )
    print("‚úÖ LLM initialis√© avec succ√®s pour les agents IA")
except Exception as e:
    print(f"‚ùå Erreur d'initialisation du LLM pour les agents: {e}")
    llm = None

# --- OUTILS POUR AGENTS AUGMENT√âS ---

# 1. Outil de recherche web avec Tavily
try:
    web_search_tool = TavilySearchResults(
        max_results=3,  # Limiter pour √©viter la surcharge d'informations
        search_depth="basic",  # Recherche basique pour √™tre plus rapide
    )
    print("‚úÖ Outil de recherche web (Tavily) initialis√©")
except Exception as e:
    print(f"‚ùå Erreur d'initialisation de Tavily: {e}")
    web_search_tool = None


# 2. Outil de donn√©es financi√®res avec yfinance
@tool
def get_stock_price(ticker: str) -> str:
    """R√©cup√®re le prix actuel et la variation journali√®re pour un ticker donn√©."""
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="2d")  # 2 jours pour calculer la variation
        if hist.empty:
            return f"‚ùå Donn√©es non trouv√©es pour {ticker}"

        # Prix actuel (derni√®re cl√¥ture)
        current_price = hist["Close"].iloc[-1]

        # Variation par rapport √† la veille
        if len(hist) >= 2:
            previous_price = hist["Close"].iloc[-2]
            change_percent = ((current_price - previous_price) / previous_price) * 100
            change_symbol = (
                "üìà" if change_percent > 0 else "üìâ" if change_percent < 0 else "‚û°Ô∏è"
            )

            return f"üí∞ {ticker}: {current_price:.2f} USD {change_symbol} {change_percent:+.2f}% vs hier"
        else:
            return f"üí∞ {ticker}: {current_price:.2f} USD (variation non disponible)"

    except Exception as e:
        return f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es pour {ticker}: {str(e)}"


@tool
def get_market_sentiment(ticker: str) -> str:
    """R√©cup√®re des informations sur le sentiment du march√© pour un ticker."""
    try:
        stock = yf.Ticker(ticker)
        info = stock.info

        # Informations cl√©s
        market_cap = info.get("marketCap", "N/A")
        pe_ratio = info.get("trailingPE", "N/A")
        volume = info.get("averageVolume", "N/A")

        # Formatage des grandes valeurs
        if isinstance(market_cap, int | float):
            if market_cap > 1e12:
                market_cap_str = f"{market_cap/1e12:.1f}T USD"
            elif market_cap > 1e9:
                market_cap_str = f"{market_cap/1e9:.1f}B USD"
            else:
                market_cap_str = f"{market_cap/1e6:.1f}M USD"
        else:
            market_cap_str = "N/A"

        return (
            f"üìä {ticker} - Cap: {market_cap_str} | P/E: {pe_ratio} | Volume moy: {volume:,}"
            if isinstance(volume, int)
            else f"üìä {ticker} - Cap: {market_cap_str} | P/E: {pe_ratio} | Volume moy: {volume}"
        )

    except Exception as e:
        return f"‚ùå Erreur sentiment march√© pour {ticker}: {str(e)}"


print("‚úÖ Outils financiers (yfinance) initialis√©s")

# --- MOD√àLES PYDANTIC POUR LA VALIDATION ---


class AgentSelection(BaseModel):
    """Mod√®le pour la s√©lection d'agents par le routeur."""

    agents: list[dict[str, str]] = Field(
        description="Liste des agents s√©lectionn√©s avec leur type et focus"
    )


class TickerIdentification(BaseModel):
    """Mod√®le pour la sortie de l'agent Ticker Hunter."""

    ticker: str = Field(description="Symbole boursier de l'entreprise")
    nom_entreprise: str = Field(description="Nom complet de l'entreprise")
    justification_impact: str = Field(
        description="Justification de l'impact sur cette entreprise"
    )


class TickerHunterResult(BaseModel):
    """Mod√®le pour la sortie compl√®te de l'agent Ticker Hunter."""

    tickers_identifies: list[TickerIdentification] = Field(
        description="Liste des tickers identifi√©s avec leurs justifications"
    )


# --- PROFILS D'AGENTS SP√âCIALIS√âS ---

# Ticker Hunter - Agent sp√©cialis√© dans l'identification de tickers actionnables
ticker_hunter_template = PromptTemplate(
    input_variables=["news_summary", "full_article_text"],
    template="""
Tu es "The Ticker Hunter", un analyste financier redoutable pour le fonds BERZERK. Ta seule et unique mission est d'identifier des opportunit√©s de trading actionnables √† partir d'informations. Tu ignores les concepts vagues et tu te concentres sur les entreprises cot√©es.

Analyse le r√©sum√© et le texte complet de l'article ci-dessous.

**R√©sum√© :**
{news_summary}

**Texte Complet :**
{full_article_text}

---
**TACHE :**
Identifie les 1 √† 5 entreprises cot√©es en bourse (et leurs tickers boursiers) les plus directement et significativement impact√©es par cette news.
Pour chaque entreprise, fournis une justification concise expliquant POURQUOI elle est impact√©e.

R√©ponds IMP√âRATIVEMENT au format JSON suivant, et rien d'autre. Si aucune action n'est clairement identifiable, retourne une liste vide.

{{
    "tickers_identifies": [
        {{
            "ticker": "AAPL",
            "nom_entreprise": "Apple Inc.",
            "justification_impact": "L'article mentionne des probl√®mes dans la cha√Æne d'approvisionnement des iPhones en Chine."
        }},
        {{
            "ticker": "QCOM",
            "nom_entreprise": "Qualcomm",
            "justification_impact": "En tant que fournisseur cl√© d'Apple, Qualcomm serait directement affect√© par un ralentissement de la production."
        }}
    ]
}}

**R√àGLES CRITIQUES ABSOLUES :**
- **FORMAT :** Le ticker est une cha√Æne de 1 √† 5 lettres MAJUSCULES, parfois suivi d'un point et d'un suffixe de march√© (ex: .PA, .DE). Exemples de tickers valides: 'AAPL', 'MSFT', 'AIR.PA'.
- **INTERDIT :** Le ticker ne doit JAMAIS contenir de '$', d'espaces, de minuscules, ou √™tre une phrase descriptive. 'CRYPTO_INDEX' ou '$TSLA' sont INVALIDE.
- **INTERDIT :** Ne retourne jamais un nom de place de march√© (ex: 'XETRA', 'NASDAQ') ou un indice (ex: 'S&P 500') comme ticker.
- **SOURCE :** Uniquement des entreprises cot√©es sur des bourses majeures (NYSE, NASDAQ, Euronext, etc.).
- **FOCUS :** Si la news parle d'une entreprise non cot√©e (ex: Discord, une startup), tu ne dois PAS l'identifier. Ta mission est de trouver des tickers **tradables**.
- **SI AUCUN TICKER VALIDE :** Retourne imp√©rativement une liste vide `[]`. Ne tente pas d'inventer un ticker.
- **V√âRIFICATION :** Avant de proposer un ticker, assure-toi mentalement qu'il correspond √† une entreprise sp√©cifique et non √† un concept g√©n√©ral ou une place de march√©. V√©rifie qu'il existe r√©ellement en bourse.
- Impact direct et mesurable sur le business
- Justification factuelle bas√©e sur le contenu de l'article
- Maximum 5 tickers pour rester focus
""",
)

# Analyste Actions - Sp√©cialis√© dans l'analyse d'actions individuelles
analyste_actions_template = PromptTemplate(
    input_variables=["focus", "news_summary", "full_article_text"],
    template="""
Tu es un Analyste Financier Senior sp√©cialis√© en actions pour le fonds d'investissement BERZERK.

**Ton Focus Exclusif : L'action {focus}.**

Ta mission est d'√©valuer l'impact d'une nouvelle sur cette action sp√©cifique. Ignore les autres aspects.
Tu dois analyser avec pr√©cision l'impact potentiel sur le cours de l'action, les volumes, et les perspectives.

R√©sum√© de la news :
{news_summary}

Texte complet de l'article :
{full_article_text}

---
Produis une analyse concise au format Markdown avec les sections suivantes :

### üéØ √âvaluation sur {focus}
- **Sentiment :** (Positif, N√©gatif, Neutre)
- **Impact (1-10) :** (Note l'impact potentiel sur le cours de l'action)
- **Justification :** (Explique ton raisonnement en 2-3 phrases claires, en te basant sur des faits de l'article.)

### üìä Analyse Technique
- **Catalyseurs identifi√©s :** (√âl√©ments qui pourraient faire bouger le cours)
- **Risques potentiels :** (√âl√©ments n√©gatifs √† surveiller)

### üéØ Recommandation d'Action
- **Horizon :** (Court Terme, Moyen Terme, Long Terme)
- **Action :** (Surveiller, Renforcer la position, All√©ger la position, Ne rien faire)
- **Niveau de confiance :** (Faible, Moyen, √âlev√©)
""",
)

# Analyste Sectoriel - Sp√©cialis√© dans l'analyse de secteurs d'activit√©
analyste_sectoriel_template = PromptTemplate(
    input_variables=["focus", "news_summary", "full_article_text"],
    template="""
Tu es un Analyste Sectoriel Expert pour le fonds d'investissement BERZERK.

**Ton Focus Exclusif : Le secteur {focus}.**

Ta mission est d'analyser l'impact d'une nouvelle sur l'ensemble du secteur. Tu dois identifier les tendances,
les dynamiques concurrentielles et les implications pour toutes les entreprises du secteur.

R√©sum√© de la news :
{news_summary}

Texte complet de l'article :
{full_article_text}

---
Produis une analyse sectorielle au format Markdown avec les sections suivantes :

### üè≠ Impact Sectoriel sur {focus}
- **Sentiment Global :** (Positif, N√©gatif, Neutre)
- **Ampleur d'Impact (1-10) :** (Note l'impact sur l'ensemble du secteur)
- **Justification :** (Explique les m√©canismes d'impact sur le secteur)

### üîÑ Dynamiques Concurrentielles
- **Gagnants potentiels :** (Quelles entreprises/sous-secteurs pourraient b√©n√©ficier)
- **Perdants potentiels :** (Quelles entreprises/sous-secteurs pourraient souffrir)
- **Changements structurels :** (√âvolutions durables attendues)

### üéØ Implications Strat√©giques
- **Opportunit√©s d'investissement :** (Nouvelles opportunit√©s cr√©√©es)
- **Risques sectoriels :** (Nouveaux risques √† surveiller)
- **Horizon temporel :** (Court/Moyen/Long terme pour les impacts)
""",
)

# Strat√©giste G√©opolitique - Sp√©cialis√© dans l'analyse g√©opolitique et macro√©conomique
strategiste_geopolitique_template = PromptTemplate(
    input_variables=["focus", "news_summary", "full_article_text"],
    template="""
Tu es un Strat√©giste G√©opolitique Senior pour le fonds d'investissement BERZERK.

**Ton Focus Exclusif : {focus}.**

Ta mission est d'analyser les implications g√©opolitiques et macro√©conomiques d'une nouvelle.
Tu dois identifier les ramifications sur les relations internationales, les politiques √©conomiques,
et les flux de capitaux mondiaux.

R√©sum√© de la news :
{news_summary}

Texte complet de l'article :
{full_article_text}

---
Produis une analyse g√©opolitique au format Markdown avec les sections suivantes :

### üåç Analyse G√©opolitique : {focus}
- **Sentiment G√©opolitique :** (Stabilisant, D√©stabilisant, Neutre)
- **Niveau de Risque (1-10) :** (Impact sur la stabilit√© g√©opolitique)
- **Justification :** (Explique les m√©canismes g√©opolitiques en jeu)

### üó∫Ô∏è Implications R√©gionales
- **R√©gions affect√©es :** (Zones g√©ographiques principales concern√©es)
- **Acteurs cl√©s :** (Pays, institutions, alliances impliqu√©s)
- **Tensions potentielles :** (Nouveaux conflits ou r√©solutions possibles)

### üí∞ Impact sur les March√©s
- **Devises affect√©es :** (Monnaies qui pourraient √™tre impact√©es)
- **Secteurs sensibles :** (Industries particuli√®rement expos√©es)
- **Flux de capitaux :** (R√©allocations d'investissement attendues)

### üéØ Recommandations Strat√©giques
- **Positionnement recommand√© :** (D√©fensif, Offensif, Neutre)
- **Horizon d'impact :** (Court/Moyen/Long terme)
- **Indicateurs √† surveiller :** (Signaux d'alerte ou d'opportunit√©)
""",
)

# Agent Investisseur Final - Le superviseur qui prend la d√©cision finale
investisseur_final_template = PromptTemplate(
    input_variables=["debriefing_equipe", "capital_disponible", "actionable_tickers"],
    template="""
Tu es l'Agent Investisseur en chef du fonds BERZERK. Tu es froid, logique, et uniquement guid√© par la performance et la gestion du risque.

Ta mission est de prendre la d√©cision finale d'investissement bas√©e sur le rapport consolid√© de ton √©quipe d'analystes sp√©cialis√©s.

**Tickers Identifi√©s par le Ticker Hunter :**
{actionable_tickers}

**Rapport de l'√âquipe d'Analystes :**
---
{debriefing_equipe}
---

**Contexte Financier Actuel :**
- Capital total disponible pour de nouveaux trades : {capital_disponible} ‚Ç¨

**TACHE FINALE :**
Sur la base EXCLUSIVE des informations ci-dessus, produis une d√©cision d'investissement structur√©e au format JSON. Ne rien ajouter d'autre.

**NOUVELLE R√àGLE STRAT√âGIQUE :**
- Si plusieurs analyses d'actions sont positives (par exemple, plusieurs recommandations d'ACHAT), ta mission est de **s√©lectionner la MEILLEURE et UNIQUE opportunit√©**. Compare la clart√© du signal, la conviction de l'analyse et l'impact direct de la news. Justifie bri√®vement ton choix dans la `justification_synthetique`. Ignore les autres opportunit√©s.

**PRIORIT√â :** Concentre-toi sur les tickers sp√©cifiques identifi√©s par le Ticker Hunter. Ignore les analyses macro g√©n√©rales.

Le format JSON doit contenir les cl√©s suivantes :
- "decision": "LONG" (pari sur la hausse), "SHORT" (pari sur la baisse), "SURVEILLER" ou "IGNORER".
- "ticker": Le ticker de l'action **s√©lectionn√©e** (string, ou null si IGNORER).
- "confiance": "√âLEV√âE", "MOYENNE", "FAIBLE" (string).
- "horizon": "Court Terme", "Moyen Terme", ou "Long Terme". D√âDUIS-LE du rapport.
- "justification_synthetique": Une phrase unique et directe expliquant la d√©cision.
- "allocation_capital_pourcentage": Le pourcentage du capital disponible √† allouer √† ce trade (nombre flottant, de 0.0 √† 5.0). Allouer 0 si la d√©cision n'est pas "LONG". Une allocation typique pour une confiance MOYENNE est 1%, √âLEV√âE est 2-3%.
- "points_cles_positifs": Une liste de 2-3 points cl√©s positifs tir√©s du rapport.
- "points_cles_negatifs_risques": Une liste de 2-3 risques ou points n√©gatifs tir√©s du rapport.
""",
)

# Dictionnaire des profils d'agents
AGENT_PROFILES = {
    "ticker_hunter": ticker_hunter_template,
    "analyste_actions": analyste_actions_template,
    "analyste_sectoriel": analyste_sectoriel_template,
    "strategiste_geopolitique": strategiste_geopolitique_template,
    "investisseur_final": investisseur_final_template,
}

# --- FONCTIONS PRINCIPALES ---


def route_to_agents(entities: list[str], news_summary: str) -> list[dict[str, str]]:
    """
    Routeur intelligent qui s√©lectionne les agents appropri√©s selon les entit√©s d√©tect√©es.

    Args:
        entities: Liste des entit√©s d√©tect√©es (tickers, secteurs, concepts)
        news_summary: R√©sum√© de la news

    Returns:
        Liste de dictionnaires avec agent_type et focus pour chaque agent s√©lectionn√©
    """
    if not llm:
        print("‚ùå LLM non disponible pour le routage")
        return []

    # Prompt pour le routeur intelligent
    router_template = PromptTemplate(
        input_variables=["entities", "news_summary", "available_agents"],
        template="""
Tu es le Chef d'Orchestre du syst√®me d'analyse BERZERK. Ta mission est de s√©lectionner
la meilleure √©quipe d'agents IA pour analyser une news financi√®re.

**Agents disponibles :**
{available_agents}

**Entit√©s d√©tect√©es dans la news :**
{entities}

**R√©sum√© de la news :**
{news_summary}

**Instructions :**
1. Analyse les entit√©s et le contenu de la news
2. S√©lectionne 1 √† 3 agents maximum (√©vite la redondance)
3. Pour chaque agent, d√©finis un focus pr√©cis bas√© sur les entit√©s

**Crit√®res de s√©lection :**
- **analyste_actions** : Si des tickers d'actions sp√©cifiques sont mentionn√©s (ex: AAPL, TSLA)
- **analyste_sectoriel** : Si des secteurs d'activit√© sont concern√©s (ex: Tech, Pharma, √ânergie)
- **strategiste_geopolitique** : Si des aspects g√©opolitiques, mon√©taires ou macro√©conomiques sont pr√©sents

**Format de r√©ponse attendu (JSON strict) :**
{{
    "agents": [
        {{"agent_type": "analyste_actions", "focus": "AAPL"}},
        {{"agent_type": "analyste_sectoriel", "focus": "Technologie"}},
        {{"agent_type": "strategiste_geopolitique", "focus": "Relations commerciales USA-Chine"}}
    ]
}}

Assure-toi que chaque focus soit sp√©cifique et pertinent pour l'agent s√©lectionn√©.
""",
    )

    try:
        # Pr√©paration des donn√©es
        available_agents = """
- analyste_actions : Analyse d'actions individuelles et de tickers sp√©cifiques
- analyste_sectoriel : Analyse de secteurs d'activit√© et industries
- strategiste_geopolitique : Analyse g√©opolitique et macro√©conomique
"""

        # Configuration du parser JSON
        parser = JsonOutputParser(pydantic_object=AgentSelection)

        # Cr√©ation de la cha√Æne LangChain
        chain = router_template | llm | parser

        # Ex√©cution du routage
        result = chain.invoke(
            {
                "entities": ", ".join(entities),
                "news_summary": news_summary,
                "available_agents": available_agents,
            }
        )

        selected_agents = result.get("agents", [])
        print(f"‚úÖ Routeur : {len(selected_agents)} agent(s) s√©lectionn√©(s)")

        return selected_agents

    except Exception as e:
        print(f"‚ùå Erreur dans le routage des agents: {e}")
        # Fallback : s√©lection basique bas√©e sur les entit√©s
        fallback_agents = []

        # Recherche de tickers (g√©n√©ralement en majuscules, 2-5 caract√®res)
        tickers = [
            entity for entity in entities if entity.isupper() and 2 <= len(entity) <= 5
        ]
        if tickers:
            fallback_agents.append(
                {"agent_type": "analyste_actions", "focus": tickers[0]}
            )

        # Recherche de secteurs (mots-cl√©s courants)
        secteurs = [
            "tech",
            "technologie",
            "√©nergie",
            "finance",
            "sant√©",
            "pharma",
            "automobile",
        ]
        for entity in entities:
            if any(secteur in entity.lower() for secteur in secteurs):
                fallback_agents.append(
                    {"agent_type": "analyste_sectoriel", "focus": entity}
                )
                break

        return fallback_agents


def run_agent_analysis(
    agent_type: str, focus: str, news_summary: str, full_article_text: str
) -> str:
    """
    Ex√©cute l'analyse d'un agent sp√©cifique.

    Args:
        agent_type: Type d'agent (cl√© du dictionnaire AGENT_PROFILES)
        focus: Focus sp√©cifique pour l'analyse
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article

    Returns:
        Analyse format√©e en Markdown ou message d'erreur
    """
    if not llm:
        return "‚ùå **Erreur :** LLM non disponible pour l'analyse"

    if agent_type not in AGENT_PROFILES:
        return f"‚ùå **Erreur :** Agent '{agent_type}' non reconnu"

    try:
        # R√©cup√©ration du template de l'agent
        agent_prompt = AGENT_PROFILES[agent_type]

        # Cr√©ation de la cha√Æne LangChain
        chain = agent_prompt | llm

        # Ex√©cution de l'analyse
        analysis_result = chain.invoke(
            {
                "focus": focus,
                "news_summary": news_summary,
                "full_article_text": full_article_text,
            }
        )

        print(f"‚úÖ Analyse termin√©e - Agent: {agent_type}, Focus: {focus}")
        return (
            analysis_result.content
            if hasattr(analysis_result, "content")
            else str(analysis_result)
        )

    except Exception as e:
        error_msg = f"‚ùå **Erreur lors de l'analyse** - Agent: {agent_type}, Focus: {focus}\n**D√©tail:** {str(e)}"
        print(error_msg)
        return error_msg


def run_ticker_hunter(
    news_summary: str, full_article_text: str
) -> dict[str, list[dict]]:
    """
    Ex√©cute l'agent Ticker Hunter pour identifier les tickers actionnables.

    Args:
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article

    Returns:
        Dictionnaire avec la liste des tickers identifi√©s
    """
    if not llm:
        print("‚ùå LLM non disponible pour le Ticker Hunter")
        return {"tickers_identifies": []}

    try:
        # Configuration du parser JSON avec validation Pydantic
        parser = JsonOutputParser(pydantic_object=TickerHunterResult)

        # R√©cup√©ration du template du Ticker Hunter
        ticker_hunter_prompt = AGENT_PROFILES["ticker_hunter"]

        # Cr√©ation de la cha√Æne LangChain
        chain = ticker_hunter_prompt | llm | parser

        # Ex√©cution de l'analyse
        result = chain.invoke(
            {"news_summary": news_summary, "full_article_text": full_article_text}
        )

        tickers_bruts = result.get("tickers_identifies", [])
        
        # --- D√âBUT DE LA MODIFICATION : VALIDATION ET NETTOYAGE ---
        tickers_valides = []
        if tickers_bruts:
            print(f"üî¨ Ticker Hunter a retourn√© {len(tickers_bruts)} ticker(s) bruts. Validation en cours...")
            for ticker_info in tickers_bruts:
                ticker = ""
                # G√©rer les objets Pydantic et les dictionnaires
                if hasattr(ticker_info, "ticker"):
                    ticker = ticker_info.ticker
                else:
                    ticker = ticker_info.get("ticker", "")
                
                # 1. Nettoyage initial : supprimer les '$' et les espaces
                ticker_nettoye = ticker.strip().replace("$", "")
                
                # 2. Validation du format : lettres majuscules, points autoris√©s, longueur
                import re
                if re.match(r"^[A-Z]{1,6}(\.[A-Z]{2})?$", ticker_nettoye):
                    # Le format est plausible, on le garde
                    # On met √† jour le ticker dans le dictionnaire/objet
                    if hasattr(ticker_info, "ticker"):
                        ticker_info.ticker = ticker_nettoye
                    else:
                        ticker_info['ticker'] = ticker_nettoye
                    tickers_valides.append(ticker_info)
                    print(f"    ‚úÖ Ticker valide trouv√© : {ticker_nettoye}")
                else:
                    print(f"    ‚ùå Ticker invalide rejet√© : '{ticker}'")
        
        result['tickers_identifies'] = tickers_valides
        # --- FIN DE LA MODIFICATION ---

        print(f"üéØ Ticker Hunter : {len(tickers_valides)} ticker(s) final(aux) apr√®s validation.")
        
        return result

    except Exception as e:
        print(f"‚ùå Erreur dans le Ticker Hunter: {e}")
        return {"tickers_identifies": []}


# --- AGENTS AUGMENT√âS (AVEC OUTILS) ---


def create_augmented_analyst(focus_ticker: str = None) -> AgentExecutor:
    """
    Cr√©e un agent analyste augment√© avec acc√®s √† des outils web et financiers.

    Args:
        focus_ticker: Ticker √† analyser en priorit√© (optionnel)

    Returns:
        AgentExecutor configur√© avec les outils
    """
    if not llm:
        raise ValueError("LLM non disponible pour cr√©er l'agent augment√©")

    # D√©finition des outils disponibles
    tools = []

    # Ajout des outils disponibles
    if web_search_tool:
        tools.append(web_search_tool)

    tools.extend([get_stock_price, get_market_sentiment])

    # Prompt syst√®me pour l'agent augment√©
    focus_instruction = (
        f" Tu te concentres principalement sur {focus_ticker}." if focus_ticker else ""
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                f"""Tu es un analyste financier expert du fonds BERZERK avec acc√®s √† des outils temps r√©el.{focus_instruction}

**Tes outils disponibles :**
- web_search_tool : Recherche d'informations compl√©mentaires sur le web
- get_stock_price : Prix actuel et variation des actions
- get_market_sentiment : Informations sur capitalisation, P/E, volume

**Ton processus d'analyse :**
1. Analyse d'abord la news fournie
2. Utilise tes outils pour v√©rifier le contexte actuel du march√©
3. Recherche des informations compl√©mentaires si n√©cessaire
4. Produis une analyse compl√®te et nuanc√©e

**R√®gles importantes :**
- Utilise tes outils de mani√®re strat√©gique (pas syst√©matiquement)
- Mentionne si le march√© a d√©j√† r√©agi √† la news
- Contextualise tes recommandations avec les donn√©es temps r√©el
- Sois pr√©cis et actionnable dans tes conclusions""",
            ),
            ("user", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ]
    )

    # Cr√©ation de l'agent
    agent = create_tool_calling_agent(llm, tools, prompt)

    # Cr√©ation de l'ex√©cuteur
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,  # Pour voir le processus de r√©flexion
        max_iterations=5,  # Limiter les it√©rations pour √©viter les boucles
        early_stopping_method="generate",  # Arr√™t anticip√© si n√©cessaire
    )

    return agent_executor


def run_augmented_analysis(
    ticker: str, news_summary: str, full_article_text: str
) -> str:
    """
    Ex√©cute une analyse augment√©e avec acc√®s aux outils externes.

    Args:
        ticker: Ticker √† analyser
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article

    Returns:
        Analyse compl√®te avec donn√©es temps r√©el
    """
    try:
        # Cr√©ation de l'agent augment√© pour ce ticker
        agent_executor = create_augmented_analyst(focus_ticker=ticker)

        # Pr√©paration de la requ√™te
        query = f"""
        Analyse l'impact de cette news sur l'action {ticker}.

        **R√©sum√© de la news :**
        {news_summary}

        **Texte complet :**
        {full_article_text[:2000]}...  # Limitation pour √©viter les tokens excessifs

        **Ta mission :**
        1. V√©rifie le prix actuel et la variation de {ticker}
        2. Recherche des informations compl√©mentaires si n√©cessaire
        3. √âvalue si le march√© a d√©j√† int√©gr√© cette news
        4. Produis une recommandation d'investissement pr√©cise

        Utilise tes outils pour avoir une vision compl√®te du contexte actuel !
        """

        # Ex√©cution de l'analyse
        result = agent_executor.invoke({"input": query})

        return result.get("output", "Erreur dans l'analyse augment√©e")

    except Exception as e:
        return f"‚ùå **Erreur dans l'analyse augment√©e :** {str(e)}"


# --- AGENTS PURE PREDICTION (MODE BERZERK TAC AU TAC) ---


def create_pure_prediction_analyst(focus_ticker: str = None) -> AgentExecutor:
    """
    Cr√©e un agent analyste "pur" qui se base UNIQUEMENT sur l'analyse textuelle
    et le contexte web, sans acc√®s aux donn√©es de prix en temps r√©el.

    Args:
        focus_ticker: Ticker √† analyser en priorit√© (optionnel)

    Returns:
        AgentExecutor configur√© sans outils financiers
    """
    if not llm:
        raise ValueError("LLM non disponible pour cr√©er l'agent de pr√©diction pure")

    # Outils disponibles : UNIQUEMENT la recherche web pour le contexte qualitatif
    tools = []
    if web_search_tool:
        tools.append(web_search_tool)

    focus_instruction = (
        f" Tu te concentres principalement sur {focus_ticker}." if focus_ticker else ""
    )

    # Un prompt enti√®rement r√©orient√© vers la pr√©diction
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                f"""Tu es un analyste financier visionnaire pour le fonds BERZERK. Ta mission est de pr√©dire l'impact FUTUR d'une news, SANS te soucier de la r√©action pass√©e du march√©. Tu agis "tac au tac".{focus_instruction}

**Ton seul outil disponible :**
- web_search_tool : Pour obtenir plus de contexte QUALITATIF sur la news (produits, concurrents, technologie).

**Ton processus de pr√©diction :**
1. Analyse en profondeur la news fournie.
2. Si n√©cessaire, utilise la recherche web pour comprendre le contexte (ex: "Qu'est-ce que la technologie X mentionn√©e ?"). N'UTILISE PAS la recherche pour les prix.
3. Sur la base EXCLUSIVE de l'information et de son contexte, produis une pr√©diction d'impact et une recommandation d'action imm√©diate.

**R√®gles CRITIQUES :**
- IGNORE TOTALEMENT si le march√© a d√©j√† r√©agi ou non.
- Ta d√©cision doit √™tre une PURE PR√âDICTION bas√©e sur le potentiel de la news.
- Sois d√©cisif et direct. Le but est d'agir avant tout le monde.
- Base tes recommandations sur l'impact business fondamental pr√©dit.""",
            ),
            ("user", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ]
    )

    # Cr√©ation de l'agent
    agent = create_tool_calling_agent(llm, tools, prompt)

    # Cr√©ation de l'ex√©cuteur
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,  # Pour voir le processus de r√©flexion
        max_iterations=4,  # Moins d'it√©rations pour √™tre plus rapide
        early_stopping_method="generate",  # Arr√™t anticip√© si n√©cessaire
    )

    return agent_executor


def run_pure_prediction_analysis(
    ticker: str, news_summary: str, full_article_text: str
) -> str:
    """
    Ex√©cute une analyse de pr√©diction pure sans donn√©es de march√© historiques.

    Args:
        ticker: Ticker √† analyser
        news_summary: R√©sum√© de la news
        full_article_text: Texte complet de l'article

    Returns:
        Analyse de pr√©diction pure
    """
    try:
        # Cr√©ation de l'agent de pr√©diction pure pour ce ticker
        agent_executor = create_pure_prediction_analyst(focus_ticker=ticker)

        # Pr√©paration de la requ√™te orient√©e pr√©diction
        query = f"""
        Analyse l'impact pr√©dictif de cette news sur l'action {ticker}.

        **R√©sum√© de la news :**
        {news_summary}

        **Texte complet :**
        {full_article_text[:2000]}...

        **Ta mission PURE PREDICTION :**
        1. √âvalue la magnitude de cette information sur le business futur.
        2. D√©termine le sentiment pr√©dictif (tr√®s positif, positif, neutre, n√©gatif, tr√®s n√©gatif).
        3. Produis une recommandation d'action imm√©diate (Acheter, Vendre, Surveiller) et une justification bas√©e sur ta pr√©diction.
        4. Si n√©cessaire, recherche des informations contextuelles qualitatives (technologie, secteur, concurrence).

        INTERDIT : Aucune donn√©e de prix, volume ou r√©action de march√©. Ta d√©cision doit √™tre instantan√©e et visionnaire.
        """

        # Ex√©cution de l'analyse
        result = agent_executor.invoke({"input": query})

        return result.get("output", "Erreur dans l'analyse de pr√©diction pure.")

    except Exception as e:
        return f"‚ùå **Erreur dans l'analyse de pr√©diction pure :** {str(e)}"


# --- FONCTIONS UTILITAIRES ---


def get_available_agents() -> list[str]:
    """Retourne la liste des agents disponibles."""
    return list(AGENT_PROFILES.keys())


def get_agent_description(agent_type: str) -> str:
    """Retourne une description d'un agent sp√©cifique."""
    descriptions = {
        "analyste_actions": "Sp√©cialis√© dans l'analyse d'actions individuelles et de tickers sp√©cifiques",
        "analyste_sectoriel": "Expert en analyse de secteurs d'activit√© et dynamiques industrielles",
        "strategiste_geopolitique": "Sp√©cialis√© dans l'analyse g√©opolitique et macro√©conomique",
    }
    return descriptions.get(agent_type, "Agent non reconnu")


# --- FONCTION DE TEST ---


def test_agents_module():
    """Fonction de test pour v√©rifier le bon fonctionnement du module."""
    print("üß™ Test du module agents.py")
    print("-" * 50)

    # Test 1: V√©rification des profils
    print(f"‚úÖ {len(AGENT_PROFILES)} profils d'agents charg√©s")
    for agent_type in AGENT_PROFILES.keys():
        print(f"   - {agent_type}: {get_agent_description(agent_type)}")

    # Test 2: Test du routeur
    test_entities = ["AAPL", "TSLA", "Technologie", "Intelligence Artificielle"]
    test_summary = "Apple et Tesla annoncent un partenariat dans l'IA automobile"

    print(f"\nüîÄ Test du routeur avec entit√©s: {test_entities}")
    selected_agents = route_to_agents(test_entities, test_summary)
    print(f"‚úÖ Agents s√©lectionn√©s: {selected_agents}")

    print("\nüéØ Module agents.py pr√™t √† l'emploi !")


if __name__ == "__main__":
    test_agents_module()
</file>

<file path="berzerk_dashboard.py">
#!/usr/bin/env python3
"""
‚ö° BERZERK - Decision Feed
========================

Interface √©pur√©e "Clart√© Radicale" pour le suivi des d√©cisions d'investissement IA.
Philosophie : Priorit√© √† l'action, simplicit√©, hi√©rarchie claire.

Auteur: BERZERK Team
Phase: 8.1 - Ajout du suivi de performance instantan√©
"""

import hashlib
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Any

import plotly.graph_objects as go
import streamlit as st
import yfinance as yf

# Configuration de la page
st.set_page_config(
    page_title="BERZERK Decision Feed",
    page_icon="‚ö°",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# --- NOUVELLES FONCTIONS DE PERFORMANCE ---



@st.cache_data(ttl=60)  # Cache 1 minute pour les prix actuels
def get_current_price(ticker: str) -> float:
    """R√©cup√®re le prix actuel d'une action avec des fallbacks robustes."""
    ticker = ticker.strip().replace("$", "")  # Nettoyage du ticker
    if not ticker:
        return 0.0
    try:
        stock = yf.Ticker(ticker)
        
        # 1. Priorit√© aux donn√©es intraday
        data = stock.history(period="1d", interval="1m")
        if not data.empty:
            return float(data["Close"].iloc[-1])

        # 2. Fallback sur 'info'
        info = stock.info
        price = info.get("regularMarketPrice") or info.get("currentPrice")
        if price:
            return float(price)

        # 3. Fallback ultime sur la derni√®re cl√¥ture historique
        hist = stock.history(period="5d")
        if not hist.empty:
            return float(hist["Close"].iloc[-1])
            
        return 0.0
    except Exception:
        # Gestion silencieuse des erreurs
        return 0.0


# --- FONCTIONS EXISTANTES (MODIFI√âES ET CONSERV√âES) ---


def display_confidence_signal(confidence: str):
    """Affiche un indicateur visuel de force du signal."""
    confidence_map = {"√âLEV√âE": 3, "MOYENNE": 2, "FAIBLE": 1}
    level = confidence_map.get(confidence.upper(), 0)

    bars = "".join(
        [
            f'<div class="signal-bar {"filled" if i < level else ""}"></div>'
            for i in range(3)
        ]
    )

    st.markdown(
        f"""
        <div class="signal-container">
            <div class="signal-bars">{bars}</div>
            <span class="signal-text">{confidence.capitalize()}</span>
        </div>
    """,
        unsafe_allow_html=True,
    )


@st.cache_data(ttl=900)  # Cache de 15 minutes pour les graphiques
def get_sparkline_chart(ticker: str):
    """G√©n√®re un mini-graphique (sparkline) avec couleur de tendance."""
    ticker = ticker.strip().replace("$", "")  # Nettoyage du ticker
    if not ticker:
        return None, "N/A"

    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="7d", interval="1d")

        if len(hist) < 2:
            return None, "N/A"

        start_price = hist["Close"].iloc[0]
        end_price = hist["Close"].iloc[-1]

        color = "#28a745" if end_price > start_price else "#dc3545"
        fill_color = (
            "rgba(40, 167, 69, 0.1)"
            if end_price > start_price
            else "rgba(220, 53, 69, 0.1)"
        )
        trend = "Haussier" if end_price > start_price else "Baissier"

        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                x=hist.index,
                y=hist["Close"],
                mode="lines",
                line={"color": color, "width": 2.5},
                fill="tozeroy",
                fillcolor=fill_color,
            )
        )
        fig.update_layout(
            height=50,
            margin={"l": 0, "r": 0, "t": 5, "b": 0},
            xaxis={"visible": False},
            yaxis={"visible": False},
            paper_bgcolor="rgba(0,0,0,0)",
            plot_bgcolor="rgba(0,0,0,0)",
            showlegend=False,
        )
        return fig, trend
    except Exception:
        # Gestion silencieuse des erreurs
        return None, "N/A"


@st.cache_data(ttl=60)  # Cache de 60 secondes
def load_decisions_from_db() -> list[dict[str, Any]]:
    """Charge les d√©cisions depuis la DB et les enrichit avec les donn√©es de performance."""
    try:
        conn = sqlite3.connect("berzerk.db")
        cursor = conn.cursor()

        cursor.execute(
            """
            SELECT title, link, published_date, decision_json, analyzed_at
            FROM articles
            WHERE decision_json IS NOT NULL AND status = 'analyzed'
            AND analyzed_at >= datetime('now', '-30 days')
            ORDER BY analyzed_at DESC
        """
        )

        rows = cursor.fetchall()
        conn.close()

        decisions = []
        for title, link, _published_date, decision_json, analyzed_at in rows:
            try:
                decision_data = json.loads(decision_json)
                
                # --- D√âBUT DE LA MODIFICATION ---
                # R√©cup√©rer l'action brute, quelle que soit la cl√© utilis√©e ("action" ou "decision")
                action_brute = decision_data.get("action", decision_data.get("decision", "INCONNUE")).upper()
                
                # Normaliser l'action pour qu'elle soit compatible avec le nouveau syst√®me
                if action_brute == "ACHETER":
                    action_normalisee = "LONG"
                elif action_brute == "VENDRE":
                    action_normalisee = "SHORT"
                else:
                    # Garde les actions d√©j√† au bon format (LONG, SHORT, SURVEILLER)
                    action_normalisee = action_brute
                # --- FIN DE LA MODIFICATION ---
                
                ticker = decision_data.get("ticker", None)

                if action_normalisee in ["INCONNUE", "ERREUR"] or not ticker:
                    continue

                # Cr√©er un identifiant unique bas√© sur analyzed_at pour √©viter les cl√©s dupliqu√©es
                unique_id = hashlib.md5(f"{analyzed_at}_{link}".encode()).hexdigest()[
                    :8
                ]

                # --- ENRICHISSEMENT AVEC DONN√âES DE PERFORMANCE ---
                prix_decision = float(decision_data.get("prix_a_la_decision", 0.0))
                
                # On r√©cup√®re le prix actuel pour la comparaison
                prix_actuel = get_current_price(ticker)

                decision = {
                    "action": action_normalisee,
                    "ticker": ticker,
                    "unique_id": unique_id,  # Identifiant unique pour √©viter les doublons
                    "nom_entreprise": decision_data.get(
                        "nom_entreprise", f"Entreprise {ticker}"
                    ),
                    "news_title": title,
                    "analyzed_at": analyzed_at,
                    # NOUVELLES DONN√âES DE PERFORMANCE
                    "prix_decision": prix_decision,
                    "prix_actuel": prix_actuel,
                    # ---
                    "justification": decision_data.get(
                        "justification_synthetique",
                        decision_data.get(
                            "justification", "Analyse automatique BERZERK"
                        ),
                    ),
                    "points_positifs": decision_data.get(
                        "points_cles_positifs", ["Analyse favorable"]
                    ),
                    "points_negatifs": decision_data.get(
                        "points_cles_negatifs_risques", ["Risques standards"]
                    ),
                    "allocation_pct": decision_data.get(
                        "allocation_capital_pourcentage",
                        decision_data.get("allocation_pourcentage", 0.0),
                    ),
                    "confiance": decision_data.get("confiance", "MOYENNE"),
                    "horizon": decision_data.get("horizon", "Court Terme"),
                    "article_link": link,
                }
                decisions.append(decision)

            except (json.JSONDecodeError, KeyError) as e:
                print(f"Erreur parsing JSON pour '{title}': {e}")
                continue

        return decisions

    except Exception as e:
        st.error(f"Erreur critique chargement donn√©es : {e}")
        return []


def get_sample_decisions() -> list[dict[str, Any]]:
    """G√©n√®re des d√©cisions d'exemple pour la d√©monstration (avec donn√©es de performance)."""
    return [
        {
            "action": "LONG",
            "ticker": "AAPL",
            "unique_id": "sample001",
            "nom_entreprise": "Apple Inc.",
            "news_title": "Apple annonce des avanc√©es majeures dans l'IA pour l'iPhone 17.",
            "analyzed_at": "2024-12-07T14:32:00",
            "prix_decision": 195.50,
            "prix_actuel": get_current_price("AAPL"),
            "justification": "L'annonce d'une nouvelle puce IA devrait booster les ventes et donner un avantage concurrentiel significatif √† Apple sur le march√© des smartphones.",
            "points_positifs": [
                "Avantage concurrentiel IA",
                "Cycle de remplacement acc√©l√©r√©",
                "Marges √©lev√©es",
            ],
            "points_negatifs": [
                "Risques d'ex√©cution",
                "Valorisation d√©j√† √©lev√©e",
                "Concurrence intense",
            ],
            "allocation_pct": 2.5,
            "confiance": "√âLEV√âE",
            "horizon": "Moyen Terme",
            "article_link": "https://example.com/apple-ai-news",
        },
        {
            "action": "SHORT",
            "ticker": "XOM",
            "unique_id": "sample002",
            "nom_entreprise": "ExxonMobil Corporation",
            "news_title": "OPEC+ augmente la production, craintes de surabondance p√©troli√®re",
            "analyzed_at": "2024-12-07T12:15:00",
            "prix_decision": 118.75,
            "prix_actuel": get_current_price("XOM"),
            "justification": "La surabondance de l'offre p√©troli√®re et les craintes sur la demande exercent une pression baissi√®re directe sur la rentabilit√© future de XOM.",
            "points_positifs": ["Dividende stable", "Gestion financi√®re solide"],
            "points_negatifs": [
                "Pression sur les prix du p√©trole",
                "Surabondance de l'offre",
                "Demande incertaine",
            ],
            "allocation_pct": 0.0,
            "confiance": "MOYENNE",
            "horizon": "Court Terme",
            "article_link": "https://example.com/opec-oil-news",
        },
        {
            "action": "SURVEILLER",
            "ticker": "NVDA",
            "unique_id": "sample003",
            "nom_entreprise": "NVIDIA Corporation",
            "news_title": "NVIDIA pr√©sente ses nouveaux processeurs IA de nouvelle g√©n√©ration",
            "analyzed_at": "2024-12-07T10:45:00",
            "prix_decision": 485.20,
            "prix_actuel": get_current_price("NVDA"),
            "justification": "Innovation prometteuse mais valorisation d√©j√† √©lev√©e. Attendre une correction pour une meilleure opportunit√© d'entr√©e.",
            "points_positifs": [
                "Leadership IA",
                "Innovation continue",
                "Demande croissante",
            ],
            "points_negatifs": [
                "Valorisation excessive",
                "Volatilit√© √©lev√©e",
                "D√©pendance cyclique",
            ],
            "allocation_pct": 1.0,
            "confiance": "FAIBLE",
            "horizon": "Long Terme",
            "article_link": "https://example.com/nvidia-ai-news",
        },
    ]


def display_decision_card(decision: dict[str, Any]):
    """Affiche une carte de d√©cision 2.1 avec suivi de performance int√©gr√©."""
    action = decision["action"]
    color_map = {
        "LONG": "#28a745",      # Vert pour LONG
        "SHORT": "#dc3545",     # Rouge pour SHORT
        "ACHETER": "#28a745",   # Compatibilit√© avec les anciennes donn√©es
        "VENDRE": "#dc3545",    # Compatibilit√© avec les anciennes donn√©es
        "SURVEILLER": "#ffc107",
        "IGNORER": "#6c757d",
    }

    with st.container(border=True):

        # === EN-T√äTE INT√âGR√â (INFO + GRAPHIQUE) ===
        header_cols = st.columns([1, 2.5, 2])

        with header_cols[0]:
            # Badge d'action
            st.markdown(
                f"""
                <div style="background-color: {color_map.get(action, '#6c757d')}; color: white; padding: 12px; text-align: center; border-radius: 8px; font-weight: bold; font-size: 1.1rem; height: 100%;">
                    {action}
                </div>
            """,
                unsafe_allow_html=True,
            )

        with header_cols[1]:
            # Ticker, Nom et News
            st.subheader(f"{decision['ticker']} - {decision['nom_entreprise']}")
            st.write(f"_{decision['news_title']}_")
            analyzed_dt = datetime.fromisoformat(
                decision["analyzed_at"].replace("Z", "+00:00")
            )
            st.caption(f"Analyse du {analyzed_dt.strftime('%d/%m/%y %H:%M')}")

        with header_cols[2]:
            # Sparkline avec cl√© unique
            sparkline_fig, trend = get_sparkline_chart(decision["ticker"])
            if sparkline_fig:
                # Cl√© unique utilisant ticker + unique_id pour √©viter les doublons
                unique_key = f"sparkline_{decision['ticker']}_{decision['unique_id']}"
                st.plotly_chart(sparkline_fig, use_container_width=True, key=unique_key)
                st.caption(f"Tendance 7J: {trend}")
            else:
                st.caption("Tendance 7J: Donn√©es indisponibles")

        # Affichage conditionnel pour IGNORER/SURVEILLER
        if action in ["IGNORER", "SURVEILLER"]:
            st.info(f"Raison de la surveillance : {decision['justification']}")
        else:
            # --- SECTION ROBUSTE : SUIVI DE PERFORMANCE ---
            st.markdown("---")
            st.markdown(
                '<div class="key-indicator-title" style="text-align:left; margin-bottom: 0.5rem;">üìä Suivi de la Position</div>',
                unsafe_allow_html=True,
            )

            perf_cols = st.columns(3)
            prix_decision = decision.get("prix_decision", 0.0)
            prix_actuel = decision.get("prix_actuel", 0.0)
            # Affichage du Prix √† la D√©cision
            with perf_cols[0]:
                if prix_decision > 0:
                    st.metric("Prix √† la d√©cision", f"{prix_decision:.2f} $")
                else:
                    st.metric("Prix √† la d√©cision", "N/A", help="Le prix n'a pas pu √™tre captur√© au moment de la d√©cision.")
            # Affichage du Prix Actuel
            with perf_cols[1]:
                if prix_actuel > 0:
                    st.metric("Prix actuel", f"{prix_actuel:.2f} $")
                else:
                    st.metric("Prix actuel", "N/A", help="Le prix actuel est indisponible (march√© ferm√© ou ticker invalide).")
            # Affichage de la Performance (conditionnel)
            with perf_cols[2]:
                if prix_decision > 0 and prix_actuel > 0:
                    perf_pct = 0
                    if decision["action"] == "LONG":
                        perf_pct = ((prix_actuel - prix_decision) / prix_decision) * 100
                    elif decision["action"] == "SHORT":
                        perf_pct = ((prix_decision - prix_actuel) / prix_decision) * 100
                    st.metric(
                        "Performance",
                        f"{perf_pct:+.2f}%",
                        delta_color="normal" if perf_pct >= 0 else "inverse",
                    )
                else:
                    st.metric("Performance", "N/A", help="Calcul impossible sans les deux prix.")
            st.markdown("---")
        # --- FIN DE LA SECTION MODIFI√âE ---

        # === INDICATEURS CL√âS ===
        kpi_cols = st.columns(3)

        # R√©cup√©ration du secteur via yfinance (gestion silencieuse des erreurs)
        sector = "N/A"
        try:
            stock_info = yf.Ticker(decision["ticker"]).info
            sector = stock_info.get("sector", "N/A")
        except Exception:
            pass

        with kpi_cols[0]:
            st.markdown(
                '<div class="key-indicator-title">Force du Signal</div>',
                unsafe_allow_html=True,
            )
            display_confidence_signal(decision.get("confiance", "INCONNUE"))

        with kpi_cols[1]:
            st.markdown(
                '<div class="key-indicator-title">Horizon</div>', unsafe_allow_html=True
            )
            st.markdown(
                f'<div class="key-indicator-value">{decision.get("horizon", "N/A")}</div>',
                unsafe_allow_html=True,
            )

        with kpi_cols[2]:
            st.markdown(
                '<div class="key-indicator-title">Secteur</div>', unsafe_allow_html=True
            )
            st.markdown(
                f'<div class="key-indicator-value">{sector}</div>',
                unsafe_allow_html=True,
            )

        # === EXPANDER POUR LES D√âTAILS ===
        with st.expander("‚ñº Voir le raisonnement de l'IA et les d√©tails"):
            st.markdown("#### Justification de l'IA")
            st.write(decision["justification"])
            st.markdown("---")
            col_pos, col_neg = st.columns(2)
            with col_pos:
                st.markdown("‚úÖ **Points Cl√©s Positifs**")
                for point in decision["points_positifs"]:
                    st.write(f"‚Ä¢ {point}")
            with col_neg:
                st.markdown("‚ö†Ô∏è **Risques & Points N√©gatifs**")
                for point in decision["points_negatifs"]:
                    st.write(f"‚Ä¢ {point}")
            if decision["action"] == "LONG":
                st.info(
                    f"üí° Allocation Sugg√©r√©e: {decision['allocation_pct']}% du capital de trading."
                )
            st.link_button("Consulter l'article original ‚Üó", decision["article_link"])


def display_decision_feed():
    """Affiche le flux de d√©cisions avec suivi de performance."""
    # === BARRE DE STATUT ===
    stat_col1, stat_col2, stat_col3 = st.columns(3)

    # Charger les d√©cisions
    decisions = load_decisions_from_db()

    # Si pas de donn√©es r√©elles, utiliser les exemples
    if not decisions:
        st.warning("üîÑ Aucune d√©cision r√©cente dans la base. Affichage des exemples.")
        decisions = get_sample_decisions()

    # Calculs pour les statistiques
    now = datetime.now()
    decisions_24h = len(
        [
            d
            for d in decisions
            if datetime.fromisoformat(d["analyzed_at"].replace("Z", "+00:00"))
            > now - timedelta(hours=24)
        ]
    )
    # Compter les signaux LONG des derni√®res 24h
    longs_24h = len(
        [
            d
            for d in decisions
            if d["action"] == "LONG"
            and datetime.fromisoformat(d["analyzed_at"].replace("Z", "+00:00"))
            > now - timedelta(hours=24)
        ]
    )

    with stat_col1:
        st.metric("Statut Syst√®me", "üü¢ Op√©rationnel")

    with stat_col2:
        st.metric("D√©cisions 24h", decisions_24h)

    with stat_col3:
        st.metric("Signaux LONG 24h", longs_24h)

    st.markdown("---")

    # === FLUX PRINCIPAL ===
    if decisions:
        st.markdown("### üìà Flux de D√©cisions avec Suivi de Performance")

        for decision in decisions:
            display_decision_card(decision)
            st.markdown("")  # Espace entre les cartes
    else:
        st.info("üìä Aucune d√©cision √† afficher pour le moment.")
        st.markdown(
            "Lancez le monitoring pour commencer √† g√©n√©rer des d√©cisions : `python start_realtime_monitor.py`"
        )


def display_active_portfolio():
    """Affiche le portefeuille actif avec KPIs et tableau d√©taill√©."""
    st.header("üìä Suivi du Portefeuille Actif")
    
    decisions = load_decisions_from_db()
    
    # --- V√âRIFICATION CL√â ---
    # Ce filtrage fonctionnera maintenant gr√¢ce √† la normalisation faite en Phase 1
    active_positions = [d for d in decisions if d['action'] in ['LONG', 'SHORT']]
    # --- FIN DE LA V√âRIFICATION ---

    if not active_positions:
        st.warning("‚ÑπÔ∏è Aucune position LONG ou SHORT n'a √©t√© trouv√©e dans les d√©cisions r√©centes.")
        st.write("Le portefeuille actif s'affichera ici d√®s que de nouvelles positions de trading seront prises par l'IA.")
        return
    
    # Calculer les KPIs globaux
    total_pnl_pct = 0
    winning_trades = 0
    
    for pos in active_positions:
        prix_decision = pos.get("prix_decision", 0.0)
        prix_actuel = pos.get("prix_actuel", 0.0)
        pnl_pct = 0
        if prix_decision > 0 and prix_actuel > 0:
            if pos['action'] == 'LONG':
                pnl_pct = ((prix_actuel - prix_decision) / prix_decision) * 100
            elif pos['action'] == 'SHORT':
                pnl_pct = ((prix_decision - prix_actuel) / prix_decision) * 100
        
        if pnl_pct > 0:
            winning_trades += 1
        total_pnl_pct += pnl_pct

    avg_pnl = total_pnl_pct / len(active_positions)
    win_rate = (winning_trades / len(active_positions)) * 100
    
    # Afficher les KPIs
    kpi_cols = st.columns(4)
    with kpi_cols[0]:
        st.metric("Positions Ouvertes", len(active_positions))
    with kpi_cols[1]:
        long_count = len([p for p in active_positions if p['action'] == 'LONG'])
        st.metric("Positions LONG", long_count)
    with kpi_cols[2]:
        short_count = len([p for p in active_positions if p['action'] == 'SHORT'])
        st.metric("Positions SHORT", short_count)
    with kpi_cols[3]:
        st.metric("Taux de R√©ussite", f"{win_rate:.1f}%")
        
    st.markdown("---")
    
    # Tableau d√©taill√© des positions
    st.subheader("D√©tail des Positions")
    
    # Cr√©er les en-t√™tes du tableau
    header_cols = st.columns([1, 1, 2, 1.5, 1.5, 1.5])
    headers = ["Ticker", "Direction", "Date Entr√©e", "Prix Entr√©e", "Prix Actuel", "Performance (%)"]
    for col, header in zip(header_cols, headers):
        col.markdown(f"**{header}**")

    # Mapping des couleurs
    color_map = {
        "LONG": "#28a745",
        "SHORT": "#dc3545",
        "SURVEILLER": "#ffc107",
        "IGNORER": "#6c757d",
    }

    # Afficher chaque position
    for pos in active_positions:
        prix_decision = pos.get("prix_decision", 0.0)
        prix_actuel = pos.get("prix_actuel", 0.0)
        pnl_pct = 0
        
        if prix_decision > 0 and prix_actuel > 0:
            if pos['action'] == 'LONG':
                pnl_pct = ((prix_actuel - prix_decision) / prix_decision) * 100
            elif pos['action'] == 'SHORT':
                pnl_pct = ((prix_decision - prix_actuel) / prix_decision) * 100

        color = "green" if pnl_pct >= 0 else "red"
        
        row_cols = st.columns([1, 1, 2, 1.5, 1.5, 1.5])
        row_cols[0].text(pos['ticker'])
        row_cols[1].markdown(f"**<font color='{color_map[pos['action']]}'>{pos['action']}</font>**", unsafe_allow_html=True)
        analyzed_dt = datetime.fromisoformat(pos["analyzed_at"].replace("Z", "+00:00"))
        row_cols[2].text(analyzed_dt.strftime('%d/%m/%y %H:%M'))
        row_cols[3].text(f"{prix_decision:.2f} $")
        row_cols[4].text(f"{prix_actuel:.2f} $")
        row_cols[5].markdown(f"**<font color='{color}'>{pnl_pct:+.2f}%</font>**", unsafe_allow_html=True)
        
        # Ajouter un expander pour les d√©tails du signal original
        with st.expander(f"Voir d√©tails pour {pos['ticker']}"):
            st.write(f"**Signal original :** {pos['news_title']}")
            st.write(f"**Justification IA :** {pos['justification']}")


def main():
    """Fonction principale de l'interface Decision Feed."""

    # === STYLES CSS ENRICHIS ===
    st.markdown(
        """
        <style>
        /* STYLES EXISTANTS POUR LA CARTE AM√âLIOR√âE */
        .signal-container {
            display: flex;
            align-items: center;
            gap: 8px;
        }
        .signal-bars {
            display: flex;
            align-items: flex-end;
            gap: 2px;
        }
        .signal-bar {
            width: 6px;
            background-color: #e0e0e0;
            border-radius: 2px;
        }
        .signal-bar:nth-child(1) { height: 8px; }
        .signal-bar:nth-child(2) { height: 12px; }
        .signal-bar:nth-child(3) { height: 16px; }
        .signal-bar.filled {
            background-color: #34a853;
        }
        .signal-text {
            font-size: 0.9rem;
            font-weight: 500;
        }
        .key-indicator-title {
            font-size: 0.8rem;
            color: #5f6368;
            margin-bottom: 0.3rem;
            text-transform: uppercase;
        }
        .key-indicator-value {
            font-size: 1rem;
            font-weight: 600;
            color: #202124;
        }

        /* NOUVEAUX STYLES POUR LA PERFORMANCE */
        .perf-container {
            border: 1px solid #e0e0e0;
            border-radius: 0.5rem;
            padding: 0.8rem 1rem;
            text-align: center;
            background-color: #f8f9fa;
        }
        .perf-label {
            font-size: 0.75rem;
            color: #5f6368;
            margin-bottom: 0.25rem;
            text-transform: uppercase;
            font-weight: 500;
        }
        .perf-value {
            font-size: 1.2rem;
            font-weight: 700;
        }
        .perf-positive { color: #1e8e3e; }
        .perf-negative { color: #d93025; }
        </style>
    """,
        unsafe_allow_html=True,
    )

    # === EN-T√äTE ===
    st.title("‚ö° BERZERK - Centre de Commandement Trading")
    st.caption("Analyse IA. D√©cisions Imm√©diates. Suivi de Performance Temps R√©el.")

    # Cr√©ation des deux onglets principaux
    tab1, tab2 = st.tabs(["‚ö° Flux de D√©cisions", "üìä Portefeuille Actif"])

    with tab1:
        display_decision_feed()

    with tab2:
        display_active_portfolio()
    
    # Rafra√Æchissement automatique natif Python - Solution robuste
    from streamlit_autorefresh import st_autorefresh

    # Configure le composant pour rafra√Æchir la page toutes les 60 secondes (60000 millisecondes)
    # On peut aussi ajouter un compteur visuel si on le souhaite.
    st_autorefresh(interval=60 * 1000, key="price_refresher")

    # Ajouter un indicateur visuel pour l'utilisateur
    st.markdown("""
        <div style="position: fixed; bottom: 10px; right: 15px; padding: 6px 12px; background: rgba(0, 0, 0, 0.6); color: white; border-radius: 8px; font-family: monospace; font-size: 12px; z-index: 9999;">
            Auto-Refresh: 60s
        </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
</file>

<file path="orchestrator.py">
"""
Orchestrateur Automatis√© BERZERK - Phase 2.3
============================================

Ce module contient le pipeline automatis√© complet utilisant LangGraph pour orchestrer
l'ensemble de la cha√Æne d'analyse financi√®re : de la news brute √† la d√©cision d'investissement.

Architecture : News ‚Üí Analyse Initiale ‚Üí Routage Agents ‚Üí Analyses Sp√©cialis√©es ‚Üí D√©cision Finale

Auteur: BERZERK Team
Phase: 2.3 - Automatisation Compl√®te
"""

import sys
from datetime import datetime
from typing import Any, TypedDict

import yfinance as yf
from langchain_core.output_parsers import JsonOutputParser

# LangGraph Imports
from langgraph.graph import END, StateGraph
from pydantic import BaseModel, Field

from agents import (
    AGENT_PROFILES,
    llm,
    route_to_agents,
    run_agent_analysis,
    run_pure_prediction_analysis,  # NOUVEAU : Agent de pr√©diction pure
    run_ticker_hunter,
)

# Imports depuis nos modules existants
from berzerk_lab import analyze_news_with_llm, get_article_text

import os

# --- D√âFINITION DE L'√âTAT DU GRAPHE ---


class GraphState(TypedDict):
    """√âtat qui circule dans le graphe et est mis √† jour √† chaque √©tape."""

    news_link: str
    news_summary: str
    full_article_text: str
    initial_analysis: dict[str, Any]
    actionable_tickers: list[dict[str, str]]  # Nouveau : R√©sultat du Ticker Hunter
    agent_team: list[dict[str, str]]
    agent_debriefing: str
    final_decision: dict[str, Any]
    capital_disponible: float
    execution_log: list[str]
    timestamp: str


# --- MOD√àLE PYDANTIC POUR LA D√âCISION FINALE ---


class InvestmentDecision(BaseModel):
    """Mod√®le pour valider la d√©cision finale d'investissement."""

    decision: str = Field(description="LONG (pari sur la hausse), SHORT (pari sur la baisse), SURVEILLER ou IGNORER")
    ticker: str = Field(description="Ticker de l'action concern√©e ou null")
    confiance: str = Field(description="√âLEV√âE, MOYENNE ou FAIBLE")
    horizon: str = Field(description="Court Terme, Moyen Terme, ou Long Terme")
    justification_synthetique: str = Field(description="Justification en une phrase")
    allocation_capital_pourcentage: float = Field(
        description="Pourcentage du capital √† allouer (0.0 √† 5.0)"
    )
    points_cles_positifs: list[str] = Field(description="Points positifs cl√©s")
    points_cles_negatifs_risques: list[str] = Field(description="Risques identifi√©s")


# --- FONCTION DE CAPTURE DE PRIX ---


def get_live_price(ticker: str) -> float:
    """R√©cup√®re le prix le plus r√©cent disponible pour un ticker avec des fallbacks robustes."""
    ticker = ticker.strip().replace("$", "")
    if not ticker:
        print(f"[WARN] Ticker vide ou invalide pour la capture de prix.")
        return 0.0
    try:
        stock = yf.Ticker(ticker)
        # 1. Tentative Intraday
        print(f"[INFO] Tentative de r√©cup√©ration du prix intraday pour {ticker}...")
        try:
            data = stock.history(period="1d", interval="1m")
            if not data.empty:
                price = float(data["Close"].iloc[-1])
                print(f"[INFO] Prix intraday r√©cup√©r√© pour {ticker}: {price}")
                return price
            else:
                print(f"[WARN] Pas de donn√©es intraday pour {ticker}.")
        except Exception as e:
            print(f"[WARN] √âchec r√©cup√©ration intraday pour {ticker}: {e}")
        # 2. Tentative via stock.info
        print(f"[INFO] Tentative de r√©cup√©ration du prix via info pour {ticker}...")
        try:
            info = stock.info
            price = info.get("regularMarketPrice") or info.get("currentPrice")
            if price:
                print(f"[INFO] Prix info r√©cup√©r√© pour {ticker}: {price}")
                return float(price)
            else:
                print(f"[WARN] Pas de prix dans info pour {ticker}.")
        except Exception as e:
            print(f"[WARN] √âchec r√©cup√©ration info pour {ticker}: {e}")
        # 3. Tentative Historique 5j
        print(f"[INFO] Tentative de r√©cup√©ration du prix historique (5j) pour {ticker}...")
        try:
            hist = stock.history(period="5d")
            if not hist.empty:
                price = float(hist["Close"].iloc[-1])
                print(f"[INFO] Prix historique r√©cup√©r√© pour {ticker}: {price}")
                return price
            else:
                print(f"[WARN] Pas de donn√©es historiques pour {ticker}.")
        except Exception as e:
            print(f"[WARN] √âchec r√©cup√©ration historique pour {ticker}: {e}")
        print(f"[WARN] Impossible de r√©cup√©rer le prix pour {ticker} apr√®s tous les fallbacks.")
        return 0.0
    except Exception as e:
        print(f"[WARN] Exception inattendue lors de la r√©cup√©ration du prix pour {ticker}: {e}")
        return 0.0


def send_telegram_notification(message: str):
    """Envoie une notification Telegram via le bot configur√©."""
    bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
    chat_id = os.getenv("TELEGRAM_CHAT_ID")
    if not bot_token or not chat_id:
        print("[WARN] Variables Telegram manquantes : TELEGRAM_BOT_TOKEN ou TELEGRAM_CHAT_ID non d√©finies. Notification ignor√©e.")
        return
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": message,
        "parse_mode": "Markdown"
    }
    try:
        import requests
        response = requests.post(url, data=payload, timeout=10)
        if response.status_code != 200:
            print(f"[ERROR] Notification Telegram √©chou√©e : {response.status_code} - {response.text}")
        else:
            print("[INFO] Notification Telegram envoy√©e avec succ√®s.")
    except Exception as e:
        print(f"[ERROR] Exception lors de l'envoi Telegram : {e}")


# --- FONCTIONS UTILITAIRES ---


def log_step(state: GraphState, message: str) -> None:
    """Ajoute un log √† l'√©tat avec timestamp."""
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_message = f"[{timestamp}] {message}"
    state["execution_log"].append(log_message)
    print(f"üîÑ {log_message}")


def format_debriefing(agent_analyses: list[dict[str, str]]) -> str:
    """Formate les analyses des agents pour le superviseur."""
    debriefing_parts = []
    for i, analysis in enumerate(agent_analyses, 1):
        debriefing_parts.append(
            f"\n--- ANALYSE {i} : {analysis['agent_type'].upper().replace('_', ' ')} ---\n"
            f"Focus : {analysis['focus']}\n\n"
            f"{analysis['analysis']}\n"
            f"{'='*80}"
        )
    return "\n".join(debriefing_parts)


# --- N≈íUDS DU GRAPHE (chaque n≈ìud est une fonction) ---


def node_initial_analysis(state: GraphState) -> GraphState:
    """N≈ìud 1 : R√©cup√®re le texte de l'article et fait l'analyse initiale."""
    log_step(state, "D√âMARRAGE - Analyse Initiale")

    try:
        # R√©cup√©ration du texte complet
        full_text = get_article_text(state["news_link"])
        if not full_text:
            raise ValueError("Impossible de r√©cup√©rer le texte de l'article")

        # Analyse initiale avec LLM
        analysis = analyze_news_with_llm(full_text)
        if not analysis:
            raise ValueError("√âchec de l'analyse initiale")

        # Mise √† jour de l'√©tat
        state["full_article_text"] = full_text
        state["initial_analysis"] = analysis
        state["news_summary"] = analysis.get("resume", "")

        log_step(
            state,
            f"‚úÖ Analyse initiale termin√©e - Impact: {analysis.get('impact', 'N/A')}/10",
        )
        log_step(
            state, f"‚úÖ Entit√©s d√©tect√©es: {', '.join(analysis.get('entites', []))}"
        )

    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans l'analyse initiale: {str(e)}")
        state["initial_analysis"] = {"error": str(e)}

    return state


def node_find_actionable_tickers(state: GraphState) -> GraphState:
    """N≈ìud 2 : Chasse aux Tickers - Identifie les tickers actionnables."""
    log_step(state, "TICKER HUNTER - Identification des tickers actionnables")

    try:
        if "error" in state["initial_analysis"]:
            raise ValueError(
                "Analyse initiale √©chou√©e, impossible d'identifier les tickers"
            )

        # Ex√©cution du Ticker Hunter
        ticker_result = run_ticker_hunter(
            news_summary=state["news_summary"],
            full_article_text=state["full_article_text"],
        )

        raw_tickers = ticker_result.get("tickers_identifies", [])
        
        if not raw_tickers:
            log_step(state, "‚ö†Ô∏è  Aucun ticker actionnable identifi√© par l'IA.")
            state["actionable_tickers"] = []
            return state

        log_step(state, f"üî¨ {len(raw_tickers)} ticker(s) brut(s) identifi√©(s). Validation en cours...")
        
        validated_tickers = []
        for ticker_info in raw_tickers:
            # Gestion des Pydantic/dict
            ticker_symbol = ticker_info.ticker if hasattr(ticker_info, 'ticker') else ticker_info.get("ticker", "")
            
            # 1. Nettoyage (d√©j√† fait dans agents.py mais redondance s√©curitaire)
            clean_ticker = ticker_symbol.strip().replace("$", "")

            # 2. V√©rification de viabilit√© avec yfinance (L'AJOUT CRUCIAL)
            try:
                stock = yf.Ticker(clean_ticker)
                # On fait un appel tr√®s l√©ger juste pour voir si le ticker existe
                info = stock.info
                if not info or info.get('regularMarketPrice') is None and info.get('currentPrice') is None:
                    raise ValueError("Ticker non trouv√© ou sans donn√©es de prix.")
                
                log_step(state, f"‚úÖ Ticker '{clean_ticker}' valid√© avec yfinance.")
                
                # Mettre √† jour le ticker nettoy√© dans l'objet
                if hasattr(ticker_info, 'ticker'):
                    ticker_info.ticker = clean_ticker
                else:
                    ticker_info['ticker'] = clean_ticker

                validated_tickers.append(ticker_info)

            except Exception as e:
                log_step(state, f"‚ùå Ticker '{clean_ticker}' REJET√â apr√®s validation yfinance. Raison: {e}")

        state["actionable_tickers"] = validated_tickers
        log_step(state, f"üéØ {len(validated_tickers)} ticker(s) final(aux) apr√®s validation.")

    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans le Ticker Hunter: {str(e)}")
        state["actionable_tickers"] = []

    return state


def node_route_to_agents(state: GraphState) -> GraphState:
    """N≈ìud 3 : Recrute l'√©quipe d'agents bas√©e sur les tickers identifi√©s."""
    log_step(state, "ROUTAGE - Recrutement de l'√©quipe d'agents (bas√© sur tickers)")

    try:
        if "error" in state["initial_analysis"]:
            raise ValueError("Analyse initiale √©chou√©e, impossible de router")

        actionable_tickers = state.get("actionable_tickers", [])

        if actionable_tickers:
            # Mode PR√âCIS : Tickers identifi√©s ‚Üí Agents cibl√©s
            team = []

            # Pour chaque ticker, on cr√©e un analyste d'actions d√©di√©
            for ticker_info in actionable_tickers:
                # Gestion des objets Pydantic ET des dictionnaires
                if hasattr(ticker_info, "ticker"):
                    ticker = ticker_info.ticker
                    company = ticker_info.nom_entreprise
                else:
                    ticker = ticker_info.get("ticker", "")
                    company = ticker_info.get("nom_entreprise", "")

                team.append(
                    {"agent_type": "analyste_actions", "focus": f"{ticker} ({company})"}
                )

            # Ajout d'un analyste sectoriel si multiple tickers
            if len(actionable_tickers) > 1:
                sectors = []
                for ticker_info in actionable_tickers:
                    # Gestion des objets Pydantic ET des dictionnaires
                    if hasattr(ticker_info, "justification_impact"):
                        justification = ticker_info.justification_impact
                    else:
                        justification = ticker_info.get("justification_impact", "")
                    # Extraction de mots-cl√©s sectoriels basiques
                    if any(
                        word in justification.lower()
                        for word in [
                            "tech",
                            "technologie",
                            "intelligence artificielle",
                            "ia",
                        ]
                    ):
                        sectors.append("Technologie")
                    elif any(
                        word in justification.lower()
                        for word in ["auto", "v√©hicule", "transport"]
                    ):
                        sectors.append("Automobile")
                    elif any(
                        word in justification.lower()
                        for word in ["√©nergie", "p√©trole", "gaz"]
                    ):
                        sectors.append("√ânergie")
                    elif any(
                        word in justification.lower()
                        for word in ["finance", "banque", "cr√©dit"]
                    ):
                        sectors.append("Finance")

                if sectors:
                    unique_sectors = list(set(sectors))
                    team.append(
                        {
                            "agent_type": "analyste_sectoriel",
                            "focus": f"Impact sectoriel sur {', '.join(unique_sectors)}",
                        }
                    )

            log_step(
                state,
                f"üéØ Mode PR√âCIS activ√© - {len(actionable_tickers)} ticker(s) cibl√©(s)",
            )

        else:
            # Mode FALLBACK : Analyse macro classique
            team = [
                {
                    "agent_type": "strategiste_geopolitique",
                    "focus": "Analyse macro√©conomique g√©n√©rale de la situation"
                }
            ]
            log_step(state, "‚ö†Ô∏è Aucun ticker actionnable, fallback sur agent macro.")

        state["agent_team"] = team

        # --- D√âBUT DE LA MODIFICATION ---
        # Filet de s√©curit√© : Si, pour une raison quelconque, aucun agent n'est
        # recrut√© en mode fallback, on assigne un strat√®ge g√©opolitique par d√©faut.
        if not team:
            log_step(state, "‚ö†Ô∏è Aucun agent recrut√©. Assignation d'un agent par d√©faut pour √©viter l'√©chec.")
            state["agent_team"] = [
                {
                    "agent_type": "strategiste_geopolitique",
                    "focus": "Analyse macro√©conomique g√©n√©rale de la situation"
                }
            ]
        # --- FIN DE LA MODIFICATION ---

        log_step(state, f"‚úÖ √âquipe recrut√©e: {len(state['agent_team'])} agent(s)")
        for agent in team:
            log_step(state, f"   - {agent['agent_type']} ‚Üí Focus: {agent['focus']}")

    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans le routage des agents: {str(e)}")
        state["agent_team"] = []

    return state


def node_run_agent_analyses(state: GraphState) -> GraphState:
    """N≈ìud 4 : Ex√©cute les analyses de chaque agent sp√©cialis√© (mode PURE PREDICTION)."""
    log_step(
        state, "EX√âCUTION - Analyses sp√©cialis√©es PURE PREDICTION (mode 'tac au tac')"
    )

    try:
        if not state["agent_team"]:
            raise ValueError("Aucun agent disponible pour l'analyse")

        agent_analyses = []
        actionable_tickers = state.get("actionable_tickers", [])

        for i, agent in enumerate(state["agent_team"], 1):
            log_step(
                state,
                f"Ex√©cution agent {i}/{len(state['agent_team'])}: {agent['agent_type']}",
            )

            # D√©tecter si c'est un agent d'analyse d'actions avec ticker identifi√©
            is_ticker_analysis = (
                agent["agent_type"] == "analyste_actions"
                and actionable_tickers
                and len(actionable_tickers) > 0
            )

            if is_ticker_analysis:
                # Extraire le ticker du focus (format: "AAPL (Apple Inc.)")
                focus_text = agent["focus"]
                ticker = None

                # Chercher le ticker dans les actionable_tickers
                for ticker_info in actionable_tickers:
                    # Gestion des objets Pydantic ET des dictionnaires
                    if hasattr(ticker_info, "ticker"):
                        ticker_value = ticker_info.ticker
                    else:
                        ticker_value = ticker_info.get("ticker", "")

                    if ticker_value in focus_text:
                        ticker = ticker_value
                        break

                if ticker:
                    log_step(
                        state,
                        f"üöÄ Analyse PURE PREDICTION pour {ticker} (mode 'tac au tac')",
                    )

                    # === MODIFICATION CL√â ICI ===
                    # Utiliser l'agent de pure pr√©diction sans donn√©es de prix
                    analysis = run_pure_prediction_analysis(
                        ticker=ticker,
                        news_summary=state["news_summary"],
                        full_article_text=state["full_article_text"],
                    )

                    agent_analyses.append(
                        {
                            "agent_type": agent["agent_type"]
                            + "_pure_prediction",  # Marquer le mode
                            "focus": agent["focus"],
                            "analysis": analysis,
                            "ticker": ticker,
                            "is_augmented": False,  # Il n'est plus "augment√©" avec des donn√©es de prix
                        }
                    )

                    log_step(
                        state, f"‚úÖ Analyse PURE PREDICTION termin√©e pour {ticker}"
                    )
                else:
                    # Fallback vers l'analyse classique
                    log_step(
                        state,
                        f"‚ö†Ô∏è Ticker non trouv√©, analyse classique pour {focus_text}",
                    )
                    analysis = run_agent_analysis(
                        agent_type=agent["agent_type"],
                        focus=agent["focus"],
                        news_summary=state["news_summary"],
                        full_article_text=state["full_article_text"],
                    )

                    agent_analyses.append(
                        {
                            "agent_type": agent["agent_type"],
                            "focus": agent["focus"],
                            "analysis": analysis,
                            "is_augmented": False,
                        }
                    )

                    log_step(
                        state, f"‚úÖ Analyse classique termin√©e: {agent['agent_type']}"
                    )
            else:
                # Agent classique (sectoriel, g√©opolitique, etc.)
                log_step(state, f"üìä Analyse classique pour {agent['agent_type']}")

                analysis = run_agent_analysis(
                    agent_type=agent["agent_type"],
                    focus=agent["focus"],
                    news_summary=state["news_summary"],
                    full_article_text=state["full_article_text"],
                )

                agent_analyses.append(
                    {
                        "agent_type": agent["agent_type"],
                        "focus": agent["focus"],
                        "analysis": analysis,
                        "is_augmented": False,
                    }
                )

                log_step(state, f"‚úÖ Analyse classique termin√©e: {agent['agent_type']}")

        # Formatage du debriefing pour le superviseur
        state["agent_debriefing"] = format_debriefing(agent_analyses)

        # Compter les analyses pure prediction
        pure_prediction_count = sum(
            1 for a in agent_analyses if "pure_prediction" in a.get("agent_type", "")
        )
        log_step(
            state,
            f"‚úÖ Debriefing consolid√© - {len(agent_analyses)} analyses ({pure_prediction_count} pure prediction)",
        )

    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans les analyses d'agents: {str(e)}")
        state["agent_debriefing"] = f"ERREUR: {str(e)}"

    return state


def node_final_investor_decision(state: GraphState) -> GraphState:
    """N≈ìud 5 : Prend la d√©cision finale d'investissement via l'Agent Superviseur."""
    log_step(state, "D√âCISION - Agent Investisseur Final")

    try:
        if not state["agent_debriefing"] or "ERREUR" in state["agent_debriefing"]:
            raise ValueError("Debriefing invalide, impossible de prendre une d√©cision")

        # Configuration du parser JSON
        parser = JsonOutputParser(pydantic_object=InvestmentDecision)

        # R√©cup√©ration du template de l'investisseur final
        investor_prompt = AGENT_PROFILES["investisseur_final"]

        # Formatage des tickers pour l'investisseur final
        actionable_tickers = state.get("actionable_tickers", [])
        tickers_summary = "Aucun ticker sp√©cifique identifi√©"

        if actionable_tickers:
            tickers_list = []
            for ticker_info in actionable_tickers:
                # Gestion des objets Pydantic ET des dictionnaires
                if hasattr(ticker_info, "ticker"):
                    # Objet Pydantic
                    ticker = ticker_info.ticker
                    company = ticker_info.nom_entreprise
                    justification = ticker_info.justification_impact
                else:
                    # Dictionnaire classique (fallback)
                    ticker = ticker_info.get("ticker", "N/A")
                    company = ticker_info.get("nom_entreprise", "N/A")
                    justification = ticker_info.get("justification_impact", "N/A")

                tickers_list.append(f"‚Ä¢ {ticker} ({company}): {justification}")
            tickers_summary = "\n".join(tickers_list)

        # Cr√©ation de la cha√Æne LangChain
        chain = investor_prompt | llm | parser

        # Ex√©cution de la d√©cision
        decision_result = chain.invoke(
            {
                "debriefing_equipe": state["agent_debriefing"],
                "capital_disponible": state["capital_disponible"],
                "actionable_tickers": tickers_summary,
            }
        )

        # --- D√âBUT DE LA CORRECTION ---
        decision_obj = None
        if isinstance(decision_result, list):
            if decision_result:
                # Si le LLM retourne une liste, on prend le premier √©l√©ment
                log_step(
                    state, "‚ö†Ô∏è  Le LLM a retourn√© une liste, prise du premier √©l√©ment."
                )
                decision_obj = decision_result[0]
            else:
                raise ValueError("Le LLM a retourn√© une liste vide.")
        else:
            # Comportement normal (objet Pydantic ou dict)
            decision_obj = decision_result

        # Maintenant, on s'assure que decision_obj est un dictionnaire
        if hasattr(decision_obj, "decision"):
            # C'est un objet Pydantic, convertir en dict
            decision_dict = {
                "decision": decision_obj.decision,
                "ticker": decision_obj.ticker,
                "confiance": decision_obj.confiance,
                "justification_synthetique": decision_obj.justification_synthetique,
                "allocation_capital_pourcentage": decision_obj.allocation_capital_pourcentage,
                "points_cles_positifs": decision_obj.points_cles_positifs,
                "points_cles_negatifs_risques": decision_obj.points_cles_negatifs_risques,
            }
        else:
            # C'est d√©j√† un dictionnaire
            decision_dict = decision_obj
        # --- FIN DE LA CORRECTION ---

        # --- NOUVEAU : CAPTURE DU PRIX AU MOMENT DE LA D√âCISION ---
        decision_ticker = decision_dict.get("ticker")
        prix_au_moment_decision = 0.0
        if decision_ticker:
            log_step(state, f"üí∞ Capture du prix live pour {decision_ticker}...")
            prix_au_moment_decision = get_live_price(decision_ticker)
            if prix_au_moment_decision > 0:
                log_step(state, f"‚úÖ Prix captur√© : {prix_au_moment_decision:.2f} USD")
            else:
                log_step(state, f"‚ö†Ô∏è  Impossible de capturer le prix pour {decision_ticker}")

        # NOUVEAU : On ajoute le prix "grav√©" √† la d√©cision
        decision_dict["prix_a_la_decision"] = prix_au_moment_decision
        # --- FIN DE LA CAPTURE DE PRIX ---

        # --- D√âBUT DE LA CORRECTION LOGIQUE ---
        # Si la d√©cision est LONG mais que l'allocation est nulle,
        # la confiance est insuffisante. On ram√®ne la d√©cision √† SURVEILLER.
        if (
            decision_dict.get("decision") == "LONG"
            and decision_dict.get("allocation_capital_pourcentage", 0.0) == 0.0
        ):

            log_step(
                state,
                "‚ö†Ô∏è  INCOH√âRENCE D√âTECT√âE: LONG avec 0% d'allocation. D√©cision r√©trograd√©e √† SURVEILLER.",
            )

            # R√©trograder la d√©cision
            decision_dict["decision"] = "SURVEILLER"
            decision_dict["confiance"] = "FAIBLE"  # Forcer la confiance √† FAIBLE
            decision_dict["justification_synthetique"] = (
                f"[R√©trograd√©] Signal LONG d√©tect√© mais confiance insuffisante pour une allocation de capital. {decision_dict.get('justification_synthetique', '')}"
            )
        # --- FIN DE LA CORRECTION LOGIQUE ---

        state["final_decision"] = decision_dict

        # Logs d√©taill√©s de la d√©cision
        log_step(state, f"‚úÖ D√âCISION PRISE: {decision_dict.get('decision', 'N/A')}")
        log_step(state, f"   üéØ Ticker: {decision_dict.get('ticker', 'N/A')}")
        log_step(state, f"   üìä Confiance: {decision_dict.get('confiance', 'N/A')}")
        log_step(
            state,
            f"   üí∞ Allocation: {decision_dict.get('allocation_capital_pourcentage', 0)}%",
        )
        log_step(
            state,
            f"   üìù Justification: {decision_dict.get('justification_synthetique', 'N/A')}",
        )

    except Exception as e:
        log_step(state, f"‚ùå ERREUR dans la d√©cision finale: {str(e)}")
        state["final_decision"] = {
            "decision": "ERREUR",
            "ticker": None,
            "confiance": "AUCUNE",
            "justification_synthetique": f"Erreur syst√®me: {str(e)}",
            "allocation_capital_pourcentage": 0.0,
            "points_cles_positifs": [],
            "points_cles_negatifs_risques": ["Erreur syst√®me"],
        }

    return state


# --- CONSTRUCTION DU GRAPHE LANGGRAPH ---


def create_workflow() -> StateGraph:
    """Cr√©e et configure le graphe d'orchestration avec le nouveau Ticker Hunter."""

    workflow = StateGraph(GraphState)

    # Ajout des n≈ìuds (dans l'ordre d'ex√©cution)
    workflow.add_node("initial_analysis", node_initial_analysis)
    workflow.add_node(
        "find_actionable_tickers", node_find_actionable_tickers
    )  # NOUVEAU
    workflow.add_node("route_to_agents", node_route_to_agents)
    workflow.add_node("run_agent_analyses", node_run_agent_analyses)
    workflow.add_node("final_investor_decision", node_final_investor_decision)

    # D√©finition des transitions (nouveau flux avec Ticker Hunter)
    workflow.set_entry_point("initial_analysis")
    workflow.add_edge("initial_analysis", "find_actionable_tickers")  # 1 ‚Üí 2
    workflow.add_edge("find_actionable_tickers", "route_to_agents")  # 2 ‚Üí 3
    workflow.add_edge("route_to_agents", "run_agent_analyses")  # 3 ‚Üí 4
    workflow.add_edge("run_agent_analyses", "final_investor_decision")  # 4 ‚Üí 5
    workflow.add_edge("final_investor_decision", END)  # 5 ‚Üí FIN

    return workflow


# --- FONCTION PRINCIPALE D'ORCHESTRATION ---


def run_berzerk_pipeline(
    news_link: str, capital_disponible: float = 30000.0
) -> dict[str, Any]:
    """
    Ex√©cute le pipeline complet d'analyse BERZERK.

    Args:
        news_link: URL de l'article √† analyser
        capital_disponible: Capital disponible pour l'investissement

    Returns:
        √âtat final avec la d√©cision d'investissement
    """

    print("\n" + "=" * 80)
    print("üöÄ D√âMARRAGE DU PIPELINE AUTOMATIS√â BERZERK")
    print("=" * 80)

    # √âtat initial
    initial_state = GraphState(
        news_link=news_link,
        news_summary="",
        full_article_text="",
        initial_analysis={},
        actionable_tickers=[],  # NOUVEAU : Pour stocker les tickers identifi√©s
        agent_team=[],
        agent_debriefing="",
        final_decision={},
        capital_disponible=capital_disponible,
        execution_log=[],
        timestamp=datetime.now().isoformat(),
    )

    # Cr√©ation et compilation du graphe
    workflow = create_workflow()
    app = workflow.compile()

    # Ex√©cution du pipeline
    try:
        final_state = app.invoke(initial_state)

        print("\n" + "=" * 80)
        print("üéØ PIPELINE TERMIN√â - R√âSULTATS FINAUX")
        print("=" * 80)

        return final_state

    except Exception as e:
        print(f"\n‚ùå ERREUR CRITIQUE DANS LE PIPELINE: {str(e)}")
        return {
            "error": str(e),
            "execution_log": initial_state.get("execution_log", []),
            "final_decision": {
                "decision": "ERREUR_CRITIQUE",
                "justification_synthetique": f"Pipeline interrompu: {str(e)}",
            },
        }


# --- FONCTION D'AFFICHAGE DES R√âSULTATS ---


def display_final_results(final_state: dict[str, Any]) -> None:
    """Affiche les r√©sultats finaux de mani√®re format√©e."""

    # Affichage des tickers identifi√©s
    actionable_tickers = final_state.get("actionable_tickers", [])
    if actionable_tickers:
        print("\nüéØ TICKERS IDENTIFI√âS PAR LE TICKER HUNTER:")
        for ticker_info in actionable_tickers:
            # Gestion des objets Pydantic ET des dictionnaires
            if hasattr(ticker_info, "ticker"):
                ticker = ticker_info.ticker
                company = ticker_info.nom_entreprise
                justification = ticker_info.justification_impact
            else:
                ticker = ticker_info.get("ticker", "N/A")
                company = ticker_info.get("nom_entreprise", "N/A")
                justification = ticker_info.get("justification_impact", "N/A")
            print(f"   üè¢ {ticker} ({company})")
            print(f"      üìù {justification}")
    else:
        print("\n‚ö†Ô∏è AUCUN TICKER ACTIONNABLE IDENTIFI√â")

    decision = final_state.get("final_decision", {})

    print("\nüìä D√âCISION FINALE BERZERK:")
    print(f"   üéØ Action: {decision.get('decision', 'N/A')}")
    print(f"   üìà Ticker: {decision.get('ticker', 'N/A')}")
    print(f"   üîí Confiance: {decision.get('confiance', 'N/A')}")
    print(f"   üí∞ Allocation: {decision.get('allocation_capital_pourcentage', 0)}%")
    print(f"   üìù Justification: {decision.get('justification_synthetique', 'N/A')}")

    positifs = decision.get("points_cles_positifs", [])
    if positifs:
        print("\n‚úÖ Points Positifs:")
        for point in positifs:
            print(f"   ‚Ä¢ {point}")

    risques = decision.get("points_cles_negatifs_risques", [])
    if risques:
        print("\n‚ö†Ô∏è Risques Identifi√©s:")
        for risque in risques:
            print(f"   ‚Ä¢ {risque}")

    print("\nüìã Logs d'ex√©cution:")
    for log in final_state.get("execution_log", []):
        print(f"   {log}")


# --- TESTS ET EX√âCUTION PRINCIPALE ---


def test_pipeline():
    """Fonction de test avec des exemples d'articles."""

    print("üß™ MODE TEST - S√©lection automatique d'un article r√©cent")

    # Pour le test, on peut utiliser un URL simple ou une simulation
    test_url = "https://finance.yahoo.com/news/"  # URL g√©n√©rique pour test

    return run_berzerk_pipeline(news_link=test_url, capital_disponible=25000.0)


if __name__ == "__main__":
    """Point d'entr√©e principal."""

    # V√©rification des arguments de ligne de commande
    if len(sys.argv) > 1:
        news_url = sys.argv[1]
        capital = float(sys.argv[2]) if len(sys.argv) > 2 else 30000.0

        print(f"üì∞ Analyse de: {news_url}")
        print(f"üí∞ Capital disponible: {capital}‚Ç¨")

        final_state = run_berzerk_pipeline(news_url, capital)
        display_final_results(final_state)

    else:
        print("üß™ MODE DEMO - Ex√©cution du pipeline de test")
        final_state = test_pipeline()
        display_final_results(final_state)

        print("\nüí° Usage: python orchestrator.py <URL_NEWS> [CAPITAL]")
        print(
            "   Exemple: python orchestrator.py 'https://finance.yahoo.com/news/apple-ai-news' 25000"
        )
</file>

</files>
