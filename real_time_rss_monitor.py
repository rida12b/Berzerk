#!/usr/bin/env python3
"""
ğŸš€ BERZERK Real-Time RSS Monitor - Surveillance RSS Quasi-InstantanÃ©e
=====================================================================

Ce systÃ¨me avancÃ© surveille les flux RSS en temps quasi-rÃ©el avec :
- Polling haute frÃ©quence (30-60 secondes)
- Optimisations HTTP (ETags, Last-Modified, conditional requests)
- Threading asynchrone pour Ã©viter les blocages
- DÃ©tection intelligente des changements
- Analyse automatique instantanÃ©e

Architecture Temps RÃ©el :
- Pas d'attente bloquante (utilise threading)
- RÃ©activitÃ© Ã©vÃ©nementielle
- Gestion des erreurs robuste
- IntÃ©gration avec le pipeline BERZERK existant

Usage: python real_time_rss_monitor.py [poll_interval_seconds]
ArrÃªt: Ctrl+C
"""

import hashlib
import re
import json
import sqlite3
import sys
import threading
import time
from dataclasses import dataclass
from datetime import datetime
from email.utils import parsedate_to_datetime

import feedparser
import requests

# Import des modules BERZERK
from berzerk_lab import init_db
import configparser
from orchestrator import run_berzerk_pipeline, send_telegram_notification


@dataclass
class FeedState:
    """Ã‰tat d'un flux RSS avec optimisations HTTP"""

    url: str
    last_modified: str | None = None
    etag: str | None = None
    last_check: datetime | None = None
    last_content_hash: str | None = None
    consecutive_errors: int = 0
    # articles_cache supprimÃ© - causait des doublons aprÃ¨s redÃ©marrage

    def should_check(self, min_interval: int) -> bool:
        """DÃ©termine si le flux doit Ãªtre vÃ©rifiÃ© maintenant"""
        if self.last_check is None:
            return True

        # Algorithme adaptatif : plus d'erreurs = moins de vÃ©rifications
        if self.consecutive_errors > 0:
            penalty = min(self.consecutive_errors * 30, 300)  # Max 5 minutes de penalty
            return (datetime.now() - self.last_check).total_seconds() > (
                min_interval + penalty
            )

        return (datetime.now() - self.last_check).total_seconds() >= min_interval


class RealTimeRSSMonitor:
    """Surveillant RSS temps rÃ©el avec optimisations avancÃ©es"""

    def __init__(self, poll_interval: int = 30, capital: float = 25000.0):
        # Heure de dÃ©marrage du moniteur (filtre temporel)
        self.startup_time = datetime.now()
        self.poll_interval = poll_interval  # En secondes
        self.capital = capital
        self.feeds_state: dict[str, FeedState] = {}
        self.running = False
        self.stats = {
            "total_checks": 0,
            "new_articles_found": 0,
            "analyses_completed": 0,
            "errors": 0,
            "start_time": datetime.now(),
        }

        # Configuration des requÃªtes HTTP optimisÃ©es
        self.session = requests.Session()
        self.session.headers.update(
            {
                "User-Agent": "BERZERK-RSS-Monitor/1.0 (Real-Time News Analysis)",
                "Accept": "application/rss+xml, application/xml, text/xml",
                "Accept-Encoding": "gzip, deflate",
                "Connection": "keep-alive",
            }
        )

        # Initialisation
        self.init_feeds_state()

        print("ğŸš€ BERZERK Real-Time RSS Monitor initialisÃ©")
        print(f"   âš¡ Polling: {poll_interval} secondes (haute frÃ©quence)")
        feeds = self.load_feeds_from_config()
        print(f"   ğŸ“ˆ Flux RSS: {len(feeds)} source(s)")
        for feed_name, feed_url in feeds.items():
            print(f"   ğŸ“¡ {feed_name}: {feed_url}")
        print(f"   ğŸ’° Capital: {capital:,.2f}â‚¬")
        print("   ğŸ”„ Optimisations: ETags, Last-Modified, Threading")
        self.log(
            f"âœ… Moniteur dÃ©marrÃ©. Seules les news publiÃ©es aprÃ¨s {self.startup_time.strftime('%Y-%m-%d %H:%M:%S')} seront traitÃ©es.",
            "SUCCESS",
        )
        print("-" * 70)

    def init_feeds_state(self):
        """Initialise l'Ã©tat de chaque flux RSS"""
        feeds = self.load_feeds_from_config()
        for _feed_name, feed_url in feeds.items():
            self.feeds_state[feed_url] = FeedState(url=feed_url)

    def load_feeds_from_config(self) -> dict[str, str]:
        """Charge les flux RSS depuis config.ini (section [RSS_FEEDS])."""
        config = configparser.ConfigParser()
        config.read("config.ini")
        if "RSS_FEEDS" not in config:
            return {}
        return dict(config["RSS_FEEDS"])  # name -> url

    def log(self, message: str, level: str = "INFO"):
        """Logger avec timestamp et niveau"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        level_emoji = {
            "INFO": "â„¹ï¸",
            "SUCCESS": "âœ…",
            "WARNING": "âš ï¸",
            "ERROR": "âŒ",
            "DETECTION": "ğŸ”",
        }.get(level, "ğŸ“")
        print(f"âš¡ [{timestamp}] {level_emoji} {message}")

    def calculate_content_hash(self, content: str) -> str:
        """Calcule un hash du contenu pour dÃ©tecter les changements"""
        return hashlib.md5(content.encode("utf-8")).hexdigest()

    def check_feed_optimized(self, feed_state: FeedState) -> list[dict]:
        """VÃ©rifie un flux RSS avec optimisations HTTP"""
        try:
            headers = {}

            # Optimisations HTTP conditionnelles
            if feed_state.etag:
                headers["If-None-Match"] = feed_state.etag
            if feed_state.last_modified:
                headers["If-Modified-Since"] = feed_state.last_modified

            # RequÃªte HTTP avec timeout court
            response = self.session.get(feed_state.url, headers=headers, timeout=10)

            feed_state.last_check = datetime.now()
            self.stats["total_checks"] += 1

            # Gestion des codes de statut HTTP
            if response.status_code == 304:
                # Not Modified - aucun changement
                self.log(f"ğŸ”„ Pas de changement: {feed_state.url[:50]}...")
                feed_state.consecutive_errors = 0
                return []

            if response.status_code != 200:
                raise Exception(f"HTTP {response.status_code}")

            # Mise Ã  jour des mÃ©tadonnÃ©es de cache
            feed_state.etag = response.headers.get("ETag")
            feed_state.last_modified = response.headers.get("Last-Modified")

            # VÃ©rification du hash du contenu
            content_hash = self.calculate_content_hash(response.text)
            if feed_state.last_content_hash == content_hash:
                self.log(f"ğŸ”„ Contenu identique: {feed_state.url[:50]}...")
                feed_state.consecutive_errors = 0
                return []

            feed_state.last_content_hash = content_hash

            # Parsing RSS
            feed = feedparser.parse(response.text)

            if feed.bozo:
                self.log(f"âš ï¸ Feed mal formÃ©: {feed_state.url[:50]}...")

            # Filtrage des nouveaux articles - LOGIQUE SIMPLIFIÃ‰E
            new_articles = []
            for entry in feed.entries:
                article_link = entry.get("link", "")

                # Extraction des mÃ©tadonnÃ©es
                published_date = None
                if hasattr(entry, "published_parsed") and entry.published_parsed:
                    published_date = datetime(*entry.published_parsed[:6])
                elif hasattr(entry, "published"):
                    try:
                        published_date = parsedate_to_datetime(entry.published)
                    except Exception:
                        published_date = datetime.now()
                else:
                    published_date = datetime.now()

                # Nouveau filtre temporel: ignorer les articles plus anciens que l'heure de dÃ©marrage
                if published_date < self.startup_time:
                    continue

                article = {
                    "title": entry.get("title", "Titre non disponible"),
                    "link": article_link,
                    "published_date": published_date,
                    "summary": entry.get("summary", ""),
                    "source": feed_state.url,
                    "discovered_at": datetime.now(),
                }

                new_articles.append(article)

            # SuccÃ¨s - reset des erreurs
            feed_state.consecutive_errors = 0

            if new_articles:
                self.log(
                    f"ğŸ¯ {len(new_articles)} VRAIS nouveaux articles dÃ©tectÃ©s sur {feed_state.url[:50]}...",
                    "DETECTION",
                )
                self.stats["new_articles_found"] += len(new_articles)

                # Publier des Ã©vÃ©nements de news pour chaque ticker identifiÃ©
                try:
                    for article in new_articles:
                        title = article.get("title", "")
                        summary = article.get("summary", "")
                        tickers_in_title = identify_tickers_in_text(title)
                        tickers_in_summary = identify_tickers_in_text(summary)
                        for ticker in set(tickers_in_title + tickers_in_summary):
                            try:
                                publish_news_event(ticker, article)
                                self.log(f"ğŸ—ï¸ Event publiÃ©: {ticker} â† '{title[:40]}...'", "SUCCESS")
                            except Exception as e:
                                self.log(f"âš ï¸ Ã‰chec publication event {ticker}: {e}")
                except Exception as e:
                    self.log(f"âš ï¸ Erreur lors de la publication des news_events: {e}")

            return new_articles

        except Exception as e:
            feed_state.consecutive_errors += 1
            self.stats["errors"] += 1
            self.log(f"âŒ Erreur sur {feed_state.url[:50]}: {e}")
            return []

    def store_article(self, article: dict):
        """Stocke un article dans la base de donnÃ©es"""
        try:
            conn = sqlite3.connect("berzerk.db")
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT OR IGNORE INTO articles
                (title, link, published_date, source, status, published_str)
                VALUES (?, ?, ?, ?, 'pending', ?)
            """,
                (
                    article["title"],
                    article["link"],
                    article["published_date"].isoformat(),
                    article["source"],
                    article.get(
                        "summary", "RSS Feed"
                    ),  # Utilise summary comme published_str
                ),
            )

            conn.commit()
            conn.close()

            if cursor.rowcount > 0:
                self.log(f"ğŸ’¾ Article stockÃ©: {article['title'][:50]}...")

        except Exception as e:
            self.log(f"âŒ Erreur stockage: {e}")

    def analyze_article_realtime(self, article: dict) -> dict | None:
        """Analyse un article en temps rÃ©el avec le pipeline BERZERK"""
        try:
            self.log(f"ğŸ¤– Analyse TEMPS RÃ‰EL: {article['title'][:50]}...")

            # Lancement du pipeline complet
            result = run_berzerk_pipeline(article["link"], self.capital)

            if result and "final_decision" in result:
                # Sauvegarde de la dÃ©cision
                self.save_decision_to_db(article["link"], result["final_decision"])

                # Statistiques
                self.stats["analyses_completed"] += 1

                # Affichage du rÃ©sultat
                decision = result["final_decision"]
                action = decision.get("decision", "INCONNU")

                # --- DÃ‰BUT DU TEMPLATE FINAL ---
                if action in ["LONG", "SHORT"]:
                    ticker = decision.get("ticker", "N/A")
                    prix_decision = decision.get("prix_a_la_decision", 0.0)
                    confiance = decision.get("confiance", "INCONNUE")
                    justification = decision.get("justification_synthetique", "N/A")
                    article_link = article["link"]

                    if action == "LONG":
                        signal_color = "ğŸŸ¢"
                        action_label = "ACHAT (LONG)"
                    else:  # SHORT
                        signal_color = "ğŸ”´"
                        action_label = "VENTE (SHORT)"

                    message = (
                        f"{signal_color} *NOUVEAU SIGNAL BERZERK*\n\n"
                        f"*{action_label}:* `{ticker}`\n"
                        f"-----------------------------------\n"
                        f"ğŸ’° *Prix d'EntrÃ©e:* `{prix_decision:.2f} $`\n"
                        f"ğŸ’ª *Confiance:* **{confiance.upper()}**\n\n"
                        f"> {justification}\n\n"
                        f"ğŸ“° [Lire l'article source]({article_link})"
                    )
                    send_telegram_notification(message)
                # --- FIN DU TEMPLATE FINAL ---

                if action in ["LONG", "ACHETER"]:  # CompatibilitÃ© avec anciennes donnÃ©es
                    self.log(
                        f"ğŸš€ SIGNAL LONG IDENTIFIÃ‰: {article['title'][:50]}...", "SUCCESS"
                    )
                    ticker = decision.get("ticker_cible", "N/A")
                    allocation = decision.get("allocation_pourcentage", 0)
                    self.log(f"   ğŸ’° Ticker: {ticker}, Allocation: {allocation}%")
                elif action == "SURVEILLER":
                    self.log(f"ğŸ‘€ SURVEILLANCE: {article['title'][:50]}...")
                else:
                    self.log(f"âœ… Analyse terminÃ©e: {action}")

                return result
            else:
                self.log(f"âš ï¸ Ã‰chec d'analyse: {article['title'][:50]}...")
                return None

        except Exception as e:
            self.log(f"âŒ Erreur analyse temps rÃ©el: {e}")
            return None

    def save_decision_to_db(self, article_link: str, decision: dict):
        """Sauvegarde la dÃ©cision dans la base de donnÃ©es"""
        try:
            conn = sqlite3.connect("berzerk.db")
            cursor = conn.cursor()

            cursor.execute(
                """
                UPDATE articles
                SET decision_json = ?,
                    status = 'analyzed',
                    analyzed_at = ?
                WHERE link = ?
            """,
                (
                    json.dumps(decision, ensure_ascii=False),
                    datetime.now().isoformat(),
                    article_link,
                ),
            )

            # Nouvelle logique: crÃ©er un trade si dÃ©cision LONG/SHORT
            try:
                decision_type = str(decision.get("decision", "")).upper()
                if decision_type in ("LONG", "SHORT"):
                    # RÃ©cupÃ©rer l'id de l'article concernÃ©
                    cursor.execute(
                        "SELECT id FROM articles WHERE link = ?",
                        (article_link,),
                    )
                    row = cursor.fetchone()
                    if row:
                        article_id = row[0]
                        ticker = decision.get("ticker") or ""
                        entry_price = decision.get("prix_a_la_decision") or 0.0
                        entry_at = datetime.now().isoformat()

                        cursor.execute(
                            """
                            INSERT OR IGNORE INTO trades (
                                article_id, ticker, decision_type, entry_at, entry_price, status
                            ) VALUES (?, ?, ?, ?, ?, 'OPEN')
                            """,
                            (
                                article_id,
                                ticker,
                                decision_type,
                                entry_at,
                                float(entry_price) if entry_price is not None else 0.0,
                            ),
                        )

                        self.log(
                            f"âœ… Trade enregistrÃ©: {decision_type} {ticker} @ {entry_price}",
                            "SUCCESS",
                        )
                    else:
                        self.log(
                            "âš ï¸ Impossible de crÃ©er le trade: article introuvable aprÃ¨s UPDATE",
                            "WARNING",
                        )
            except Exception as e:
                self.log(f"âš ï¸ Erreur lors de la crÃ©ation du trade: {e}")

            conn.commit()
            conn.close()

        except Exception as e:
            self.log(f"âŒ Erreur sauvegarde dÃ©cision: {e}")

    def monitoring_thread(self):
        """Thread principal de surveillance"""
        self.log("ğŸ”„ Thread de surveillance dÃ©marrÃ©")

        while self.running:
            try:
                # VÃ©rifier chaque flux RSS
                for _feed_url, feed_state in self.feeds_state.items():
                    if not self.running:
                        break

                    # VÃ©rifier si le flux doit Ãªtre contrÃ´lÃ©
                    if feed_state.should_check(self.poll_interval):
                        new_articles = self.check_feed_optimized(feed_state)

                        # Traiter les nouveaux articles
                        for article in new_articles:
                            if not self.running:
                                break

                            # Stockage en base
                            self.store_article(article)

                            # Analyse immÃ©diate en arriÃ¨re-plan
                            threading.Thread(
                                target=self.analyze_article_realtime,
                                args=(article,),
                                daemon=True,
                            ).start()

                # Pause courte avant le prochain cycle
                time.sleep(1)

            except Exception as e:
                self.log(f"âŒ Erreur dans le thread de surveillance: {e}")
                time.sleep(5)  # Pause plus longue en cas d'erreur

        self.log("ğŸ›‘ Thread de surveillance arrÃªtÃ©")

    def display_stats(self):
        """Affiche les statistiques en temps rÃ©el"""
        uptime = datetime.now() - self.stats["start_time"]

        print("\n" + "=" * 50)
        print("ğŸ“Š STATISTIQUES TEMPS RÃ‰EL")
        print("=" * 50)
        print(f"â±ï¸  Uptime: {uptime}")
        print(f"ğŸ”„ VÃ©rifications totales: {self.stats['total_checks']}")
        print(f"ğŸ“ˆ Nouveaux articles: {self.stats['new_articles_found']}")
        print(f"ğŸ¤– Analyses complÃ¨tes: {self.stats['analyses_completed']}")
        print(f"âŒ Erreurs: {self.stats['errors']}")
        # Cache supprimÃ©: on n'utilise plus de cache d'articles en mÃ©moire
        print("=" * 50)

    def start(self):
        """DÃ©marre la surveillance temps rÃ©el"""
        self.log("ğŸš€ DÃ‰MARRAGE DE LA SURVEILLANCE TEMPS RÃ‰EL", "SUCCESS")
        self.log(f"âš¡ Polling: {self.poll_interval} secondes")
        self.log("â¹ï¸  ArrÃªt: Ctrl+C")

        # Initialiser la base de donnÃ©es
        init_db()

        # DÃ©marrer le thread de surveillance
        self.running = True
        monitor_thread = threading.Thread(target=self.monitoring_thread, daemon=True)
        monitor_thread.start()

        try:
            # Boucle principale avec affichage des stats
            while True:
                time.sleep(30)  # Afficher les stats toutes les 30 secondes
                self.display_stats()

        except KeyboardInterrupt:
            self.log("ğŸ›‘ ArrÃªt demandÃ© par l'utilisateur", "WARNING")
        finally:
            self.running = False
            self.log("ğŸ‘‹ Surveillance temps rÃ©el arrÃªtÃ©e", "SUCCESS")
            self.display_stats()


def identify_tickers_in_text(text: str) -> list[str]:
    """Identifie des tickers basÃ©s sur des mots en MAJUSCULES (2 Ã  5 lettres)."""
    if not text:
        return []
    try:
        return re.findall(r"\b[A-Z]{2,5}\b", text)
    except Exception:
        return []


def publish_news_event(ticker: str, article: dict) -> None:
    """Publie un Ã©vÃ©nement de news dans la table news_events."""
    conn = sqlite3.connect("berzerk.db")
    cursor = conn.cursor()
    try:
        cursor.execute(
            """
            INSERT INTO news_events (ticker, news_title, news_link, detected_at, is_processed)
            VALUES (?, ?, ?, ?, 0)
            """,
            (
                ticker.strip(),
                article.get("title", "Titre non disponible"),
                article.get("link", ""),
                datetime.now().isoformat(),
            ),
        )
        conn.commit()
    finally:
        conn.close()

    def store_article(self, article: dict):
        """Stocke un article dans la base de donnÃ©es"""
        try:
            conn = sqlite3.connect("berzerk.db")
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT OR IGNORE INTO articles
                (title, link, published_date, source, status, published_str)
                VALUES (?, ?, ?, ?, 'pending', ?)
            """,
                (
                    article["title"],
                    article["link"],
                    article["published_date"].isoformat(),
                    article["source"],
                    article.get(
                        "summary", "RSS Feed"
                    ),  # Utilise summary comme published_str
                ),
            )

            conn.commit()
            conn.close()

            if cursor.rowcount > 0:
                self.log(f"ğŸ’¾ Article stockÃ©: {article['title'][:50]}...")

        except Exception as e:
            self.log(f"âŒ Erreur stockage: {e}")

    def analyze_article_realtime(self, article: dict) -> dict | None:
        """Analyse un article en temps rÃ©el avec le pipeline BERZERK"""
        try:
            self.log(f"ğŸ¤– Analyse TEMPS RÃ‰EL: {article['title'][:50]}...")

            # Lancement du pipeline complet
            result = run_berzerk_pipeline(article["link"], self.capital)

            if result and "final_decision" in result:
                # Sauvegarde de la dÃ©cision
                self.save_decision_to_db(article["link"], result["final_decision"])

                # Marquer comme traitÃ©
                self.processed_articles.add(article["link"])

                # Statistiques
                self.stats["analyses_completed"] += 1

                # Affichage du rÃ©sultat
                decision = result["final_decision"]
                action = decision.get("decision", "INCONNU")

                # --- DÃ‰BUT DU TEMPLATE FINAL ---
                if action in ["LONG", "SHORT"]:
                    ticker = decision.get("ticker", "N/A")
                    prix_decision = decision.get("prix_a_la_decision", 0.0)
                    confiance = decision.get("confiance", "INCONNUE")
                    justification = decision.get("justification_synthetique", "N/A")
                    article_link = article["link"]

                    if action == "LONG":
                        signal_color = "ğŸŸ¢"
                        action_label = "ACHAT (LONG)"
                    else: # SHORT
                        signal_color = "ğŸ”´"
                        action_label = "VENTE (SHORT)"
                    
                    message = (
                        f"{signal_color} *NOUVEAU SIGNAL BERZERK*\n\n"
                        f"*{action_label}:* `{ticker}`\n"
                        f"-----------------------------------\n"
                        f"ğŸ’° *Prix d'EntrÃ©e:* `{prix_decision:.2f} $`\n"
                        f"ğŸ’ª *Confiance:* **{confiance.upper()}**\n\n"
                        f"> {justification}\n\n"
                        f"ğŸ“° [Lire l'article source]({article_link})"
                    )
                    send_telegram_notification(message)
                # --- FIN DU TEMPLATE FINAL ---

                if action in ["LONG", "ACHETER"]:  # CompatibilitÃ© avec anciennes donnÃ©es
                    self.log(
                        f"ğŸš€ SIGNAL LONG IDENTIFIÃ‰: {article['title'][:50]}...", "SUCCESS"
                    )
                    ticker = decision.get("ticker_cible", "N/A")
                    allocation = decision.get("allocation_pourcentage", 0)
                    self.log(f"   ğŸ’° Ticker: {ticker}, Allocation: {allocation}%")
                elif action == "SURVEILLER":
                    self.log(f"ğŸ‘€ SURVEILLANCE: {article['title'][:50]}...")
                else:
                    self.log(f"âœ… Analyse terminÃ©e: {action}")

                return result
            else:
                self.log(f"âš ï¸ Ã‰chec d'analyse: {article['title'][:50]}...")
                return None

        except Exception as e:
            self.log(f"âŒ Erreur analyse temps rÃ©el: {e}")
            return None

    def save_decision_to_db(self, article_link: str, decision: dict):
        """Sauvegarde la dÃ©cision dans la base de donnÃ©es"""
        try:
            conn = sqlite3.connect("berzerk.db")
            cursor = conn.cursor()

            cursor.execute(
                """
                UPDATE articles
                SET decision_json = ?,
                    status = 'analyzed',
                    analyzed_at = ?
                WHERE link = ?
            """,
                (
                    json.dumps(decision, ensure_ascii=False),
                    datetime.now().isoformat(),
                    article_link,
                ),
            )

            # Nouvelle logique: crÃ©er un trade si dÃ©cision LONG/SHORT
            try:
                decision_type = str(decision.get("decision", "")).upper()
                if decision_type in ("LONG", "SHORT"):
                    # RÃ©cupÃ©rer l'id de l'article concernÃ©
                    cursor.execute(
                        "SELECT id FROM articles WHERE link = ?",
                        (article_link,),
                    )
                    row = cursor.fetchone()
                    if row:
                        article_id = row[0]
                        ticker = decision.get("ticker") or ""
                        entry_price = decision.get("prix_a_la_decision") or 0.0
                        entry_at = datetime.now().isoformat()

                        cursor.execute(
                            """
                            INSERT OR IGNORE INTO trades (
                                article_id, ticker, decision_type, entry_at, entry_price, status
                            ) VALUES (?, ?, ?, ?, ?, 'OPEN')
                            """,
                            (
                                article_id,
                                ticker,
                                decision_type,
                                entry_at,
                                float(entry_price) if entry_price is not None else 0.0,
                            ),
                        )

                        self.log(
                            f"âœ… Trade enregistrÃ©: {decision_type} {ticker} @ {entry_price}",
                            "SUCCESS",
                        )
                    else:
                        self.log(
                            "âš ï¸ Impossible de crÃ©er le trade: article introuvable aprÃ¨s UPDATE",
                            "WARNING",
                        )
            except Exception as e:
                self.log(f"âš ï¸ Erreur lors de la crÃ©ation du trade: {e}")

            conn.commit()
            conn.close()

        except Exception as e:
            self.log(f"âŒ Erreur sauvegarde dÃ©cision: {e}")

    def monitoring_thread(self):
        """Thread principal de surveillance"""
        self.log("ğŸ”„ Thread de surveillance dÃ©marrÃ©")

        while self.running:
            try:
                # VÃ©rifier chaque flux RSS
                for _feed_url, feed_state in self.feeds_state.items():
                    if not self.running:
                        break

                    # VÃ©rifier si le flux doit Ãªtre contrÃ´lÃ©
                    if feed_state.should_check(self.poll_interval):
                        new_articles = self.check_feed_optimized(feed_state)

                        # Traiter les nouveaux articles
                        for article in new_articles:
                            if not self.running:
                                break

                            # Stockage en base
                            self.store_article(article)

                            # Analyse immÃ©diate en arriÃ¨re-plan
                            threading.Thread(
                                target=self.analyze_article_realtime,
                                args=(article,),
                                daemon=True,
                            ).start()

                # Pause courte avant le prochain cycle
                time.sleep(1)

            except Exception as e:
                self.log(f"âŒ Erreur dans le thread de surveillance: {e}")
                time.sleep(5)  # Pause plus longue en cas d'erreur

        self.log("ğŸ›‘ Thread de surveillance arrÃªtÃ©")

    def display_stats(self):
        """Affiche les statistiques en temps rÃ©el"""
        uptime = datetime.now() - self.stats["start_time"]

        print("\n" + "=" * 50)
        print("ğŸ“Š STATISTIQUES TEMPS RÃ‰EL")
        print("=" * 50)
        print(f"â±ï¸  Uptime: {uptime}")
        print(f"ğŸ”„ VÃ©rifications totales: {self.stats['total_checks']}")
        print(f"ğŸ“ˆ Nouveaux articles: {self.stats['new_articles_found']}")
        print(f"ğŸ¤– Analyses complÃ¨tes: {self.stats['analyses_completed']}")
        print(f"âŒ Erreurs: {self.stats['errors']}")
        print(f"ğŸ’¾ Articles en cache: {len(self.processed_articles)}")
        print("=" * 50)

    def start(self):
        """DÃ©marre la surveillance temps rÃ©el"""
        self.log("ğŸš€ DÃ‰MARRAGE DE LA SURVEILLANCE TEMPS RÃ‰EL", "SUCCESS")
        self.log(f"âš¡ Polling: {self.poll_interval} secondes")
        self.log("â¹ï¸  ArrÃªt: Ctrl+C")

        # Initialiser la base de donnÃ©es
        init_db()

        # DÃ©marrer le thread de surveillance
        self.running = True
        monitor_thread = threading.Thread(target=self.monitoring_thread, daemon=True)
        monitor_thread.start()

        try:
            # Boucle principale avec affichage des stats
            while True:
                time.sleep(30)  # Afficher les stats toutes les 30 secondes
                self.display_stats()

        except KeyboardInterrupt:
            self.log("ğŸ›‘ ArrÃªt demandÃ© par l'utilisateur", "WARNING")
        finally:
            self.running = False
            self.log("ğŸ‘‹ Surveillance temps rÃ©el arrÃªtÃ©e", "SUCCESS")
            self.display_stats()


def main():
    """Point d'entrÃ©e principal"""
    # Configuration par dÃ©faut
    poll_interval = 30  # 30 secondes par dÃ©faut
    capital = 25000.0

    # Parsing des arguments
    if len(sys.argv) > 1:
        try:
            poll_interval = int(sys.argv[1])
            if poll_interval < 10:
                raise ValueError("L'intervalle doit Ãªtre d'au moins 10 secondes")
        except ValueError as e:
            print(f"âŒ Erreur: {e}")
            print("ğŸ’¡ Usage: python real_time_rss_monitor.py [poll_interval_seconds]")
            print("ğŸ“Š Exemple: python real_time_rss_monitor.py 30")
            sys.exit(1)

    print("ğŸš€ BERZERK Real-Time RSS Monitor")
    print("âš¡ Surveillance quasi-instantanÃ©e avec polling optimisÃ©")
    print(f"ğŸ”„ Intervalle: {poll_interval} secondes")
    print("-" * 70)

    # Lancement du monitor
    monitor = RealTimeRSSMonitor(poll_interval, capital)
    monitor.start()


if __name__ == "__main__":
    main()
